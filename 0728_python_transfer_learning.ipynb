{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS4D1YOXyyuRW5W/fd5zMH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alex-Jung-HB/0728_python_transfer-learning/blob/main/0728_python_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Mount a google drive"
      ],
      "metadata": {
        "id": "LfxjF8pQePNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF4m5_eZykW-",
        "outputId": "71ade7d9-98b6-470a-bb0e-3e84dfe50a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "File copy to Colab"
      ],
      "metadata": {
        "id": "UEkGfYBbeXo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP 파일을 코랩으로 복사\n",
        "!cp \"/content/drive/MyDrive/dataset.zip\" \"/content/\"\n",
        "\n",
        "# 압축 해제\n",
        "!unzip -o /content/dataset.zip -d /content/\n",
        "\n",
        "# 압축 해제 확인\n",
        "!ls -la /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xneYgsP4z-XY",
        "outputId": "6f44b720-ee95-4ffe-d30a-351cc80d1590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dataset.zip\n",
            "   creating: /content/dataset/\n",
            "  inflating: /content/dataset/best.pt  \n",
            "  inflating: /content/dataset/dataset.yaml  \n",
            "   creating: /content/dataset/train/\n",
            "   creating: /content/dataset/train/images/\n",
            "  inflating: /content/dataset/train/images/add_image1.png  \n",
            "  inflating: /content/dataset/train/images/add_image10.png  \n",
            "  inflating: /content/dataset/train/images/add_image11.png  \n",
            "  inflating: /content/dataset/train/images/add_image12.png  \n",
            "  inflating: /content/dataset/train/images/add_image13.png  \n",
            "  inflating: /content/dataset/train/images/add_image14.png  \n",
            "  inflating: /content/dataset/train/images/add_image15.png  \n",
            "  inflating: /content/dataset/train/images/add_image16.png  \n",
            "  inflating: /content/dataset/train/images/add_image17.png  \n",
            "  inflating: /content/dataset/train/images/add_image18.png  \n",
            "  inflating: /content/dataset/train/images/add_image19.png  \n",
            "  inflating: /content/dataset/train/images/add_image2.png  \n",
            "  inflating: /content/dataset/train/images/add_image20.png  \n",
            "  inflating: /content/dataset/train/images/add_image21.png  \n",
            "  inflating: /content/dataset/train/images/add_image3.png  \n",
            "  inflating: /content/dataset/train/images/add_image4.png  \n",
            "  inflating: /content/dataset/train/images/add_image5.png  \n",
            "  inflating: /content/dataset/train/images/add_image6.png  \n",
            "  inflating: /content/dataset/train/images/add_image7.png  \n",
            "  inflating: /content/dataset/train/images/add_image8.png  \n",
            "  inflating: /content/dataset/train/images/add_image9.png  \n",
            "  inflating: /content/dataset/train/images/day3_1.png  \n",
            "  inflating: /content/dataset/train/images/day3_10.png  \n",
            "  inflating: /content/dataset/train/images/day3_11.png  \n",
            "  inflating: /content/dataset/train/images/day3_12.png  \n",
            "  inflating: /content/dataset/train/images/day3_13.png  \n",
            "  inflating: /content/dataset/train/images/day3_14.png  \n",
            "  inflating: /content/dataset/train/images/day3_15.png  \n",
            "  inflating: /content/dataset/train/images/day3_16.png  \n",
            "  inflating: /content/dataset/train/images/day3_17.png  \n",
            "  inflating: /content/dataset/train/images/day3_2.png  \n",
            "  inflating: /content/dataset/train/images/day3_3.png  \n",
            "  inflating: /content/dataset/train/images/day3_4.png  \n",
            "  inflating: /content/dataset/train/images/day3_6.png  \n",
            "  inflating: /content/dataset/train/images/day3_7.png  \n",
            "  inflating: /content/dataset/train/images/day3_8.png  \n",
            "  inflating: /content/dataset/train/images/day3__9.png  \n",
            "  inflating: /content/dataset/train/images/day5.png  \n",
            "  inflating: /content/dataset/train/images/lane_image186.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image189.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image190.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image192.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image193.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image194.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image195.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image196.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image242.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image81.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image87.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image89.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image1.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image10.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image100.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image101.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image102.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image103.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image104.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image105.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image106.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image107.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image108.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image109.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image11.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image110.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image111.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image112.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image113.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image114.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image115.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image116.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image117.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image118.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image119.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image12.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image120.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image121.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image122.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image123.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image124.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image125.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image126.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image127.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image128.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image129.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image13.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image130.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image131.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image132.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image133.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image134.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image135.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image136.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image137.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image138.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image139.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image14.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image140.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image141.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image142.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image143.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image144.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image145.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image146.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image147.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image148.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image149.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image15.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image150.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image151.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image152.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image153.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image154.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image155.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image156.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image157.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image158.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image159.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image16.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image160.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image161.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image162.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image163.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image164.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image165.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image166.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image167.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image168.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image169.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image17.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image170.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image171.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image172.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image173.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image174.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image175.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image176.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image177.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image178.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image179.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image18.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image180.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image181.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image182.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image183.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image184.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image185.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image186.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image187.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image188.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image189.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image19.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image190.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image191.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image192.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image193.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image194.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image195.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image196.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image197.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image198.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image199.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image2.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image20.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image200.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image21.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image213.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image214.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image215.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image216.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image217.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image218.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image219.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image22.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image220.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image221.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image222.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image223.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image224.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image225.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image226.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image227.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image228.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image229.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image23.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image230.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image231.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image232.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image233.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image234.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image235.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image236.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image237.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image238.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image239.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image24.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image240.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image241.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image242.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image243.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image244.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image245.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image246.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image247.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image248.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image249.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image25.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image250.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image251.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image252.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image253.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image254.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image255.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image256.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image257.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image258.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image259.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image26.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image260.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image27.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image28.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image29.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image3.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image30.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image31.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image32.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image33.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image34.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image35.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image36.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image37.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image38.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image39.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image4.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image40.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image41.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image42.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image43.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image44.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image45.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image46.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image47.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image48.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image49.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image5.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image50.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image51.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image52.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image53.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image54.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image55.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image56.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image57.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image58.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image59.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image6.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image60.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image61.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image62.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image63.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image64.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image65.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image66.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image67.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image68.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image69.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image7.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image70.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image71.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image72.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image73.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image74.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image75.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image76.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image77.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image78.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image79.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image8.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image80.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image81.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image82.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image83.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image84.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image85.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image86.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image87.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image88.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image89.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image9.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image90.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image91.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image92.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image93.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image94.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image95.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image96.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image97.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image98.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image99.jpg  \n",
            "   creating: /content/dataset/train/labels/\n",
            "  inflating: /content/dataset/train/labels/add_image1.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image10.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image11.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image12.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image13.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image14.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image15.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image16.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image17.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image18.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image19.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image2.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image20.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image21.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image3.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image4.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image5.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image6.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image7.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image8.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image9.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_1.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_10.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_11.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_12.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_13.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_14.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_15.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_16.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_17.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_2.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_3.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_4.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_6.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_7.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_8.txt  \n",
            "  inflating: /content/dataset/train/labels/day3__9.txt  \n",
            "  inflating: /content/dataset/train/labels/day5.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image186.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image189.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image190.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image192.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image193.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image194.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image195.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image196.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image242.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image81.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image87.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image89.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image1.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image10.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image100.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image101.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image102.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image103.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image104.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image105.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image106.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image107.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image108.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image109.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image11.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image110.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image111.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image112.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image113.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image114.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image115.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image116.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image117.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image118.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image119.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image12.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image120.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image121.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image122.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image123.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image124.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image125.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image126.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image127.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image128.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image129.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image13.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image130.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image131.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image132.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image133.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image134.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image135.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image136.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image137.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image138.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image139.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image14.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image140.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image141.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image142.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image143.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image144.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image145.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image146.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image147.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image148.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image149.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image15.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image150.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image151.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image152.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image153.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image154.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image155.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image156.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image157.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image158.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image159.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image16.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image160.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image161.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image162.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image163.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image164.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image165.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image166.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image167.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image168.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image169.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image17.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image170.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image171.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image172.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image173.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image174.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image175.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image176.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image177.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image178.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image179.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image18.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image180.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image181.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image182.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image183.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image184.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image185.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image186.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image187.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image188.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image189.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image19.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image190.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image191.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image192.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image193.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image194.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image195.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image196.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image197.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image198.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image199.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image2.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image20.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image200.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image21.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image213.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image214.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image215.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image216.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image217.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image218.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image219.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image22.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image220.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image221.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image222.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image223.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image224.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image225.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image226.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image227.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image228.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image229.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image23.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image230.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image231.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image232.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image233.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image234.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image235.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image236.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image237.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image238.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image239.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image24.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image240.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image241.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image242.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image243.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image244.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image245.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image246.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image247.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image248.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image249.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image25.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image250.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image251.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image252.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image253.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image254.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image255.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image256.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image257.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image258.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image259.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image26.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image260.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image27.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image28.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image29.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image3.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image30.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image31.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image32.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image33.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image34.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image35.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image36.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image37.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image38.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image39.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image4.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image40.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image41.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image42.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image43.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image44.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image45.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image46.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image47.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image48.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image49.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image5.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image50.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image51.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image52.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image53.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image54.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image55.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image56.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image57.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image58.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image59.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image6.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image60.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image61.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image62.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image63.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image64.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image65.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image66.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image67.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image68.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image69.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image7.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image70.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image71.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image72.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image73.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image74.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image75.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image76.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image77.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image78.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image79.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image8.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image80.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image81.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image82.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image83.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image84.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image85.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image86.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image87.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image88.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image89.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image9.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image90.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image91.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image92.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image93.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image94.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image95.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image96.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image97.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image98.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image99.txt  \n",
            "   creating: /content/dataset/valid/\n",
            "   creating: /content/dataset/valid/images/\n",
            "  inflating: /content/dataset/valid/images/lane_image244.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image245.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image252.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image253.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image261.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image264.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image268.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image276.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image282.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image285.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image288.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image296.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image305.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image310.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image311.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image316.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image320.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image325.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image330.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image334.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image342.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image360.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image370.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image383.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image386.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image402.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image407.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image411.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image414.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image433.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image435.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image436.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image439.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image444.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image451.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image452.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image457.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image458.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image460.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image461.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image466.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image470.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image472.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image475.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image478.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image488.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image499.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image506.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image515.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image518.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image527.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image537.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image551.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image552.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image563.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image577.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image581.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image597.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image599.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image605.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image201.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image202.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image203.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image204.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image205.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image206.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image207.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image208.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image209.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image210.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image211.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image212.jpg  \n",
            "   creating: /content/dataset/valid/labels/\n",
            "  inflating: /content/dataset/valid/labels/lane_image244.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image245.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image252.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image253.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image261.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image264.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image268.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image276.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image282.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image285.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image288.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image296.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image305.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image310.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image311.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image316.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image320.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image325.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image330.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image334.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image342.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image360.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image370.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image383.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image386.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image402.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image407.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image411.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image414.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image433.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image435.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image436.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image439.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image444.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image451.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image452.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image457.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image458.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image460.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image461.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image466.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image470.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image472.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image475.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image478.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image488.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image499.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image506.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image515.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image518.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image527.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image537.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image551.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image552.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image563.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image577.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image581.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image597.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image599.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image605.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image201.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image202.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image203.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image204.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image205.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image206.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image207.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image208.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image209.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image210.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image211.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image212.txt  \n",
            "total 136984\n",
            "drwxr-xr-x 1 root root      4096 Jul 28 23:58 .\n",
            "drwxr-xr-x 1 root root      4096 Jul 28 23:42 ..\n",
            "drwxr-xr-x 4 root root      4096 Jul 25 13:38 .config\n",
            "drwxrwxrwx 4 root root      4096 Jul 24 05:20 dataset\n",
            "-rw------- 1 root root 140244539 Jul 28 23:58 dataset.zip\n",
            "drwx------ 6 root root      4096 Jul 28 23:58 drive\n",
            "drwxr-xr-x 1 root root      4096 Jul 25 13:38 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "File copy to Colab"
      ],
      "metadata": {
        "id": "FuA9pjYYdQCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📚 COMPLETE ANNOTATED GUIDE - ZIP FILE IN GOOGLE COLAB\n",
        "# Every command explained step by step for easy understanding\n",
        "\n",
        "# =============================================================================\n",
        "# 🔗 STEP 1: MOUNT GOOGLE DRIVE\n",
        "# =============================================================================\n",
        "\n",
        "# Import the drive module from google.colab\n",
        "# This module allows us to connect Colab to your Google Drive account\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount (connect) your Google Drive to Colab\n",
        "# This creates a bridge between Colab and your personal Google Drive\n",
        "# After this, your Drive files will be accessible at /content/drive/MyDrive/\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 📝 What happens when you run this:\n",
        "# - A popup appears asking for permission to access your Google Drive\n",
        "# - You click \"Connect to Google Drive\"\n",
        "# - You sign in to your Google account\n",
        "# - You grant permission to Colab\n",
        "# - Your Drive becomes accessible in Colab at the path /content/drive/MyDrive/\n",
        "\n",
        "# =============================================================================\n",
        "# 🔍 STEP 2: VERIFY THE FILE EXISTS (OPTIONAL BUT RECOMMENDED)\n",
        "# =============================================================================\n",
        "\n",
        "# List detailed information about your specific ZIP file\n",
        "# -l = long format (shows permissions, size, date, owner)\n",
        "# -a = show all files (including hidden ones starting with .)\n",
        "!ls -la \"/content/drive/MyDrive/dataset.zip\"\n",
        "\n",
        "# 📝 What this command does:\n",
        "# - Checks if dataset.zip actually exists in your Google Drive\n",
        "# - Shows file size, creation date, and permissions\n",
        "# - If file doesn't exist, you'll get \"No such file or directory\" error\n",
        "# - If file exists, you'll see something like: -rw------- 1 root root 140123456 Jul 28 dataset.zip\n",
        "\n",
        "# Alternative: Check what's in your entire Drive root folder\n",
        "!ls -la /content/drive/MyDrive/\n",
        "\n",
        "# 📝 This shows ALL files and folders in your Google Drive root\n",
        "# Helpful to see everything you have and find your ZIP file\n",
        "\n",
        "# =============================================================================\n",
        "# 📂 STEP 3: COPY FILE FROM GOOGLE DRIVE TO COLAB WORKSPACE\n",
        "# =============================================================================\n",
        "\n",
        "# Copy the ZIP file from Google Drive to Colab's local storage\n",
        "# cp = copy command\n",
        "# \"/content/drive/MyDrive/dataset.zip\" = source (where to copy FROM)\n",
        "# /content/ = destination (where to copy TO)\n",
        "!cp \"/content/drive/MyDrive/dataset.zip\" /content/\n",
        "\n",
        "# 📝 Why we use quotes around the source path:\n",
        "# - Protects against special characters or spaces in filenames\n",
        "# - Good practice even when not strictly necessary\n",
        "# - \"/content/drive/MyDrive/dataset.zip\" is safer than /content/drive/MyDrive/dataset.zip\n",
        "\n",
        "# 📝 Understanding the paths:\n",
        "# - /content/drive/MyDrive/ = Your Google Drive (permanent storage)\n",
        "# - /content/ = Colab's workspace (temporary storage, deleted when session ends)\n",
        "# - We copy from permanent storage to temporary workspace for faster processing\n",
        "\n",
        "# =============================================================================\n",
        "# ✅ STEP 4: VERIFY THE COPY WAS SUCCESSFUL\n",
        "# =============================================================================\n",
        "\n",
        "# Check if the file was successfully copied to Colab's workspace\n",
        "!ls -la /content/dataset.zip\n",
        "\n",
        "# 📝 What to expect:\n",
        "# - If successful: Shows file details like -rw-r--r-- 1 root root 140123456 Jul 28 dataset.zip\n",
        "# - If failed: \"No such file or directory\" error\n",
        "# - The file size should match what you saw in your Google Drive\n",
        "\n",
        "# Alternative: List all ZIP files in the workspace\n",
        "!ls -la /content/*.zip\n",
        "\n",
        "# 📝 The asterisk (*) is a wildcard:\n",
        "# - *.zip means \"any filename ending with .zip\"\n",
        "# - Shows all ZIP files in the /content/ directory\n",
        "# - Useful if you have multiple ZIP files\n",
        "\n",
        "# =============================================================================\n",
        "# 📦 STEP 5: EXTRACT (UNZIP) THE FILE\n",
        "# =============================================================================\n",
        "\n",
        "# Extract the contents of the ZIP file\n",
        "# unzip = command to extract ZIP archives\n",
        "# -o = overwrite existing files without asking for confirmation\n",
        "# /content/dataset.zip = the ZIP file to extract (source)\n",
        "# -d /content/ = destination directory where files will be extracted\n",
        "!unzip -o /content/dataset.zip -d /content/\n",
        "\n",
        "# 📝 Breaking down the flags:\n",
        "# -o (overwrite): If files already exist, replace them without asking\n",
        "# -d (directory): Specifies where to extract the files\n",
        "# Without -d, files would extract to the current directory\n",
        "\n",
        "# 📝 What happens during extraction:\n",
        "# - The ZIP file is opened and read\n",
        "# - All files/folders inside are created in /content/\n",
        "# - You'll see output like \"inflating: file1.txt\" for each extracted file\n",
        "# - The original ZIP file remains unchanged (it's not deleted)\n",
        "\n",
        "# Alternative extraction commands you might see:\n",
        "\n",
        "# Extract without overwriting (asks for confirmation if files exist)\n",
        "# !unzip /content/dataset.zip -d /content/\n",
        "\n",
        "# Just see what's inside the ZIP without extracting\n",
        "# !unzip -l /content/dataset.zip\n",
        "\n",
        "# Test the ZIP file integrity without extracting\n",
        "# !unzip -t /content/dataset.zip\n",
        "\n",
        "# =============================================================================\n",
        "# 📋 STEP 6: CHECK WHAT WAS EXTRACTED\n",
        "# =============================================================================\n",
        "\n",
        "# List all contents of the workspace to see what was extracted\n",
        "!ls -la /content/\n",
        "\n",
        "# 📝 What you'll see:\n",
        "# - All the files and folders that were inside your ZIP\n",
        "# - The original dataset.zip file (still there)\n",
        "# - sample_data/ folder (default Colab folder, ignore this)\n",
        "# - drive/ folder (your mounted Google Drive, ignore this)\n",
        "\n",
        "# More detailed view of extracted contents\n",
        "!ls -laR /content/\n",
        "\n",
        "# 📝 The -R flag means \"recursive\":\n",
        "# - Shows contents of all subdirectories too\n",
        "# - Useful if your ZIP contained nested folders\n",
        "# - Can be overwhelming for large datasets\n",
        "\n",
        "# =============================================================================\n",
        "# 🧹 STEP 7: CLEAN UP (OPTIONAL BUT RECOMMENDED)\n",
        "# =============================================================================\n",
        "\n",
        "# Remove the ZIP file to save space (since we've extracted everything)\n",
        "# rm = remove (delete) command\n",
        "!rm /content/dataset.zip\n",
        "\n",
        "# 📝 Why delete the ZIP file:\n",
        "# - Saves disk space (ZIP file is now redundant)\n",
        "# - Colab has limited storage space\n",
        "# - We have all the contents extracted, so ZIP file is no longer needed\n",
        "# - You can always re-copy from Google Drive if needed\n",
        "\n",
        "# 📝 BE CAREFUL: rm permanently deletes files!\n",
        "# - No \"recycle bin\" in Linux/Colab\n",
        "# - Make sure you've successfully extracted before deleting\n",
        "# - The original ZIP is still safe in your Google Drive\n",
        "\n",
        "# =============================================================================\n",
        "# 🔍 STEP 8: VERIFY EVERYTHING IS WORKING\n",
        "# =============================================================================\n",
        "\n",
        "# Final check - list everything to confirm setup is complete\n",
        "!ls -la /content/\n",
        "\n",
        "# 📝 What you should see now:\n",
        "# - Your extracted files and folders\n",
        "# - NO dataset.zip (if you deleted it in step 7)\n",
        "# - drive/ folder (your Google Drive mount)\n",
        "# - sample_data/ folder (default Colab folder)\n",
        "\n",
        "# Check the total size of your extracted data\n",
        "!du -sh /content/\n",
        "\n",
        "# 📝 du command explanation:\n",
        "# du = disk usage (shows how much space files use)\n",
        "# -s = summary (show total size, not individual files)\n",
        "# -h = human-readable (shows sizes like 1.2GB instead of 1200000000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OnO-cocdO6Z",
        "outputId": "9a0a24c6-33ab-4cd1-dac4-97d177ca720a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "-rw------- 1 root root 140244539 Jul 28 11:24 /content/drive/MyDrive/dataset.zip\n",
            "total 11374048\n",
            "-rw------- 1 root root 1430107833 Oct 17  2022 '[2022] IITP_공간무선충전시스템.zip'\n",
            "-rw------- 1 root root  336431894 Jun 20  2023 '230620_전파자원 최종평가(1분과).zip'\n",
            "-rw------- 1 root root 1495308234 Nov 13  2023 '231113_자기소개 및 수행연구(정영배).mp4'\n",
            "-rw------- 1 root root  243208154 Feb 28  2024 '2. 전파산업(2.28수) 검토위.zip'\n",
            "-rw------- 1 root root  282856984 Mar 29  2024  9분과.zip\n",
            "-rw------- 1 root root   18438664 Apr 12  2018  AESA_F35.mp4\n",
            "-rw------- 1 root root   10220544 Jun 29  2022 'Antenna Basic and Design (220705).ppt'\n",
            "-rw------- 1 root root   10220544 Jun 29  2022 'Antenna Basic and Design (220721).ppt'\n",
            "-rw------- 1 root root   10220544 Jun 29  2022 'Antenna Basic and Design (220726).ppt'\n",
            "-rw------- 1 root root        175 Aug 27  2024 'BK21 2024의 사본.gsheet'\n",
            "drwx------ 2 root root       4096 Oct 17  2019  Classroom\n",
            "drwx------ 2 root root       4096 Jun 24 00:32 'Colab Notebooks'\n",
            "-rw------- 1 root root  140244539 Jul 28 11:24  dataset.zip\n",
            "-rw------- 1 root root   87484588 Mar 21  2024 'IITP_2024_5G 기지국,중계기용 유연박막 필터 일체형 안테나 개발.zip'\n",
            "-rw------- 1 root root   41498343 Feb 15  2019 'Phased Array Antennas.mp4'\n",
            "-rw------- 1 root root      11732 Jul 23 08:26 'Video Frame Extractor'\n",
            "-rw------- 1 root root       7870 Jul 23 08:16 'Video Frame Extractor (1)'\n",
            "drwx------ 2 root root       4096 Jun 24 00:21  YB_Jung_Class\n",
            "-rw------- 1 root root  387199735 Mar  5  2024 '과제중단 특별평가(24.3.5).zip'\n",
            "-rw------- 1 root root 4431743858 Nov 27  2023  데이터.zip\n",
            "-rw------- 1 root root        175 May 28 10:00 '본 보고서에 첨부된 ppt 파일의 그림을 최대한 추가해서 제공해줘.gsheet'\n",
            "-rw------- 1 root root  276095913 Apr  9  2024 '연구논문 및 특허.zip'\n",
            "-rw------- 1 root root        175 May 28 09:45 '연구 시작.gsheet'\n",
            "-rw------- 1 root root  700154198 Apr 22  2024  이의신청_타당성_검토위.zip\n",
            "-rw------- 1 root root        175 Apr 21  2023  일정.gsheet\n",
            "-rw------- 1 root root  106197376 Nov  1  2023 '★최고전문가 소분과 RFP검토위원회 자료_231031(화)-평가위원용PC.zip'\n",
            "-rw------- 1 root root 1639353017 Nov 15  2023  캡스톤_특허출원.zip\n",
            "-rw------- 1 root root        175 May 28 09:51 '파일 변환 및 정보 추출'$'\\n'' (1).gdoc'\n",
            "-rw------- 1 root root        175 May 28 10:01 '파일 변환 및 정보 추출'$'\\n''.gdoc'\n",
            "-rw------- 1 root root        175 Aug  4  2022 '학회지(전자파기술 33-3)_최종본.gdoc'\n",
            "-rw------- 1 root root 140244539 Jul 28 23:59 /content/dataset.zip\n",
            "-rw------- 1 root root 140244539 Jul 28 23:59 /content/dataset.zip\n",
            "Archive:  /content/dataset.zip\n",
            "  inflating: /content/dataset/best.pt  \n",
            "  inflating: /content/dataset/dataset.yaml  \n",
            "  inflating: /content/dataset/train/images/add_image1.png  \n",
            "  inflating: /content/dataset/train/images/add_image10.png  \n",
            "  inflating: /content/dataset/train/images/add_image11.png  \n",
            "  inflating: /content/dataset/train/images/add_image12.png  \n",
            "  inflating: /content/dataset/train/images/add_image13.png  \n",
            "  inflating: /content/dataset/train/images/add_image14.png  \n",
            "  inflating: /content/dataset/train/images/add_image15.png  \n",
            "  inflating: /content/dataset/train/images/add_image16.png  \n",
            "  inflating: /content/dataset/train/images/add_image17.png  \n",
            "  inflating: /content/dataset/train/images/add_image18.png  \n",
            "  inflating: /content/dataset/train/images/add_image19.png  \n",
            "  inflating: /content/dataset/train/images/add_image2.png  \n",
            "  inflating: /content/dataset/train/images/add_image20.png  \n",
            "  inflating: /content/dataset/train/images/add_image21.png  \n",
            "  inflating: /content/dataset/train/images/add_image3.png  \n",
            "  inflating: /content/dataset/train/images/add_image4.png  \n",
            "  inflating: /content/dataset/train/images/add_image5.png  \n",
            "  inflating: /content/dataset/train/images/add_image6.png  \n",
            "  inflating: /content/dataset/train/images/add_image7.png  \n",
            "  inflating: /content/dataset/train/images/add_image8.png  \n",
            "  inflating: /content/dataset/train/images/add_image9.png  \n",
            "  inflating: /content/dataset/train/images/day3_1.png  \n",
            "  inflating: /content/dataset/train/images/day3_10.png  \n",
            "  inflating: /content/dataset/train/images/day3_11.png  \n",
            "  inflating: /content/dataset/train/images/day3_12.png  \n",
            "  inflating: /content/dataset/train/images/day3_13.png  \n",
            "  inflating: /content/dataset/train/images/day3_14.png  \n",
            "  inflating: /content/dataset/train/images/day3_15.png  \n",
            "  inflating: /content/dataset/train/images/day3_16.png  \n",
            "  inflating: /content/dataset/train/images/day3_17.png  \n",
            "  inflating: /content/dataset/train/images/day3_2.png  \n",
            "  inflating: /content/dataset/train/images/day3_3.png  \n",
            "  inflating: /content/dataset/train/images/day3_4.png  \n",
            "  inflating: /content/dataset/train/images/day3_6.png  \n",
            "  inflating: /content/dataset/train/images/day3_7.png  \n",
            "  inflating: /content/dataset/train/images/day3_8.png  \n",
            "  inflating: /content/dataset/train/images/day3__9.png  \n",
            "  inflating: /content/dataset/train/images/day5.png  \n",
            "  inflating: /content/dataset/train/images/lane_image186.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image189.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image190.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image192.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image193.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image194.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image195.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image196.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image242.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image81.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image87.jpg  \n",
            "  inflating: /content/dataset/train/images/lane_image89.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image1.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image10.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image100.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image101.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image102.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image103.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image104.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image105.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image106.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image107.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image108.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image109.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image11.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image110.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image111.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image112.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image113.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image114.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image115.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image116.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image117.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image118.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image119.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image12.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image120.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image121.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image122.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image123.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image124.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image125.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image126.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image127.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image128.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image129.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image13.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image130.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image131.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image132.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image133.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image134.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image135.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image136.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image137.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image138.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image139.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image14.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image140.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image141.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image142.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image143.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image144.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image145.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image146.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image147.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image148.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image149.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image15.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image150.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image151.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image152.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image153.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image154.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image155.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image156.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image157.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image158.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image159.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image16.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image160.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image161.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image162.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image163.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image164.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image165.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image166.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image167.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image168.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image169.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image17.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image170.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image171.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image172.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image173.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image174.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image175.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image176.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image177.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image178.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image179.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image18.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image180.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image181.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image182.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image183.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image184.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image185.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image186.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image187.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image188.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image189.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image19.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image190.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image191.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image192.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image193.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image194.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image195.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image196.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image197.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image198.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image199.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image2.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image20.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image200.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image21.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image213.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image214.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image215.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image216.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image217.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image218.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image219.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image22.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image220.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image221.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image222.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image223.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image224.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image225.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image226.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image227.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image228.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image229.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image23.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image230.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image231.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image232.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image233.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image234.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image235.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image236.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image237.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image238.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image239.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image24.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image240.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image241.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image242.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image243.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image244.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image245.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image246.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image247.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image248.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image249.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image25.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image250.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image251.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image252.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image253.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image254.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image255.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image256.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image257.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image258.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image259.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image26.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image260.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image27.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image28.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image29.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image3.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image30.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image31.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image32.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image33.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image34.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image35.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image36.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image37.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image38.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image39.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image4.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image40.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image41.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image42.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image43.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image44.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image45.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image46.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image47.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image48.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image49.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image5.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image50.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image51.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image52.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image53.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image54.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image55.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image56.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image57.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image58.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image59.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image6.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image60.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image61.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image62.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image63.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image64.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image65.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image66.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image67.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image68.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image69.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image7.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image70.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image71.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image72.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image73.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image74.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image75.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image76.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image77.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image78.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image79.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image8.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image80.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image81.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image82.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image83.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image84.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image85.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image86.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image87.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image88.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image89.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image9.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image90.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image91.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image92.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image93.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image94.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image95.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image96.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image97.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image98.jpg  \n",
            "  inflating: /content/dataset/train/images/train_image99.jpg  \n",
            "  inflating: /content/dataset/train/labels/add_image1.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image10.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image11.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image12.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image13.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image14.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image15.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image16.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image17.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image18.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image19.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image2.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image20.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image21.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image3.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image4.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image5.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image6.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image7.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image8.txt  \n",
            "  inflating: /content/dataset/train/labels/add_image9.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_1.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_10.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_11.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_12.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_13.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_14.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_15.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_16.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_17.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_2.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_3.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_4.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_6.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_7.txt  \n",
            "  inflating: /content/dataset/train/labels/day3_8.txt  \n",
            "  inflating: /content/dataset/train/labels/day3__9.txt  \n",
            "  inflating: /content/dataset/train/labels/day5.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image186.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image189.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image190.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image192.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image193.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image194.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image195.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image196.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image242.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image81.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image87.txt  \n",
            "  inflating: /content/dataset/train/labels/lane_image89.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image1.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image10.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image100.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image101.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image102.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image103.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image104.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image105.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image106.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image107.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image108.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image109.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image11.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image110.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image111.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image112.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image113.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image114.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image115.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image116.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image117.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image118.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image119.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image12.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image120.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image121.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image122.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image123.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image124.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image125.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image126.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image127.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image128.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image129.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image13.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image130.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image131.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image132.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image133.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image134.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image135.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image136.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image137.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image138.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image139.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image14.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image140.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image141.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image142.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image143.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image144.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image145.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image146.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image147.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image148.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image149.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image15.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image150.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image151.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image152.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image153.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image154.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image155.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image156.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image157.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image158.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image159.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image16.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image160.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image161.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image162.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image163.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image164.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image165.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image166.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image167.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image168.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image169.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image17.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image170.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image171.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image172.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image173.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image174.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image175.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image176.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image177.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image178.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image179.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image18.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image180.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image181.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image182.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image183.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image184.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image185.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image186.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image187.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image188.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image189.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image19.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image190.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image191.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image192.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image193.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image194.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image195.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image196.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image197.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image198.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image199.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image2.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image20.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image200.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image21.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image213.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image214.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image215.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image216.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image217.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image218.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image219.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image22.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image220.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image221.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image222.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image223.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image224.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image225.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image226.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image227.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image228.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image229.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image23.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image230.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image231.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image232.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image233.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image234.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image235.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image236.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image237.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image238.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image239.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image24.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image240.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image241.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image242.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image243.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image244.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image245.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image246.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image247.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image248.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image249.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image25.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image250.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image251.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image252.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image253.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image254.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image255.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image256.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image257.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image258.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image259.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image26.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image260.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image27.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image28.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image29.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image3.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image30.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image31.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image32.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image33.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image34.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image35.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image36.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image37.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image38.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image39.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image4.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image40.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image41.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image42.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image43.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image44.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image45.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image46.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image47.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image48.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image49.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image5.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image50.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image51.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image52.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image53.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image54.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image55.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image56.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image57.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image58.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image59.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image6.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image60.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image61.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image62.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image63.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image64.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image65.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image66.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image67.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image68.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image69.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image7.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image70.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image71.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image72.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image73.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image74.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image75.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image76.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image77.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image78.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image79.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image8.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image80.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image81.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image82.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image83.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image84.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image85.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image86.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image87.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image88.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image89.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image9.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image90.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image91.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image92.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image93.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image94.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image95.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image96.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image97.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image98.txt  \n",
            "  inflating: /content/dataset/train/labels/train_image99.txt  \n",
            "  inflating: /content/dataset/valid/images/lane_image244.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image245.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image252.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image253.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image261.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image264.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image268.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image276.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image282.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image285.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image288.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image296.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image305.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image310.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image311.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image316.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image320.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image325.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image330.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image334.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image342.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image360.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image370.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image383.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image386.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image402.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image407.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image411.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image414.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image433.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image435.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image436.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image439.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image444.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image451.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image452.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image457.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image458.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image460.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image461.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image466.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image470.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image472.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image475.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image478.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image488.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image499.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image506.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image515.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image518.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image527.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image537.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image551.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image552.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image563.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image577.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image581.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image597.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image599.jpg  \n",
            "  inflating: /content/dataset/valid/images/lane_image605.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image201.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image202.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image203.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image204.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image205.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image206.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image207.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image208.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image209.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image210.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image211.jpg  \n",
            "  inflating: /content/dataset/valid/images/train_image212.jpg  \n",
            "  inflating: /content/dataset/valid/labels/lane_image244.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image245.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image252.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image253.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image261.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image264.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image268.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image276.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image282.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image285.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image288.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image296.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image305.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image310.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image311.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image316.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image320.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image325.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image330.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image334.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image342.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image360.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image370.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image383.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image386.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image402.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image407.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image411.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image414.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image433.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image435.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image436.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image439.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image444.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image451.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image452.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image457.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image458.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image460.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image461.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image466.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image470.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image472.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image475.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image478.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image488.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image499.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image506.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image515.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image518.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image527.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image537.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image551.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image552.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image563.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image577.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image581.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image597.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image599.txt  \n",
            "  inflating: /content/dataset/valid/labels/lane_image605.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image201.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image202.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image203.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image204.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image205.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image206.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image207.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image208.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image209.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image210.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image211.txt  \n",
            "  inflating: /content/dataset/valid/labels/train_image212.txt  \n",
            "total 136984\n",
            "drwxr-xr-x 1 root root      4096 Jul 28 23:58 .\n",
            "drwxr-xr-x 1 root root      4096 Jul 28 23:42 ..\n",
            "drwxr-xr-x 4 root root      4096 Jul 25 13:38 .config\n",
            "drwxrwxrwx 4 root root      4096 Jul 28 23:59 dataset\n",
            "-rw------- 1 root root 140244539 Jul 28 23:59 dataset.zip\n",
            "drwx------ 6 root root      4096 Jul 28 23:58 drive\n",
            "drwxr-xr-x 1 root root      4096 Jul 25 13:38 sample_data\n",
            "/content/:\n",
            "total 136984\n",
            "drwxr-xr-x 1 root root      4096 Jul 28 23:58 .\n",
            "drwxr-xr-x 1 root root      4096 Jul 28 23:42 ..\n",
            "drwxr-xr-x 4 root root      4096 Jul 25 13:38 .config\n",
            "drwxrwxrwx 4 root root      4096 Jul 28 23:59 dataset\n",
            "-rw------- 1 root root 140244539 Jul 28 23:59 dataset.zip\n",
            "drwx------ 6 root root      4096 Jul 28 23:58 drive\n",
            "drwxr-xr-x 1 root root      4096 Jul 25 13:38 sample_data\n",
            "\n",
            "/content/.config:\n",
            "total 60\n",
            "drwxr-xr-x 4 root root  4096 Jul 25 13:38 .\n",
            "drwxr-xr-x 1 root root  4096 Jul 28 23:58 ..\n",
            "-rw-r--r-- 1 root root     7 Jul 25 13:37 active_config\n",
            "-rw-r--r-- 1 root root     0 Jul 25 13:38 config_sentinel\n",
            "drwxr-xr-x 2 root root  4096 Jul 25 13:37 configurations\n",
            "-rw-r--r-- 1 root root 12288 Jul 25 13:37 default_configs.db\n",
            "-rw------- 1 root root     5 Jan  1  2040 gce\n",
            "-rw-r--r-- 1 root root 12288 Jul 25 13:38 hidden_gcloud_config_universe_descriptor_data_cache_configs.db\n",
            "-rw-r--r-- 1 root root     3 Jul 25 13:37 .last_opt_in_prompt.yaml\n",
            "-rw-r--r-- 1 root root    37 Jul 25 13:37 .last_survey_prompt.yaml\n",
            "-rw-r--r-- 1 root root   135 Jul 25 13:37 .last_update_check.json\n",
            "drwxr-xr-x 3 root root  4096 Jul 25 13:37 logs\n",
            "\n",
            "/content/.config/configurations:\n",
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 Jul 25 13:37 .\n",
            "drwxr-xr-x 4 root root 4096 Jul 25 13:38 ..\n",
            "-rw-r--r-- 1 root root   94 Jul 25 13:38 config_default\n",
            "\n",
            "/content/.config/logs:\n",
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Jul 25 13:37 .\n",
            "drwxr-xr-x 4 root root 4096 Jul 25 13:38 ..\n",
            "drwxr-xr-x 2 root root 4096 Jul 25 13:38 2025.07.25\n",
            "\n",
            "/content/.config/logs/2025.07.25:\n",
            "total 84\n",
            "drwxr-xr-x 2 root root  4096 Jul 25 13:38 .\n",
            "drwxr-xr-x 3 root root  4096 Jul 25 13:37 ..\n",
            "-rw-r--r-- 1 root root 48829 Jul 25 13:37 13.37.20.353939.log\n",
            "-rw-r--r-- 1 root root   465 Jul 25 13:37 13.37.44.605639.log\n",
            "-rw-r--r-- 1 root root 11764 Jul 25 13:38 13.37.52.780013.log\n",
            "-rw-r--r-- 1 root root   465 Jul 25 13:38 13.37.54.964036.log\n",
            "-rw-r--r-- 1 root root   704 Jul 25 13:38 13.38.03.364849.log\n",
            "-rw-r--r-- 1 root root   699 Jul 25 13:38 13.38.04.049484.log\n",
            "\n",
            "/content/dataset:\n",
            "total 6132\n",
            "drwxrwxrwx 4 root root    4096 Jul 28 23:59 .\n",
            "drwxr-xr-x 1 root root    4096 Jul 28 23:58 ..\n",
            "-rw-rw-rw- 1 root root 6257635 Jul 24 05:20 best.pt\n",
            "-rw-rw-rw- 1 root root      95 Jul 24 05:20 dataset.yaml\n",
            "drwxrwxrwx 4 root root    4096 Jul 23 12:00 train\n",
            "drwxrwxrwx 4 root root    4096 Jul 23 12:00 valid\n",
            "\n",
            "/content/dataset/train:\n",
            "total 36\n",
            "drwxrwxrwx 4 root root  4096 Jul 23 12:00 .\n",
            "drwxrwxrwx 4 root root  4096 Jul 28 23:59 ..\n",
            "drwxrwxrwx 2 root root 12288 Jul 28 23:59 images\n",
            "drwxrwxrwx 2 root root 16384 Jul 28 23:59 labels\n",
            "\n",
            "/content/dataset/train/images:\n",
            "total 112212\n",
            "drwxrwxrwx 2 root root   12288 Jul 28 23:59 .\n",
            "drwxrwxrwx 4 root root    4096 Jul 23 12:00 ..\n",
            "-rw-rw-rw- 1 root root  151503 Jul 23 11:31 add_image10.png\n",
            "-rw-rw-rw- 1 root root  227740 Jul 23 11:31 add_image11.png\n",
            "-rw-rw-rw- 1 root root  147288 Jul 23 11:31 add_image12.png\n",
            "-rw-rw-rw- 1 root root  203992 Jul 23 11:31 add_image13.png\n",
            "-rw-rw-rw- 1 root root  183763 Jul 23 11:32 add_image14.png\n",
            "-rw-rw-rw- 1 root root  735653 Jul 23 11:32 add_image15.png\n",
            "-rw-rw-rw- 1 root root  583041 Jul 23 11:32 add_image16.png\n",
            "-rw-rw-rw- 1 root root  798012 Jul 23 11:34 add_image17.png\n",
            "-rw-rw-rw- 1 root root  849076 Jul 23 11:34 add_image18.png\n",
            "-rw-rw-rw- 1 root root  836448 Jul 23 11:34 add_image19.png\n",
            "-rw-rw-rw- 1 root root  306098 Jul 23 11:29 add_image1.png\n",
            "-rw-rw-rw- 1 root root  991155 Jul 23 11:35 add_image20.png\n",
            "-rw-rw-rw- 1 root root  568696 Jul 23 11:35 add_image21.png\n",
            "-rw-rw-rw- 1 root root  130052 Jul 23 11:29 add_image2.png\n",
            "-rw-rw-rw- 1 root root  367913 Jul 23 11:29 add_image3.png\n",
            "-rw-rw-rw- 1 root root  280162 Jul 23 11:30 add_image4.png\n",
            "-rw-rw-rw- 1 root root  255297 Jul 23 11:30 add_image5.png\n",
            "-rw-rw-rw- 1 root root  126741 Jul 23 11:30 add_image6.png\n",
            "-rw-rw-rw- 1 root root  170325 Jul 23 11:30 add_image7.png\n",
            "-rw-rw-rw- 1 root root  293281 Jul 23 11:31 add_image8.png\n",
            "-rw-rw-rw- 1 root root  199888 Jul 23 11:31 add_image9.png\n",
            "-rw-rw-rw- 1 root root 1321375 Jul 24 00:11 day3_10.png\n",
            "-rw-rw-rw- 1 root root 1131677 Jul 24 00:11 day3_11.png\n",
            "-rw-rw-rw- 1 root root  973299 Jul 24 00:12 day3_12.png\n",
            "-rw-rw-rw- 1 root root  936635 Jul 24 00:16 day3_13.png\n",
            "-rw-rw-rw- 1 root root  795789 Jul 24 00:15 day3_14.png\n",
            "-rw-rw-rw- 1 root root 1311745 Jul 24 00:14 day3_15.png\n",
            "-rw-rw-rw- 1 root root  760604 Jul 24 00:13 day3_16.png\n",
            "-rw-rw-rw- 1 root root  854960 Jul 24 00:12 day3_17.png\n",
            "-rw-rw-rw- 1 root root  750575 Jul 23 23:56 day3_1.png\n",
            "-rw-rw-rw- 1 root root  974603 Jul 23 23:56 day3_2.png\n",
            "-rw-rw-rw- 1 root root 1119212 Jul 23 23:56 day3_3.png\n",
            "-rw-rw-rw- 1 root root  839558 Jul 23 23:57 day3_4.png\n",
            "-rw-rw-rw- 1 root root 1149289 Jul 23 23:59 day3_6.png\n",
            "-rw-rw-rw- 1 root root 1050905 Jul 24 00:10 day3_7.png\n",
            "-rw-rw-rw- 1 root root 1070284 Jul 24 00:10 day3_8.png\n",
            "-rw-rw-rw- 1 root root 1210642 Jul 24 00:11 day3__9.png\n",
            "-rw-rw-rw- 1 root root  795417 Jul 23 23:58 day5.png\n",
            "-rw-rw-rw- 1 root root  433915 Jul 21 11:04 lane_image186.jpg\n",
            "-rw-rw-rw- 1 root root  469947 Jul 21 11:04 lane_image189.jpg\n",
            "-rw-rw-rw- 1 root root  391150 Jul 21 11:04 lane_image190.jpg\n",
            "-rw-rw-rw- 1 root root  425599 Jul 21 11:04 lane_image192.jpg\n",
            "-rw-rw-rw- 1 root root  432869 Jul 21 11:04 lane_image193.jpg\n",
            "-rw-rw-rw- 1 root root  464975 Jul 21 11:04 lane_image194.jpg\n",
            "-rw-rw-rw- 1 root root  429230 Jul 21 11:04 lane_image195.jpg\n",
            "-rw-rw-rw- 1 root root  443486 Jul 21 11:04 lane_image196.jpg\n",
            "-rw-rw-rw- 1 root root  287608 Jul 21 11:04 lane_image242.jpg\n",
            "-rw-rw-rw- 1 root root  308288 Jul 21 11:04 lane_image81.jpg\n",
            "-rw-rw-rw- 1 root root  171390 Jul 21 11:04 lane_image87.jpg\n",
            "-rw-rw-rw- 1 root root  316574 Jul 21 11:04 lane_image89.jpg\n",
            "-rw-rw-rw- 1 root root  320252 Jul 21 11:04 train_image100.jpg\n",
            "-rw-rw-rw- 1 root root  353635 Jul 21 11:04 train_image101.jpg\n",
            "-rw-rw-rw- 1 root root  301569 Jul 21 11:04 train_image102.jpg\n",
            "-rw-rw-rw- 1 root root  361723 Jul 21 11:04 train_image103.jpg\n",
            "-rw-rw-rw- 1 root root  297245 Jul 21 11:04 train_image104.jpg\n",
            "-rw-rw-rw- 1 root root  300909 Jul 21 11:04 train_image105.jpg\n",
            "-rw-rw-rw- 1 root root  336937 Jul 21 11:04 train_image106.jpg\n",
            "-rw-rw-rw- 1 root root  367494 Jul 21 11:04 train_image107.jpg\n",
            "-rw-rw-rw- 1 root root  360611 Jul 21 11:04 train_image108.jpg\n",
            "-rw-rw-rw- 1 root root  289012 Jul 21 11:04 train_image109.jpg\n",
            "-rw-rw-rw- 1 root root  347548 Jul 21 11:04 train_image10.jpg\n",
            "-rw-rw-rw- 1 root root  275908 Jul 21 11:04 train_image110.jpg\n",
            "-rw-rw-rw- 1 root root  296483 Jul 21 11:04 train_image111.jpg\n",
            "-rw-rw-rw- 1 root root  293800 Jul 21 11:04 train_image112.jpg\n",
            "-rw-rw-rw- 1 root root  304621 Jul 21 11:04 train_image113.jpg\n",
            "-rw-rw-rw- 1 root root  538661 Dec 12  2023 train_image114.jpg\n",
            "-rw-rw-rw- 1 root root  375339 Jul 21 11:04 train_image115.jpg\n",
            "-rw-rw-rw- 1 root root  278546 Jul 21 11:04 train_image116.jpg\n",
            "-rw-rw-rw- 1 root root  276725 Jul 21 11:04 train_image117.jpg\n",
            "-rw-rw-rw- 1 root root  280866 Jul 21 11:04 train_image118.jpg\n",
            "-rw-rw-rw- 1 root root  276316 Jul 21 11:04 train_image119.jpg\n",
            "-rw-rw-rw- 1 root root  352545 Jul 21 11:04 train_image11.jpg\n",
            "-rw-rw-rw- 1 root root  282574 Jul 21 11:04 train_image120.jpg\n",
            "-rw-rw-rw- 1 root root  333503 Jul 21 11:04 train_image121.jpg\n",
            "-rw-rw-rw- 1 root root  293234 Jul 21 11:04 train_image122.jpg\n",
            "-rw-rw-rw- 1 root root  291370 Jul 21 11:04 train_image123.jpg\n",
            "-rw-rw-rw- 1 root root  303825 Jul 21 11:04 train_image124.jpg\n",
            "-rw-rw-rw- 1 root root  329160 Jul 21 11:04 train_image125.jpg\n",
            "-rw-rw-rw- 1 root root  283895 Jul 21 11:04 train_image126.jpg\n",
            "-rw-rw-rw- 1 root root  364306 Jul 21 11:04 train_image127.jpg\n",
            "-rw-rw-rw- 1 root root  284711 Jul 21 11:04 train_image128.jpg\n",
            "-rw-rw-rw- 1 root root  294390 Jul 21 11:04 train_image129.jpg\n",
            "-rw-rw-rw- 1 root root  269142 Jul 21 11:04 train_image12.jpg\n",
            "-rw-rw-rw- 1 root root  307164 Jul 21 11:04 train_image130.jpg\n",
            "-rw-rw-rw- 1 root root  335446 Jul 21 11:04 train_image131.jpg\n",
            "-rw-rw-rw- 1 root root  342938 Jul 21 11:04 train_image132.jpg\n",
            "-rw-rw-rw- 1 root root  295048 Jul 21 11:04 train_image133.jpg\n",
            "-rw-rw-rw- 1 root root  280079 Jul 21 11:04 train_image134.jpg\n",
            "-rw-rw-rw- 1 root root  295203 Jul 21 11:04 train_image135.jpg\n",
            "-rw-rw-rw- 1 root root  373081 Jul 21 11:04 train_image136.jpg\n",
            "-rw-rw-rw- 1 root root  289763 Jul 21 11:04 train_image137.jpg\n",
            "-rw-rw-rw- 1 root root  272668 Jul 21 11:04 train_image138.jpg\n",
            "-rw-rw-rw- 1 root root  263684 Jul 21 11:04 train_image139.jpg\n",
            "-rw-rw-rw- 1 root root  349170 Jul 21 11:04 train_image13.jpg\n",
            "-rw-rw-rw- 1 root root  353989 Jul 21 11:04 train_image140.jpg\n",
            "-rw-rw-rw- 1 root root  306215 Jul 21 11:04 train_image141.jpg\n",
            "-rw-rw-rw- 1 root root  306374 Jul 21 11:04 train_image142.jpg\n",
            "-rw-rw-rw- 1 root root  376230 Jul 21 11:04 train_image143.jpg\n",
            "-rw-rw-rw- 1 root root  427110 Jul 21 11:04 train_image144.jpg\n",
            "-rw-rw-rw- 1 root root  407895 Jul 21 11:04 train_image145.jpg\n",
            "-rw-rw-rw- 1 root root  378500 Jul 21 11:04 train_image146.jpg\n",
            "-rw-rw-rw- 1 root root  432629 Jul 21 11:04 train_image147.jpg\n",
            "-rw-rw-rw- 1 root root  465396 Jul 21 11:04 train_image148.jpg\n",
            "-rw-rw-rw- 1 root root  348819 Jul 21 11:04 train_image149.jpg\n",
            "-rw-rw-rw- 1 root root  258247 Jul 21 11:04 train_image14.jpg\n",
            "-rw-rw-rw- 1 root root  436120 Jul 21 11:04 train_image150.jpg\n",
            "-rw-rw-rw- 1 root root  410251 Jul 21 11:04 train_image151.jpg\n",
            "-rw-rw-rw- 1 root root  369627 Jul 21 11:04 train_image152.jpg\n",
            "-rw-rw-rw- 1 root root  442174 Jul 21 11:04 train_image153.jpg\n",
            "-rw-rw-rw- 1 root root  407193 Jul 21 11:04 train_image154.jpg\n",
            "-rw-rw-rw- 1 root root  433036 Jul 21 11:04 train_image155.jpg\n",
            "-rw-rw-rw- 1 root root  484599 Jul 21 11:04 train_image156.jpg\n",
            "-rw-rw-rw- 1 root root  460501 Jul 21 11:04 train_image157.jpg\n",
            "-rw-rw-rw- 1 root root  479010 Jul 21 11:04 train_image158.jpg\n",
            "-rw-rw-rw- 1 root root  456129 Jul 21 11:04 train_image159.jpg\n",
            "-rw-rw-rw- 1 root root  601419 Dec 12  2023 train_image15.jpg\n",
            "-rw-rw-rw- 1 root root  354502 Jul 21 11:04 train_image160.jpg\n",
            "-rw-rw-rw- 1 root root  361139 Jul 21 11:04 train_image161.jpg\n",
            "-rw-rw-rw- 1 root root  371376 Jul 21 11:04 train_image162.jpg\n",
            "-rw-rw-rw- 1 root root  340148 Jul 21 11:04 train_image163.jpg\n",
            "-rw-rw-rw- 1 root root  357637 Jul 21 11:04 train_image164.jpg\n",
            "-rw-rw-rw- 1 root root  396512 Jul 21 11:04 train_image165.jpg\n",
            "-rw-rw-rw- 1 root root  339672 Jul 21 11:04 train_image166.jpg\n",
            "-rw-rw-rw- 1 root root  307034 Jul 21 11:04 train_image167.jpg\n",
            "-rw-rw-rw- 1 root root  364761 Jul 21 11:04 train_image168.jpg\n",
            "-rw-rw-rw- 1 root root  335345 Jul 21 11:04 train_image169.jpg\n",
            "-rw-rw-rw- 1 root root  324314 Jul 21 11:04 train_image16.jpg\n",
            "-rw-rw-rw- 1 root root  347620 Jul 21 11:04 train_image170.jpg\n",
            "-rw-rw-rw- 1 root root  362510 Jul 21 11:04 train_image171.jpg\n",
            "-rw-rw-rw- 1 root root  340617 Jul 21 11:04 train_image172.jpg\n",
            "-rw-rw-rw- 1 root root  308716 Jul 21 11:04 train_image173.jpg\n",
            "-rw-rw-rw- 1 root root  225429 Jul 21 11:04 train_image174.jpg\n",
            "-rw-rw-rw- 1 root root  302867 Jul 21 11:04 train_image175.jpg\n",
            "-rw-rw-rw- 1 root root  356816 Jul 21 11:04 train_image176.jpg\n",
            "-rw-rw-rw- 1 root root  391537 Jul 21 11:04 train_image177.jpg\n",
            "-rw-rw-rw- 1 root root  375466 Jul 21 11:04 train_image178.jpg\n",
            "-rw-rw-rw- 1 root root  360625 Jul 21 11:04 train_image179.jpg\n",
            "-rw-rw-rw- 1 root root  237135 Jul 21 11:04 train_image17.jpg\n",
            "-rw-rw-rw- 1 root root  310324 Jul 21 11:04 train_image180.jpg\n",
            "-rw-rw-rw- 1 root root  329209 Jul 21 11:04 train_image181.jpg\n",
            "-rw-rw-rw- 1 root root  342198 Jul 21 11:04 train_image182.jpg\n",
            "-rw-rw-rw- 1 root root  283163 Jul 21 11:04 train_image183.jpg\n",
            "-rw-rw-rw- 1 root root  334451 Jul 21 11:04 train_image184.jpg\n",
            "-rw-rw-rw- 1 root root  340716 Jul 21 11:04 train_image185.jpg\n",
            "-rw-rw-rw- 1 root root  226647 Jul 21 11:04 train_image186.jpg\n",
            "-rw-rw-rw- 1 root root  321685 Jul 21 11:04 train_image187.jpg\n",
            "-rw-rw-rw- 1 root root  287474 Jul 21 11:04 train_image188.jpg\n",
            "-rw-rw-rw- 1 root root  283172 Jul 21 11:04 train_image189.jpg\n",
            "-rw-rw-rw- 1 root root  233015 Jul 21 11:04 train_image18.jpg\n",
            "-rw-rw-rw- 1 root root  293681 Jul 21 11:04 train_image190.jpg\n",
            "-rw-rw-rw- 1 root root  287669 Jul 21 11:04 train_image191.jpg\n",
            "-rw-rw-rw- 1 root root  288764 Jul 21 11:04 train_image192.jpg\n",
            "-rw-rw-rw- 1 root root  328606 Jul 21 11:04 train_image193.jpg\n",
            "-rw-rw-rw- 1 root root  423541 Jul 21 11:04 train_image194.jpg\n",
            "-rw-rw-rw- 1 root root  266279 Jul 21 11:04 train_image195.jpg\n",
            "-rw-rw-rw- 1 root root  265360 Jul 21 11:04 train_image196.jpg\n",
            "-rw-rw-rw- 1 root root  293487 Jul 21 11:04 train_image197.jpg\n",
            "-rw-rw-rw- 1 root root  256563 Jul 21 11:04 train_image198.jpg\n",
            "-rw-rw-rw- 1 root root  255582 Jul 21 11:04 train_image199.jpg\n",
            "-rw-rw-rw- 1 root root  267104 Jul 21 11:04 train_image19.jpg\n",
            "-rw-rw-rw- 1 root root  486520 Jul 21 05:28 train_image1.jpg\n",
            "-rw-rw-rw- 1 root root  297581 Jul 21 11:04 train_image200.jpg\n",
            "-rw-rw-rw- 1 root root  266675 Jul 21 11:04 train_image20.jpg\n",
            "-rw-rw-rw- 1 root root  417779 Jul 21 11:04 train_image213.jpg\n",
            "-rw-rw-rw- 1 root root  283975 Jul 21 11:04 train_image214.jpg\n",
            "-rw-rw-rw- 1 root root  296305 Jul 21 11:04 train_image215.jpg\n",
            "-rw-rw-rw- 1 root root  306692 Jul 21 11:04 train_image216.jpg\n",
            "-rw-rw-rw- 1 root root  311488 Jul 21 11:04 train_image217.jpg\n",
            "-rw-rw-rw- 1 root root  322859 Jul 21 11:04 train_image218.jpg\n",
            "-rw-rw-rw- 1 root root  340194 Jul 21 11:04 train_image219.jpg\n",
            "-rw-rw-rw- 1 root root  371025 Jul 21 11:04 train_image21.jpg\n",
            "-rw-rw-rw- 1 root root  300230 Jul 21 11:04 train_image220.jpg\n",
            "-rw-rw-rw- 1 root root  322565 Jul 21 11:04 train_image221.jpg\n",
            "-rw-rw-rw- 1 root root  427015 Jul 21 11:04 train_image222.jpg\n",
            "-rw-rw-rw- 1 root root  323548 Jul 21 11:04 train_image223.jpg\n",
            "-rw-rw-rw- 1 root root  331204 Jul 21 11:04 train_image224.jpg\n",
            "-rw-rw-rw- 1 root root  328899 Jul 21 11:04 train_image225.jpg\n",
            "-rw-rw-rw- 1 root root  348597 Jul 21 11:04 train_image226.jpg\n",
            "-rw-rw-rw- 1 root root  326047 Jul 21 11:04 train_image227.jpg\n",
            "-rw-rw-rw- 1 root root  340409 Jul 21 11:04 train_image228.jpg\n",
            "-rw-rw-rw- 1 root root  347124 Jul 21 11:04 train_image229.jpg\n",
            "-rw-rw-rw- 1 root root  320467 Jul 21 11:04 train_image22.jpg\n",
            "-rw-rw-rw- 1 root root  341659 Jul 21 11:04 train_image230.jpg\n",
            "-rw-rw-rw- 1 root root  355643 Jul 21 11:04 train_image231.jpg\n",
            "-rw-rw-rw- 1 root root  372388 Jul 21 11:04 train_image232.jpg\n",
            "-rw-rw-rw- 1 root root  372009 Jul 21 11:04 train_image233.jpg\n",
            "-rw-rw-rw- 1 root root  419595 Jul 21 11:04 train_image234.jpg\n",
            "-rw-rw-rw- 1 root root  195166 Jul 21 11:04 train_image235.jpg\n",
            "-rw-rw-rw- 1 root root  341316 Jul 21 11:04 train_image236.jpg\n",
            "-rw-rw-rw- 1 root root  308412 Jul 21 11:04 train_image237.jpg\n",
            "-rw-rw-rw- 1 root root  335479 Jul 21 11:04 train_image238.jpg\n",
            "-rw-rw-rw- 1 root root  378409 Jul 21 11:04 train_image239.jpg\n",
            "-rw-rw-rw- 1 root root  291652 Jul 21 11:04 train_image23.jpg\n",
            "-rw-rw-rw- 1 root root  335053 Jul 21 11:04 train_image240.jpg\n",
            "-rw-rw-rw- 1 root root  336114 Jul 21 11:04 train_image241.jpg\n",
            "-rw-rw-rw- 1 root root  351960 Jul 21 11:04 train_image242.jpg\n",
            "-rw-rw-rw- 1 root root  326993 Jul 21 11:04 train_image243.jpg\n",
            "-rw-rw-rw- 1 root root  328047 Jul 21 11:04 train_image244.jpg\n",
            "-rw-rw-rw- 1 root root  335022 Jul 21 11:04 train_image245.jpg\n",
            "-rw-rw-rw- 1 root root  294029 Jul 21 11:04 train_image246.jpg\n",
            "-rw-rw-rw- 1 root root  327918 Jul 21 11:04 train_image247.jpg\n",
            "-rw-rw-rw- 1 root root  316592 Jul 21 11:04 train_image248.jpg\n",
            "-rw-rw-rw- 1 root root  308679 Jul 21 11:04 train_image249.jpg\n",
            "-rw-rw-rw- 1 root root  292218 Jul 21 11:04 train_image24.jpg\n",
            "-rw-rw-rw- 1 root root  304966 Jul 21 11:04 train_image250.jpg\n",
            "-rw-rw-rw- 1 root root  321769 Jul 21 11:04 train_image251.jpg\n",
            "-rw-rw-rw- 1 root root  339009 Jul 21 11:04 train_image252.jpg\n",
            "-rw-rw-rw- 1 root root  385924 Jul 21 11:04 train_image253.jpg\n",
            "-rw-rw-rw- 1 root root  278178 Jul 21 11:04 train_image254.jpg\n",
            "-rw-rw-rw- 1 root root  392042 Jul 21 11:04 train_image255.jpg\n",
            "-rw-rw-rw- 1 root root  322303 Jul 21 11:04 train_image256.jpg\n",
            "-rw-rw-rw- 1 root root  347597 Jul 21 11:04 train_image257.jpg\n",
            "-rw-rw-rw- 1 root root  294587 Jul 21 11:04 train_image258.jpg\n",
            "-rw-rw-rw- 1 root root  282199 Jul 21 11:04 train_image259.jpg\n",
            "-rw-rw-rw- 1 root root  242266 Jul 21 11:04 train_image25.jpg\n",
            "-rw-rw-rw- 1 root root  299741 Jul 21 11:04 train_image260.jpg\n",
            "-rw-rw-rw- 1 root root  386067 Jul 21 11:04 train_image26.jpg\n",
            "-rw-rw-rw- 1 root root  237595 Jul 21 11:04 train_image27.jpg\n",
            "-rw-rw-rw- 1 root root  208516 Jul 21 11:04 train_image28.jpg\n",
            "-rw-rw-rw- 1 root root  198310 Jul 21 11:04 train_image29.jpg\n",
            "-rw-rw-rw- 1 root root  289354 Jul 21 11:04 train_image2.jpg\n",
            "-rw-rw-rw- 1 root root  215695 Jul 21 11:04 train_image30.jpg\n",
            "-rw-rw-rw- 1 root root  239027 Jul 21 11:04 train_image31.jpg\n",
            "-rw-rw-rw- 1 root root  327838 Jul 21 11:04 train_image32.jpg\n",
            "-rw-rw-rw- 1 root root  232682 Jul 21 11:04 train_image33.jpg\n",
            "-rw-rw-rw- 1 root root  227207 Jul 21 11:04 train_image34.jpg\n",
            "-rw-rw-rw- 1 root root  238276 Jul 21 11:04 train_image35.jpg\n",
            "-rw-rw-rw- 1 root root  241638 Jul 21 11:04 train_image36.jpg\n",
            "-rw-rw-rw- 1 root root  276690 Jul 21 11:04 train_image37.jpg\n",
            "-rw-rw-rw- 1 root root  381521 Jul 21 11:04 train_image38.jpg\n",
            "-rw-rw-rw- 1 root root  325581 Jul 21 11:04 train_image39.jpg\n",
            "-rw-rw-rw- 1 root root  251997 Jul 21 11:04 train_image3.jpg\n",
            "-rw-rw-rw- 1 root root  366463 Jul 21 11:04 train_image40.jpg\n",
            "-rw-rw-rw- 1 root root  294938 Jul 21 11:04 train_image41.jpg\n",
            "-rw-rw-rw- 1 root root  261973 Jul 21 11:04 train_image42.jpg\n",
            "-rw-rw-rw- 1 root root  287835 Jul 21 11:04 train_image43.jpg\n",
            "-rw-rw-rw- 1 root root  307590 Jul 21 11:04 train_image44.jpg\n",
            "-rw-rw-rw- 1 root root  378615 Jul 21 11:04 train_image45.jpg\n",
            "-rw-rw-rw- 1 root root  365998 Jul 21 11:04 train_image46.jpg\n",
            "-rw-rw-rw- 1 root root  386774 Jul 21 11:04 train_image47.jpg\n",
            "-rw-rw-rw- 1 root root  324329 Jul 21 11:04 train_image48.jpg\n",
            "-rw-rw-rw- 1 root root  303997 Jul 21 11:04 train_image49.jpg\n",
            "-rw-rw-rw- 1 root root  334019 Jul 21 11:04 train_image4.jpg\n",
            "-rw-rw-rw- 1 root root  282636 Jul 21 11:04 train_image50.jpg\n",
            "-rw-rw-rw- 1 root root  381591 Jul 21 11:04 train_image51.jpg\n",
            "-rw-rw-rw- 1 root root  264797 Jul 21 11:04 train_image52.jpg\n",
            "-rw-rw-rw- 1 root root  261069 Jul 21 11:04 train_image53.jpg\n",
            "-rw-rw-rw- 1 root root  404474 Jul 21 11:04 train_image54.jpg\n",
            "-rw-rw-rw- 1 root root  397276 Jul 21 11:04 train_image55.jpg\n",
            "-rw-rw-rw- 1 root root  387833 Jul 21 11:04 train_image56.jpg\n",
            "-rw-rw-rw- 1 root root  435755 Jul 21 11:04 train_image57.jpg\n",
            "-rw-rw-rw- 1 root root  476176 Jul 21 11:04 train_image58.jpg\n",
            "-rw-rw-rw- 1 root root  451841 Jul 21 11:04 train_image59.jpg\n",
            "-rw-rw-rw- 1 root root  304082 Jul 21 11:04 train_image5.jpg\n",
            "-rw-rw-rw- 1 root root  465798 Jul 21 11:04 train_image60.jpg\n",
            "-rw-rw-rw- 1 root root  485597 Jul 21 11:04 train_image61.jpg\n",
            "-rw-rw-rw- 1 root root  482060 Jul 21 11:04 train_image62.jpg\n",
            "-rw-rw-rw- 1 root root  437199 Jul 21 11:04 train_image63.jpg\n",
            "-rw-rw-rw- 1 root root  401357 Jul 21 11:04 train_image64.jpg\n",
            "-rw-rw-rw- 1 root root  395857 Jul 21 11:04 train_image65.jpg\n",
            "-rw-rw-rw- 1 root root  388500 Jul 21 11:04 train_image66.jpg\n",
            "-rw-rw-rw- 1 root root  316888 Jul 21 11:04 train_image67.jpg\n",
            "-rw-rw-rw- 1 root root  393631 Jul 21 11:04 train_image68.jpg\n",
            "-rw-rw-rw- 1 root root  396195 Jul 21 11:04 train_image69.jpg\n",
            "-rw-rw-rw- 1 root root  370233 Jul 21 11:04 train_image6.jpg\n",
            "-rw-rw-rw- 1 root root  393559 Jul 21 11:04 train_image70.jpg\n",
            "-rw-rw-rw- 1 root root  444667 Jul 21 11:04 train_image71.jpg\n",
            "-rw-rw-rw- 1 root root  383318 Jul 21 11:04 train_image72.jpg\n",
            "-rw-rw-rw- 1 root root  372862 Jul 21 11:04 train_image73.jpg\n",
            "-rw-rw-rw- 1 root root  391600 Jul 21 11:04 train_image74.jpg\n",
            "-rw-rw-rw- 1 root root  376814 Jul 21 11:04 train_image75.jpg\n",
            "-rw-rw-rw- 1 root root  372891 Jul 21 11:04 train_image76.jpg\n",
            "-rw-rw-rw- 1 root root  378907 Jul 21 11:04 train_image77.jpg\n",
            "-rw-rw-rw- 1 root root  385174 Jul 21 11:04 train_image78.jpg\n",
            "-rw-rw-rw- 1 root root  382605 Jul 21 11:04 train_image79.jpg\n",
            "-rw-rw-rw- 1 root root  303050 Jul 21 11:04 train_image7.jpg\n",
            "-rw-rw-rw- 1 root root  422393 Jul 21 11:04 train_image80.jpg\n",
            "-rw-rw-rw- 1 root root  428742 Jul 21 11:04 train_image81.jpg\n",
            "-rw-rw-rw- 1 root root  432921 Jul 21 11:04 train_image82.jpg\n",
            "-rw-rw-rw- 1 root root  296265 Jul 21 11:04 train_image83.jpg\n",
            "-rw-rw-rw- 1 root root  421264 Jul 21 11:04 train_image84.jpg\n",
            "-rw-rw-rw- 1 root root  436074 Jul 21 11:04 train_image85.jpg\n",
            "-rw-rw-rw- 1 root root  462885 Jul 21 11:04 train_image86.jpg\n",
            "-rw-rw-rw- 1 root root  431578 Jul 21 11:04 train_image87.jpg\n",
            "-rw-rw-rw- 1 root root  326308 Jul 21 11:04 train_image88.jpg\n",
            "-rw-rw-rw- 1 root root  323850 Jul 21 11:04 train_image89.jpg\n",
            "-rw-rw-rw- 1 root root  299885 Jul 21 11:04 train_image8.jpg\n",
            "-rw-rw-rw- 1 root root  413473 Jul 21 11:04 train_image90.jpg\n",
            "-rw-rw-rw- 1 root root  379278 Jul 21 11:04 train_image91.jpg\n",
            "-rw-rw-rw- 1 root root  392678 Jul 21 11:04 train_image92.jpg\n",
            "-rw-rw-rw- 1 root root  392645 Jul 21 11:04 train_image93.jpg\n",
            "-rw-rw-rw- 1 root root  386431 Jul 21 11:04 train_image94.jpg\n",
            "-rw-rw-rw- 1 root root  316431 Jul 21 11:04 train_image95.jpg\n",
            "-rw-rw-rw- 1 root root  306384 Jul 21 11:04 train_image96.jpg\n",
            "-rw-rw-rw- 1 root root  344481 Jul 21 11:04 train_image97.jpg\n",
            "-rw-rw-rw- 1 root root  319701 Jul 21 11:04 train_image98.jpg\n",
            "-rw-rw-rw- 1 root root  310723 Jul 21 11:04 train_image99.jpg\n",
            "-rw-rw-rw- 1 root root  322328 Jul 21 11:04 train_image9.jpg\n",
            "\n",
            "/content/dataset/train/labels:\n",
            "total 1212\n",
            "drwxrwxrwx 2 root root 16384 Jul 28 23:59 .\n",
            "drwxrwxrwx 4 root root  4096 Jul 23 12:00 ..\n",
            "-rw-rw-rw- 1 root root   531 Jul 23 11:50 add_image10.txt\n",
            "-rw-rw-rw- 1 root root   569 Jul 23 11:50 add_image11.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 11:50 add_image12.txt\n",
            "-rw-rw-rw- 1 root root   531 Jul 23 11:50 add_image13.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 11:50 add_image14.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 11:50 add_image15.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 11:50 add_image16.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 11:50 add_image17.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 11:50 add_image18.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 11:50 add_image19.txt\n",
            "-rw-rw-rw- 1 root root   645 Jul 23 11:50 add_image1.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 11:50 add_image20.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 11:50 add_image21.txt\n",
            "-rw-rw-rw- 1 root root   531 Jul 23 11:50 add_image2.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 11:50 add_image3.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 11:50 add_image4.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 11:50 add_image5.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 11:50 add_image6.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 11:50 add_image7.txt\n",
            "-rw-rw-rw- 1 root root   531 Jul 23 11:50 add_image8.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 11:50 add_image9.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 24 00:24 day3_10.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 24 00:24 day3_11.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 24 00:24 day3_12.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 24 00:24 day3_13.txt\n",
            "-rw-rw-rw- 1 root root   607 Jul 24 00:24 day3_14.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 24 00:24 day3_15.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 24 00:24 day3_16.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 24 00:24 day3_17.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 24 00:04 day3_1.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 24 00:04 day3_2.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 24 00:04 day3_3.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 24 00:04 day3_4.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 24 00:04 day3_6.txt\n",
            "-rw-rw-rw- 1 root root   531 Jul 24 00:24 day3_7.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 24 00:24 day3_8.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 24 00:24 day3__9.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 24 00:04 day5.txt\n",
            "-rw-rw-rw- 1 root root   113 Jul 22 12:02 lane_image186.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 22 12:02 lane_image189.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 22 12:02 lane_image190.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 22 12:02 lane_image192.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 22 12:02 lane_image193.txt\n",
            "-rw-rw-rw- 1 root root   113 Jul 22 12:02 lane_image194.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 22 12:02 lane_image195.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 22 12:02 lane_image196.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 22 12:02 lane_image242.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 22 12:27 lane_image81.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 22 12:27 lane_image87.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 22 12:27 lane_image89.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:58 train_image100.txt\n",
            "-rw-rw-rw- 1 root root   683 Jul 23 01:47 train_image101.txt\n",
            "-rw-rw-rw- 1 root root   569 Jul 23 01:47 train_image102.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 01:47 train_image103.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image104.txt\n",
            "-rw-rw-rw- 1 root root   531 Jul 23 01:47 train_image105.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 01:47 train_image106.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 01:47 train_image107.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 01:47 train_image108.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 01:47 train_image109.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 00:28 train_image10.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 01:47 train_image110.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 01:47 train_image111.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 01:47 train_image112.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 01:47 train_image113.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 01:47 train_image114.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 01:47 train_image115.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image116.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 01:47 train_image117.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 01:47 train_image118.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image119.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:28 train_image11.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 01:47 train_image120.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 01:47 train_image121.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image122.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 01:47 train_image123.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 01:47 train_image124.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 01:47 train_image125.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 01:47 train_image126.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 01:47 train_image127.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image128.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image129.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 00:28 train_image12.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image130.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image131.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 01:47 train_image132.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image133.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 01:47 train_image134.txt\n",
            "-rw-rw-rw- 1 root root   607 Jul 23 01:47 train_image135.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 01:47 train_image136.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 01:47 train_image137.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 01:47 train_image138.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 01:47 train_image139.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 00:28 train_image13.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 01:47 train_image140.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 01:47 train_image141.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 01:47 train_image142.txt\n",
            "-rw-rw-rw- 1 root root   531 Jul 23 01:47 train_image143.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 01:47 train_image144.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 01:47 train_image145.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 01:47 train_image146.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 01:47 train_image147.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 01:47 train_image148.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 01:47 train_image149.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:28 train_image14.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 01:47 train_image150.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 02:31 train_image151.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 02:31 train_image152.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 02:31 train_image153.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 02:31 train_image154.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 02:31 train_image155.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 02:31 train_image156.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 02:31 train_image157.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 02:31 train_image158.txt\n",
            "-rw-rw-rw- 1 root root   645 Jul 23 02:31 train_image159.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:28 train_image15.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 02:31 train_image160.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 02:31 train_image161.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 02:31 train_image162.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image163.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image164.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 02:31 train_image165.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image166.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 02:31 train_image167.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 02:31 train_image168.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 02:31 train_image169.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 00:28 train_image16.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 02:31 train_image170.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image171.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 02:31 train_image172.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 02:31 train_image173.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 02:31 train_image174.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image175.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 02:31 train_image176.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 02:31 train_image177.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image178.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 02:31 train_image179.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 00:28 train_image17.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 02:31 train_image180.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 02:31 train_image181.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 02:31 train_image182.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 02:31 train_image183.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 02:31 train_image184.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 02:31 train_image185.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 02:31 train_image186.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 02:31 train_image187.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 02:31 train_image188.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image189.txt\n",
            "-rw-rw-rw- 1 root root   645 Jul 23 00:28 train_image18.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image190.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image191.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 02:31 train_image192.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 02:31 train_image193.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image194.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 02:31 train_image195.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 02:31 train_image196.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 02:31 train_image197.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 02:31 train_image198.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 02:31 train_image199.txt\n",
            "-rw-rw-rw- 1 root root   607 Jul 23 00:28 train_image19.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 00:28 train_image1.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 02:31 train_image200.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 00:28 train_image20.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 10:49 train_image213.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 10:49 train_image214.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 10:49 train_image215.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 10:49 train_image216.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 10:49 train_image217.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 10:49 train_image218.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 10:49 train_image219.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:28 train_image21.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 10:49 train_image220.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 10:49 train_image221.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 10:49 train_image222.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 10:49 train_image223.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 10:49 train_image224.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 10:49 train_image225.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 10:49 train_image226.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 10:49 train_image227.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 10:49 train_image228.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 10:49 train_image229.txt\n",
            "-rw-rw-rw- 1 root root   569 Jul 23 00:28 train_image22.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 10:49 train_image230.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 10:49 train_image231.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 10:49 train_image232.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 10:49 train_image233.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 10:49 train_image234.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 10:49 train_image235.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 10:49 train_image236.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 10:49 train_image237.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 10:49 train_image238.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 10:49 train_image239.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:28 train_image23.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 10:49 train_image240.txt\n",
            "-rw-rw-rw- 1 root root   569 Jul 23 10:49 train_image241.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 10:49 train_image242.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 10:49 train_image243.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 10:49 train_image244.txt\n",
            "-rw-rw-rw- 1 root root   569 Jul 23 10:49 train_image245.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 10:49 train_image246.txt\n",
            "-rw-rw-rw- 1 root root   683 Jul 23 10:49 train_image247.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 10:49 train_image248.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 10:49 train_image249.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 00:28 train_image24.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 10:49 train_image250.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 10:49 train_image251.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 10:49 train_image252.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 10:49 train_image253.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 10:49 train_image254.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 10:49 train_image255.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 10:49 train_image256.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 10:49 train_image257.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 10:49 train_image258.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 10:49 train_image259.txt\n",
            "-rw-rw-rw- 1 root root   645 Jul 23 00:28 train_image25.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 10:49 train_image260.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:28 train_image26.txt\n",
            "-rw-rw-rw- 1 root root   531 Jul 23 00:28 train_image27.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:28 train_image28.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:28 train_image29.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:28 train_image2.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:28 train_image30.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 00:28 train_image31.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:28 train_image32.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 00:28 train_image33.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:28 train_image34.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:28 train_image35.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 00:28 train_image36.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 00:28 train_image37.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:28 train_image38.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:28 train_image39.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:28 train_image3.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:28 train_image40.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:28 train_image41.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 00:28 train_image42.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:28 train_image43.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 00:28 train_image44.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 00:28 train_image45.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:28 train_image46.txt\n",
            "-rw-rw-rw- 1 root root   683 Jul 23 00:28 train_image47.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 00:28 train_image48.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:28 train_image49.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 00:28 train_image4.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 00:28 train_image50.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:58 train_image51.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 00:58 train_image52.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image53.txt\n",
            "-rw-rw-rw- 1 root root    75 Jul 23 00:58 train_image54.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:58 train_image55.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 00:58 train_image56.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 00:58 train_image57.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image58.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 00:58 train_image59.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:28 train_image5.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image60.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 00:58 train_image61.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image62.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image63.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:58 train_image64.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:58 train_image65.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image66.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:58 train_image67.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:58 train_image68.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:58 train_image69.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:28 train_image6.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 00:58 train_image70.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 00:58 train_image71.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 00:58 train_image72.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image73.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 00:58 train_image74.txt\n",
            "-rw-rw-rw- 1 root root   113 Jul 23 00:58 train_image75.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:58 train_image76.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 00:58 train_image77.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 00:58 train_image78.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 00:58 train_image79.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 00:28 train_image7.txt\n",
            "-rw-rw-rw- 1 root root   151 Jul 23 00:58 train_image80.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image81.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image82.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 00:58 train_image83.txt\n",
            "-rw-rw-rw- 1 root root   189 Jul 23 00:58 train_image84.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 00:58 train_image85.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:58 train_image86.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:58 train_image87.txt\n",
            "-rw-rw-rw- 1 root root   341 Jul 23 00:58 train_image88.txt\n",
            "-rw-rw-rw- 1 root root   493 Jul 23 00:58 train_image89.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:28 train_image8.txt\n",
            "-rw-rw-rw- 1 root root   455 Jul 23 00:58 train_image90.txt\n",
            "-rw-rw-rw- 1 root root    37 Jul 23 00:58 train_image91.txt\n",
            "-rw-rw-rw- 1 root root   303 Jul 23 00:58 train_image92.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 00:58 train_image93.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image94.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:58 train_image95.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:58 train_image96.txt\n",
            "-rw-rw-rw- 1 root root   379 Jul 23 00:58 train_image97.txt\n",
            "-rw-rw-rw- 1 root root   417 Jul 23 00:58 train_image98.txt\n",
            "-rw-rw-rw- 1 root root   265 Jul 23 00:58 train_image99.txt\n",
            "-rw-rw-rw- 1 root root   227 Jul 23 00:28 train_image9.txt\n",
            "\n",
            "/content/dataset/valid:\n",
            "total 16\n",
            "drwxrwxrwx 4 root root 4096 Jul 23 12:00 .\n",
            "drwxrwxrwx 4 root root 4096 Jul 28 23:59 ..\n",
            "drwxrwxrwx 2 root root 4096 Jul 28 23:59 images\n",
            "drwxrwxrwx 2 root root 4096 Jul 28 23:59 labels\n",
            "\n",
            "/content/dataset/valid/images:\n",
            "total 23628\n",
            "drwxrwxrwx 2 root root   4096 Jul 28 23:59 .\n",
            "drwxrwxrwx 4 root root   4096 Jul 23 12:00 ..\n",
            "-rw-rw-rw- 1 root root 156858 Jul 21 11:04 lane_image244.jpg\n",
            "-rw-rw-rw- 1 root root 250786 Jul 21 11:04 lane_image245.jpg\n",
            "-rw-rw-rw- 1 root root 333556 Jul 21 11:04 lane_image252.jpg\n",
            "-rw-rw-rw- 1 root root 378142 Jul 21 11:04 lane_image253.jpg\n",
            "-rw-rw-rw- 1 root root 401074 Jul 21 11:04 lane_image261.jpg\n",
            "-rw-rw-rw- 1 root root 406144 Jul 21 11:04 lane_image264.jpg\n",
            "-rw-rw-rw- 1 root root 393625 Jul 21 11:04 lane_image268.jpg\n",
            "-rw-rw-rw- 1 root root 336373 Jul 21 11:04 lane_image276.jpg\n",
            "-rw-rw-rw- 1 root root 341532 Jul 21 11:04 lane_image282.jpg\n",
            "-rw-rw-rw- 1 root root 368403 Jul 21 11:04 lane_image285.jpg\n",
            "-rw-rw-rw- 1 root root 281786 Jul 21 11:04 lane_image288.jpg\n",
            "-rw-rw-rw- 1 root root 371972 Jul 21 11:04 lane_image296.jpg\n",
            "-rw-rw-rw- 1 root root 275663 Jul 21 11:04 lane_image305.jpg\n",
            "-rw-rw-rw- 1 root root 287401 Jul 21 11:04 lane_image310.jpg\n",
            "-rw-rw-rw- 1 root root 274655 Jul 21 11:04 lane_image311.jpg\n",
            "-rw-rw-rw- 1 root root 296256 Jul 21 11:04 lane_image316.jpg\n",
            "-rw-rw-rw- 1 root root 291549 Jul 21 11:04 lane_image320.jpg\n",
            "-rw-rw-rw- 1 root root 314026 Jul 21 11:04 lane_image325.jpg\n",
            "-rw-rw-rw- 1 root root 358151 Jul 21 11:04 lane_image330.jpg\n",
            "-rw-rw-rw- 1 root root 517330 Dec 12  2023 lane_image334.jpg\n",
            "-rw-rw-rw- 1 root root 335054 Jul 21 11:04 lane_image342.jpg\n",
            "-rw-rw-rw- 1 root root 359359 Jul 21 11:04 lane_image360.jpg\n",
            "-rw-rw-rw- 1 root root 321109 Jul 21 11:04 lane_image370.jpg\n",
            "-rw-rw-rw- 1 root root 285869 Jul 21 11:04 lane_image383.jpg\n",
            "-rw-rw-rw- 1 root root 286150 Jul 21 11:04 lane_image386.jpg\n",
            "-rw-rw-rw- 1 root root 358491 Jul 21 11:04 lane_image402.jpg\n",
            "-rw-rw-rw- 1 root root 347205 Jul 21 11:04 lane_image407.jpg\n",
            "-rw-rw-rw- 1 root root 318574 Jul 21 11:04 lane_image411.jpg\n",
            "-rw-rw-rw- 1 root root 296917 Jul 21 11:04 lane_image414.jpg\n",
            "-rw-rw-rw- 1 root root 403962 Jul 21 11:04 lane_image433.jpg\n",
            "-rw-rw-rw- 1 root root 390864 Jul 21 11:04 lane_image435.jpg\n",
            "-rw-rw-rw- 1 root root 425568 Jul 21 11:04 lane_image436.jpg\n",
            "-rw-rw-rw- 1 root root 365292 Jul 21 11:04 lane_image439.jpg\n",
            "-rw-rw-rw- 1 root root 415876 Jul 21 11:04 lane_image444.jpg\n",
            "-rw-rw-rw- 1 root root 373320 Jul 21 11:04 lane_image451.jpg\n",
            "-rw-rw-rw- 1 root root 361502 Jul 21 11:04 lane_image452.jpg\n",
            "-rw-rw-rw- 1 root root 376661 Jul 21 11:04 lane_image457.jpg\n",
            "-rw-rw-rw- 1 root root 495300 Jul 21 11:04 lane_image458.jpg\n",
            "-rw-rw-rw- 1 root root 507660 Jul 21 11:04 lane_image460.jpg\n",
            "-rw-rw-rw- 1 root root 554799 Jul 21 11:04 lane_image461.jpg\n",
            "-rw-rw-rw- 1 root root 524154 Jul 21 11:04 lane_image466.jpg\n",
            "-rw-rw-rw- 1 root root 543237 Jul 21 11:04 lane_image470.jpg\n",
            "-rw-rw-rw- 1 root root 468135 Jul 21 11:04 lane_image472.jpg\n",
            "-rw-rw-rw- 1 root root 462838 Jul 21 11:04 lane_image475.jpg\n",
            "-rw-rw-rw- 1 root root 261679 Jul 22 02:05 lane_image478.jpg\n",
            "-rw-rw-rw- 1 root root 229797 Jul 22 02:05 lane_image488.jpg\n",
            "-rw-rw-rw- 1 root root 240615 Jul 22 02:05 lane_image499.jpg\n",
            "-rw-rw-rw- 1 root root 293929 Jul 22 02:05 lane_image506.jpg\n",
            "-rw-rw-rw- 1 root root  91415 Jul 22 01:43 lane_image515.jpg\n",
            "-rw-rw-rw- 1 root root  93471 Jul 22 01:43 lane_image518.jpg\n",
            "-rw-rw-rw- 1 root root 286849 Jul 22 01:47 lane_image527.jpg\n",
            "-rw-rw-rw- 1 root root 188080 Jul 22 01:52 lane_image537.jpg\n",
            "-rw-rw-rw- 1 root root 168413 Jul 22 01:53 lane_image551.jpg\n",
            "-rw-rw-rw- 1 root root 167853 Jul 22 01:53 lane_image552.jpg\n",
            "-rw-rw-rw- 1 root root 172322 Jul 22 01:52 lane_image563.jpg\n",
            "-rw-rw-rw- 1 root root 295802 Jul 21 11:04 lane_image577.jpg\n",
            "-rw-rw-rw- 1 root root 329557 Jul 21 11:04 lane_image581.jpg\n",
            "-rw-rw-rw- 1 root root 386317 Jul 21 11:04 lane_image597.jpg\n",
            "-rw-rw-rw- 1 root root 374284 Jul 21 11:04 lane_image599.jpg\n",
            "-rw-rw-rw- 1 root root 274750 Jul 21 11:04 lane_image605.jpg\n",
            "-rw-rw-rw- 1 root root 304470 Jul 21 11:04 train_image201.jpg\n",
            "-rw-rw-rw- 1 root root 296426 Jul 21 11:04 train_image202.jpg\n",
            "-rw-rw-rw- 1 root root 426001 Jul 21 11:04 train_image203.jpg\n",
            "-rw-rw-rw- 1 root root 347614 Jul 21 11:04 train_image204.jpg\n",
            "-rw-rw-rw- 1 root root 288500 Jul 21 11:04 train_image205.jpg\n",
            "-rw-rw-rw- 1 root root 353620 Jul 21 11:04 train_image206.jpg\n",
            "-rw-rw-rw- 1 root root 361132 Jul 21 11:04 train_image207.jpg\n",
            "-rw-rw-rw- 1 root root 351534 Jul 21 11:04 train_image208.jpg\n",
            "-rw-rw-rw- 1 root root 306724 Jul 21 11:04 train_image209.jpg\n",
            "-rw-rw-rw- 1 root root 312057 Jul 21 11:04 train_image210.jpg\n",
            "-rw-rw-rw- 1 root root 318104 Jul 21 11:04 train_image211.jpg\n",
            "-rw-rw-rw- 1 root root 303285 Jul 21 11:04 train_image212.jpg\n",
            "\n",
            "/content/dataset/valid/labels:\n",
            "total 296\n",
            "drwxrwxrwx 2 root root 4096 Jul 28 23:59 .\n",
            "drwxrwxrwx 4 root root 4096 Jul 23 12:00 ..\n",
            "-rw-rw-rw- 1 root root  417 Jul 22 12:02 lane_image244.txt\n",
            "-rw-rw-rw- 1 root root  379 Jul 22 12:02 lane_image245.txt\n",
            "-rw-rw-rw- 1 root root   75 Jul 22 12:02 lane_image252.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 22 12:02 lane_image253.txt\n",
            "-rw-rw-rw- 1 root root  417 Jul 22 12:02 lane_image261.txt\n",
            "-rw-rw-rw- 1 root root  151 Jul 22 12:02 lane_image264.txt\n",
            "-rw-rw-rw- 1 root root  151 Jul 22 12:02 lane_image268.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 22 12:02 lane_image276.txt\n",
            "-rw-rw-rw- 1 root root  379 Jul 22 12:02 lane_image282.txt\n",
            "-rw-rw-rw- 1 root root  189 Jul 22 12:02 lane_image285.txt\n",
            "-rw-rw-rw- 1 root root  189 Jul 22 12:02 lane_image288.txt\n",
            "-rw-rw-rw- 1 root root  189 Jul 22 12:02 lane_image296.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:02 lane_image305.txt\n",
            "-rw-rw-rw- 1 root root  227 Jul 22 12:02 lane_image310.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:02 lane_image311.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:02 lane_image316.txt\n",
            "-rw-rw-rw- 1 root root  189 Jul 22 12:02 lane_image320.txt\n",
            "-rw-rw-rw- 1 root root  227 Jul 22 12:02 lane_image325.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 22 12:02 lane_image330.txt\n",
            "-rw-rw-rw- 1 root root  265 Jul 22 12:02 lane_image334.txt\n",
            "-rw-rw-rw- 1 root root  189 Jul 22 12:02 lane_image342.txt\n",
            "-rw-rw-rw- 1 root root  227 Jul 22 12:02 lane_image360.txt\n",
            "-rw-rw-rw- 1 root root  455 Jul 22 12:02 lane_image370.txt\n",
            "-rw-rw-rw- 1 root root  455 Jul 22 12:02 lane_image383.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:02 lane_image386.txt\n",
            "-rw-rw-rw- 1 root root  189 Jul 22 12:02 lane_image402.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:02 lane_image407.txt\n",
            "-rw-rw-rw- 1 root root  569 Jul 22 12:02 lane_image411.txt\n",
            "-rw-rw-rw- 1 root root  417 Jul 22 12:02 lane_image414.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 22 12:02 lane_image433.txt\n",
            "-rw-rw-rw- 1 root root  227 Jul 22 12:02 lane_image435.txt\n",
            "-rw-rw-rw- 1 root root  265 Jul 22 12:02 lane_image436.txt\n",
            "-rw-rw-rw- 1 root root  379 Jul 22 12:02 lane_image439.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 22 12:02 lane_image444.txt\n",
            "-rw-rw-rw- 1 root root   75 Jul 22 12:02 lane_image451.txt\n",
            "-rw-rw-rw- 1 root root  227 Jul 22 12:02 lane_image452.txt\n",
            "-rw-rw-rw- 1 root root  417 Jul 22 12:02 lane_image457.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:02 lane_image458.txt\n",
            "-rw-rw-rw- 1 root root  379 Jul 22 12:02 lane_image460.txt\n",
            "-rw-rw-rw- 1 root root  379 Jul 22 12:02 lane_image461.txt\n",
            "-rw-rw-rw- 1 root root  151 Jul 22 12:02 lane_image466.txt\n",
            "-rw-rw-rw- 1 root root   75 Jul 22 12:02 lane_image470.txt\n",
            "-rw-rw-rw- 1 root root  227 Jul 22 12:02 lane_image472.txt\n",
            "-rw-rw-rw- 1 root root  265 Jul 22 12:02 lane_image475.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:02 lane_image478.txt\n",
            "-rw-rw-rw- 1 root root  189 Jul 22 12:02 lane_image488.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 22 12:02 lane_image499.txt\n",
            "-rw-rw-rw- 1 root root   75 Jul 22 12:27 lane_image506.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:27 lane_image515.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 22 12:27 lane_image518.txt\n",
            "-rw-rw-rw- 1 root root  493 Jul 22 12:27 lane_image527.txt\n",
            "-rw-rw-rw- 1 root root  417 Jul 22 12:27 lane_image537.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:27 lane_image551.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:27 lane_image552.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 22 12:27 lane_image563.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 22 12:27 lane_image577.txt\n",
            "-rw-rw-rw- 1 root root  379 Jul 22 12:27 lane_image581.txt\n",
            "-rw-rw-rw- 1 root root  379 Jul 22 12:27 lane_image597.txt\n",
            "-rw-rw-rw- 1 root root  265 Jul 22 12:27 lane_image599.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 22 12:27 lane_image605.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 23 10:49 train_image201.txt\n",
            "-rw-rw-rw- 1 root root  189 Jul 23 10:49 train_image202.txt\n",
            "-rw-rw-rw- 1 root root  227 Jul 23 10:49 train_image203.txt\n",
            "-rw-rw-rw- 1 root root  341 Jul 23 10:49 train_image204.txt\n",
            "-rw-rw-rw- 1 root root  227 Jul 23 10:49 train_image205.txt\n",
            "-rw-rw-rw- 1 root root  227 Jul 23 10:49 train_image206.txt\n",
            "-rw-rw-rw- 1 root root  455 Jul 23 10:49 train_image207.txt\n",
            "-rw-rw-rw- 1 root root  265 Jul 23 10:49 train_image208.txt\n",
            "-rw-rw-rw- 1 root root  531 Jul 23 10:49 train_image209.txt\n",
            "-rw-rw-rw- 1 root root  303 Jul 23 10:49 train_image210.txt\n",
            "-rw-rw-rw- 1 root root  379 Jul 23 10:49 train_image211.txt\n",
            "-rw-rw-rw- 1 root root  379 Jul 23 10:49 train_image212.txt\n",
            "\n",
            "/content/drive:\n",
            "total 20\n",
            "dr-x------ 5 root root 4096 Jul 28 23:58 .Encrypted\n",
            "drwx------ 5 root root 4096 Jul 28 23:58 MyDrive\n",
            "drwx------ 4 root root 4096 Jul 28 23:58 Shareddrives\n",
            "dr-x------ 2 root root 4096 Jul 28 23:58 .shortcut-targets-by-id\n",
            "drwx------ 5 root root 4096 Jul 28 23:58 .Trash-0\n",
            "\n",
            "/content/drive/.Encrypted:\n",
            "total 12\n",
            "drwx------ 2 root root 4096 Jul 28 23:58 MyDrive\n",
            "drwx------ 2 root root 4096 Jul 28 23:58 Shareddrives\n",
            "dr-x------ 2 root root 4096 Jul 28 23:58 .shortcut-targets-by-id\n",
            "\n",
            "/content/drive/.Encrypted/MyDrive:\n",
            "total 12\n",
            "drwx------ 2 root root 4096 Oct 17  2019  Classroom\n",
            "drwx------ 2 root root 4096 Jun 24 00:32 'Colab Notebooks'\n",
            "drwx------ 2 root root 4096 Jun 24 00:21  YB_Jung_Class\n",
            "\n",
            "/content/drive/.Encrypted/MyDrive/Classroom:\n",
            "total 4\n",
            "drwx------ 2 root root 4096 Dec  5  2020 '전자기학 기말고사'\n",
            "\n",
            "'/content/drive/.Encrypted/MyDrive/Classroom/전자기학 기말고사':\n",
            "total 0\n",
            "\n",
            "'/content/drive/.Encrypted/MyDrive/Colab Notebooks':\n",
            "total 4\n",
            "drwx------ 2 root root 4096 Jul 28 11:56 .ipynb_checkpoints\n",
            "\n",
            "'/content/drive/.Encrypted/MyDrive/Colab Notebooks/.ipynb_checkpoints':\n",
            "total 0\n",
            "\n",
            "/content/drive/.Encrypted/MyDrive/YB_Jung_Class:\n",
            "total 0\n",
            "\n",
            "/content/drive/.Encrypted/Shareddrives:\n",
            "total 8\n",
            "drwx------ 1 root root 4096 Dec  7  2020 '2020_콘텐츠 자체개발_정영배 교수님'\n",
            "drwx------ 1 root root 4096 Feb 13  2020  BK21-미래자동차\n",
            "\n",
            "'/content/drive/.Encrypted/Shareddrives/2020_콘텐츠 자체개발_정영배 교수님':\n",
            "total 0\n",
            "\n",
            "/content/drive/.Encrypted/Shareddrives/BK21-미래자동차:\n",
            "total 0\n",
            "\n",
            "/content/drive/.Encrypted/.shortcut-targets-by-id:\n",
            "total 0\n",
            "\n",
            "/content/drive/MyDrive:\n",
            "total 11374048\n",
            "-rw------- 1 root root 1430107833 Oct 17  2022 '[2022] IITP_공간무선충전시스템.zip'\n",
            "-rw------- 1 root root  336431894 Jun 20  2023 '230620_전파자원 최종평가(1분과).zip'\n",
            "-rw------- 1 root root 1495308234 Nov 13  2023 '231113_자기소개 및 수행연구(정영배).mp4'\n",
            "-rw------- 1 root root  243208154 Feb 28  2024 '2. 전파산업(2.28수) 검토위.zip'\n",
            "-rw------- 1 root root  282856984 Mar 29  2024  9분과.zip\n",
            "-rw------- 1 root root   18438664 Apr 12  2018  AESA_F35.mp4\n",
            "-rw------- 1 root root   10220544 Jun 29  2022 'Antenna Basic and Design (220705).ppt'\n",
            "-rw------- 1 root root   10220544 Jun 29  2022 'Antenna Basic and Design (220721).ppt'\n",
            "-rw------- 1 root root   10220544 Jun 29  2022 'Antenna Basic and Design (220726).ppt'\n",
            "-rw------- 1 root root        175 Aug 27  2024 'BK21 2024의 사본.gsheet'\n",
            "drwx------ 3 root root       4096 Oct 17  2019  Classroom\n",
            "drwx------ 3 root root       4096 Jun 24 00:32 'Colab Notebooks'\n",
            "-rw------- 1 root root  140244539 Jul 28 11:24  dataset.zip\n",
            "-rw------- 1 root root   87484588 Mar 21  2024 'IITP_2024_5G 기지국,중계기용 유연박막 필터 일체형 안테나 개발.zip'\n",
            "-rw------- 1 root root   41498343 Feb 15  2019 'Phased Array Antennas.mp4'\n",
            "-rw------- 1 root root      11732 Jul 23 08:26 'Video Frame Extractor'\n",
            "-rw------- 1 root root       7870 Jul 23 08:16 'Video Frame Extractor (1)'\n",
            "drwx------ 2 root root       4096 Jun 24 00:21  YB_Jung_Class\n",
            "-rw------- 1 root root  387199735 Mar  5  2024 '과제중단 특별평가(24.3.5).zip'\n",
            "-rw------- 1 root root 4431743858 Nov 27  2023  데이터.zip\n",
            "-rw------- 1 root root        175 May 28 10:00 '본 보고서에 첨부된 ppt 파일의 그림을 최대한 추가해서 제공해줘.gsheet'\n",
            "-rw------- 1 root root  276095913 Apr  9  2024 '연구논문 및 특허.zip'\n",
            "-rw------- 1 root root        175 May 28 09:45 '연구 시작.gsheet'\n",
            "-rw------- 1 root root  700154198 Apr 22  2024  이의신청_타당성_검토위.zip\n",
            "-rw------- 1 root root        175 Apr 21  2023  일정.gsheet\n",
            "-rw------- 1 root root  106197376 Nov  1  2023 '★최고전문가 소분과 RFP검토위원회 자료_231031(화)-평가위원용PC.zip'\n",
            "-rw------- 1 root root 1639353017 Nov 15  2023  캡스톤_특허출원.zip\n",
            "-rw------- 1 root root        175 May 28 09:51 '파일 변환 및 정보 추출'$'\\n'' (1).gdoc'\n",
            "-rw------- 1 root root        175 May 28 10:01 '파일 변환 및 정보 추출'$'\\n''.gdoc'\n",
            "-rw------- 1 root root        175 Aug  4  2022 '학회지(전자파기술 33-3)_최종본.gdoc'\n",
            "\n",
            "/content/drive/MyDrive/Classroom:\n",
            "total 4\n",
            "drwx------ 2 root root 4096 Dec  5  2020 '전자기학 기말고사'\n",
            "\n",
            "'/content/drive/MyDrive/Classroom/전자기학 기말고사':\n",
            "total 1\n",
            "-rw------- 1 root root 175 Apr  4  2022 '전자기학 Quiz.gform'\n",
            "-rw------- 1 root root 175 Apr 21  2023 '전자기학 Quiz(응답).gsheet'\n",
            "\n",
            "'/content/drive/MyDrive/Colab Notebooks':\n",
            "total 14008\n",
            "-rw------- 1 root root   10356 Jun 25 03:03  0625_python_define-class_YB\n",
            "-rw------- 1 root root     376 Jun 26 01:39  0626_class_HB.ipynb\n",
            "-rw------- 1 root root    3795 Jun 26 02:26 '0626_python_list_YB Jung'\n",
            "-rw------- 1 root root    4049 Jun 27 01:56 '0627_python_class_YB Jung'\n",
            "-rw------- 1 root root    3953 Jun 27 03:08 '0627_pythoon_tuple_YB Jung.ipynb'\n",
            "-rw------- 1 root root  245337 Jul  4 04:46  0703_python_matplotlib\n",
            "-rw------- 1 root root   25604 Jul  3 02:14  0703_python_mumpy\n",
            "-rw------- 1 root root 1816343 Jul  7 03:00 '0707_python_machine learning.ipynb'\n",
            "-rw------- 1 root root   13476 Jul  7 02:54 '0707_python_OpenCV 그림그리기'\n",
            "-rw------- 1 root root 1071542 Jul  8 08:11 '0708_openCV_canny+HSV+Gaussian Block+녹색신호등'\n",
            "-rw------- 1 root root 1912032 Jul  8 01:58 '0708_python_신호등 영상처리'\n",
            "-rw------- 1 root root   24381 Jul  9 03:03 '0709_python_코랩에서 709_opencv_MOG2'\n",
            "-rw------- 1 root root  917103 Jul 10 02:41  0710_python_.ipynb\n",
            "-rw------- 1 root root  596035 Jul 15 06:20 '0715_python_CNN learning demo.ipynb'\n",
            "-rw------- 1 root root  821641 Jul 16 01:18 '0715_python_Image net'\n",
            "-rw------- 1 root root 2440863 Jul 17 01:03  0715_python_YOLOv8_1_image\n",
            "-rw------- 1 root root  619614 Jul 17 02:09  0715_python_YOLOv8_Youtube\n",
            "-rw------- 1 root root  744904 Jul 16 01:27  0716_python_ImageNet_Analysis.ipynb\n",
            "-rw------- 1 root root 1743019 Jul 19 02:11  0717_python_YOLO11\n",
            "-rw------- 1 root root  890015 Jul 19 02:11  0718_python_YOLO12\n",
            "-rw------- 1 root root   35665 Jul 19 02:41 '0719_Antenna_2D array antenna synthesis'\n",
            "-rw------- 1 root root   20446 Jul 19 03:01 '0719_python_YOLO11 vs YOLO12.ipynb'\n",
            "-rw------- 1 root root   50453 Jul 24 12:40 '0724_python_file combining.ipynb'\n",
            "-rw------- 1 root root   37460 Jul 24 10:00 '0724_Python_Video analysis with trained codes of Roboflow.ipynb'\n",
            "-rw------- 1 root root  224748 Jul 25 02:46 '0725_python_traffic detection practice using Pytorch.ipynb'\n",
            "-rw------- 1 root root   60279 Jul 28 23:58 '0728_python_transfer learning'\n",
            "drwx------ 2 root root    4096 Jul 28 11:56  .ipynb_checkpoints\n",
            "\n",
            "'/content/drive/MyDrive/Colab Notebooks/.ipynb_checkpoints':\n",
            "total 0\n",
            "\n",
            "/content/drive/MyDrive/YB_Jung_Class:\n",
            "total 0\n",
            "\n",
            "/content/drive/Shareddrives:\n",
            "total 8\n",
            "drwx------ 1 root root 4096 Dec  7  2020 '2020_콘텐츠 자체개발_정영배 교수님'\n",
            "drwx------ 1 root root 4096 Feb 13  2020  BK21-미래자동차\n",
            "\n",
            "'/content/drive/Shareddrives/2020_콘텐츠 자체개발_정영배 교수님':\n",
            "total 0\n",
            "\n",
            "/content/drive/Shareddrives/BK21-미래자동차:\n",
            "total 0\n",
            "\n",
            "/content/drive/.shortcut-targets-by-id:\n",
            "total 0\n",
            "\n",
            "/content/drive/.Trash-0:\n",
            "total 8\n",
            "drwx------ 2 root root 4096 Jul 28 23:58 files\n",
            "drwx------ 2 root root 4096 Jul 28 23:58 info\n",
            "\n",
            "/content/drive/.Trash-0/files:\n",
            "total 0\n",
            "\n",
            "/content/drive/.Trash-0/info:\n",
            "total 0\n",
            "\n",
            "/content/sample_data:\n",
            "total 55512\n",
            "drwxr-xr-x 1 root root     4096 Jul 25 13:38 .\n",
            "drwxr-xr-x 1 root root     4096 Jul 28 23:58 ..\n",
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rw-r--r-- 1 root root   301141 Jul 25 13:38 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root  1706430 Jul 25 13:38 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root 18289443 Jul 25 13:38 mnist_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Jul 25 13:38 mnist_train_small.csv\n",
            "-rwxr-xr-x 1 root root      962 Jan  1  2000 README.md\n",
            "total 24\n",
            "drwxr-xr-x 1 root root 4096 Jul 28 23:59 .\n",
            "drwxr-xr-x 1 root root 4096 Jul 28 23:42 ..\n",
            "drwxr-xr-x 4 root root 4096 Jul 25 13:38 .config\n",
            "drwxrwxrwx 4 root root 4096 Jul 28 23:59 dataset\n",
            "drwx------ 6 root root 4096 Jul 28 23:58 drive\n",
            "drwxr-xr-x 1 root root 4096 Jul 25 13:38 sample_data\n",
            "12G\t/content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning using trained model(Lane detection)"
      ],
      "metadata": {
        "id": "4_BQWaT_fEBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 필요한 라이브러리 설치\n",
        "!pip install roboflow ultralytics opencv-python\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "from roboflow import Roboflow\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files  # 파일 업로드를 위한 import 추가\n",
        "# Roboflow에서 이미 훈련된 모델을 불러와서 사용\n",
        "#영상에서 프레임을 추출하여 **추론(inference)**만 수행\n",
        "import cv2\n",
        "import os\n",
        "from roboflow import Roboflow\n",
        "\n",
        "def load_lane_detection_model():\n",
        "    \"\"\"\n",
        "    차선 감지 모델 로드\n",
        "    \"\"\"\n",
        "    rf = Roboflow(api_key=\"JwvZQEBhBR5uPrwepqQW\")\n",
        "    #project = rf.workspace().project(\"0722_labeling-usrpl/1\")\n",
        "    project = rf.workspace().project(\"0722_labeling-usrpl\")\n",
        "    model = project.version(1).model\n",
        "    print(\"🛣️ 차선 감지 모델 로드 완료!\")\n",
        "    return model\n",
        "\n",
        "def upload_video_files():\n",
        "    \"\"\"\n",
        "    PC에서 비디오 파일 업로드\n",
        "    \"\"\"\n",
        "    print(\"\\n🎬 Please select your video files to upload:\")\n",
        "    uploaded = files.upload()  # Returns a dictionary: {filename: file_content}\n",
        "\n",
        "    # Check if any files were actually uploaded\n",
        "    if not uploaded:\n",
        "        print(\"❌ No files uploaded!\")\n",
        "        return None  # Return None if no files uploaded\n",
        "\n",
        "    print(f\"\\n✅ Uploaded {len(uploaded)} file(s)\")\n",
        "\n",
        "    # 업로드된 파일 중 첫 번째 비디오 파일 반환\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv')):\n",
        "            print(f\"📁 Using video file: {filename}\")\n",
        "            return filename\n",
        "\n",
        "    print(\"❌ No valid video files found in upload!\")\n",
        "    return None\n",
        "\n",
        "def detect_lanes_in_video(video_path, model, output_path=\"lane_detection_result.mp4\"):\n",
        "    \"\"\"\n",
        "    영상에서 차선 감지\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # 영상 정보\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"🎬 영상 정보: {width}x{height}, {fps}fps, {total_frames}프레임\")\n",
        "\n",
        "    # 출력 설정\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    lane_detections = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        # 매 3프레임마다 차선 감지 (더 자주)\n",
        "        if frame_count % 2 == 0:\n",
        "            try:\n",
        "                temp_img_path = \"temp_frame.jpg\"\n",
        "                cv2.imwrite(temp_img_path, frame)\n",
        "\n",
        "                # 차선 감지 (낮은 신뢰도)\n",
        "                prediction = model.predict(temp_img_path, confidence=30, overlap=50)\n",
        "                predictions = prediction.json()['predictions']\n",
        "\n",
        "                frame_lanes = len(predictions)\n",
        "                lane_detections += frame_lanes\n",
        "\n",
        "                if frame_lanes > 0:\n",
        "                    print(f\"🛣️ 프레임 {frame_count}: {frame_lanes}개 차선 감지\")\n",
        "\n",
        "                # 차선 그리기\n",
        "                for lane in predictions:\n",
        "                    x1 = int(lane['x'] - lane['width']/2)\n",
        "                    y1 = int(lane['y'] - lane['height']/2)\n",
        "                    x2 = int(lane['x'] + lane['width']/2)\n",
        "                    y2 = int(lane['y'] + lane['height']/2)\n",
        "\n",
        "                    # 차선은 보라색으로 표시\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
        "\n",
        "                    # 라벨\n",
        "                    label = f\"Lane: {lane['confidence']:.2f}\"\n",
        "                    cv2.rectangle(frame, (x1, y1-30), (x1+150, y1), (255, 0, 255), -1)\n",
        "                    cv2.putText(frame, label, (x1+5, y1-8),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "                if os.path.exists(temp_img_path):\n",
        "                    os.remove(temp_img_path)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ 프레임 {frame_count} 처리 오류: {e}\")\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "        # 진행상황\n",
        "        if frame_count % 150 == 0:\n",
        "            progress = (frame_count / total_frames) * 100\n",
        "            print(f\"📊 진행률: {progress:.1f}% (총 차선 감지: {lane_detections}개)\")\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"✅ 완료! 총 {lane_detections}개 차선 감지\")\n",
        "    print(f\"🎥 결과: {output_path}\")\n",
        "\n",
        "def main_lane_detection():\n",
        "    \"\"\"\n",
        "    차선 감지 메인 함수\n",
        "    \"\"\"\n",
        "    print(\"🚗 비디오 파일 업로드 시작...\")\n",
        "    video_path = upload_video_files()\n",
        "\n",
        "    if video_path:\n",
        "        print(f\"📁 영상 파일: {video_path}\")\n",
        "\n",
        "        print(\"🛣️ 차선 감지 모델 로드 중...\")\n",
        "        try:\n",
        "            model = load_lane_detection_model()\n",
        "\n",
        "            print(\"🔍 차선 감지 시작...\")\n",
        "            detect_lanes_in_video(video_path, model, \"lane_detection_result.mp4\")\n",
        "\n",
        "            print(\"🎉 차선 감지 완료!\")\n",
        "            print(\"📺 결과 영상: lane_detection_result.mp4\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 모델 로드 실패: {e}\")\n",
        "            print(\"🔑 API 키를 확인해주세요!\")\n",
        "    else:\n",
        "        print(\"❌ 업로드된 비디오 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "def test_with_webcam_url():\n",
        "    \"\"\"\n",
        "    Roboflow Visualize 페이지의 'Paste YouTube or Image URL' 기능 사용\n",
        "    \"\"\"\n",
        "    print(\"🌐 웹 인터페이스 테스트:\")\n",
        "    print(\"1. Roboflow Visualize 페이지에서\")\n",
        "    print(\"2. 'Paste YouTube or Image URL' 입력창에\")\n",
        "    print(\"3. YouTube URL 붙여넣기\")\n",
        "    print(\"4. 차선이 잘 감지되는지 확인\")\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🛣️ 차선 감지 모드로 변경!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"💡 이 모델은 차선(lane)을 감지하는 모델입니다.\")\n",
        "    print(\"📹 드라이빙 영상이나 도로 영상에서 가장 잘 작동합니다.\")\n",
        "    print()\n",
        "    print(\"🚀 실행 방법:\")\n",
        "    print(\"1. API 키 입력\")\n",
        "    print(\"2. main_lane_detection() 실행\")\n",
        "    print(\"3. PC에서 비디오 파일 선택\")\n",
        "    print(\"4. 또는 Roboflow 웹에서 test_with_webcam_url() 방법 시도\")\n",
        "    print(\"=\" * 50)\n",
        "    main_lane_detection()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HnZ72k2bz3tq",
        "outputId": "f569fa53-aab3-4254-a5f8-af047881eb51"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.2.3)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.170)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.7.14)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.3.0)\n",
            "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.59.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "🛣️ 차선 감지 모드로 변경!\n",
            "==================================================\n",
            "💡 이 모델은 차선(lane)을 감지하는 모델입니다.\n",
            "📹 드라이빙 영상이나 도로 영상에서 가장 잘 작동합니다.\n",
            "\n",
            "🚀 실행 방법:\n",
            "1. API 키 입력\n",
            "2. main_lane_detection() 실행\n",
            "3. PC에서 비디오 파일 선택\n",
            "4. 또는 Roboflow 웹에서 test_with_webcam_url() 방법 시도\n",
            "==================================================\n",
            "🚗 비디오 파일 업로드 시작...\n",
            "\n",
            "🎬 Please select your video files to upload:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa6bfe7d-89da-45bb-8dab-97c3ad31d11f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa6bfe7d-89da-45bb-8dab-97c3ad31d11f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving KakaoTalk_20250704_093345410.mp4 to KakaoTalk_20250704_093345410.mp4\n",
            "\n",
            "✅ Uploaded 1 file(s)\n",
            "📁 Using video file: KakaoTalk_20250704_093345410.mp4\n",
            "📁 영상 파일: KakaoTalk_20250704_093345410.mp4\n",
            "🛣️ 차선 감지 모델 로드 중...\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "🛣️ 차선 감지 모델 로드 완료!\n",
            "🔍 차선 감지 시작...\n",
            "🎬 영상 정보: 1600x720, 24fps, 3760프레임\n",
            "🛣️ 프레임 2: 14개 차선 감지\n",
            "🛣️ 프레임 4: 16개 차선 감지\n",
            "🛣️ 프레임 6: 18개 차선 감지\n",
            "🛣️ 프레임 8: 18개 차선 감지\n",
            "🛣️ 프레임 10: 21개 차선 감지\n",
            "🛣️ 프레임 12: 17개 차선 감지\n",
            "🛣️ 프레임 14: 21개 차선 감지\n",
            "🛣️ 프레임 16: 23개 차선 감지\n",
            "🛣️ 프레임 18: 22개 차선 감지\n",
            "🛣️ 프레임 20: 17개 차선 감지\n",
            "🛣️ 프레임 22: 17개 차선 감지\n",
            "🛣️ 프레임 24: 19개 차선 감지\n",
            "🛣️ 프레임 26: 14개 차선 감지\n",
            "🛣️ 프레임 28: 14개 차선 감지\n",
            "🛣️ 프레임 30: 17개 차선 감지\n",
            "🛣️ 프레임 32: 14개 차선 감지\n",
            "🛣️ 프레임 34: 14개 차선 감지\n",
            "🛣️ 프레임 36: 15개 차선 감지\n",
            "🛣️ 프레임 38: 13개 차선 감지\n",
            "🛣️ 프레임 40: 12개 차선 감지\n",
            "🛣️ 프레임 42: 13개 차선 감지\n",
            "🛣️ 프레임 44: 12개 차선 감지\n",
            "🛣️ 프레임 46: 14개 차선 감지\n",
            "🛣️ 프레임 48: 15개 차선 감지\n",
            "🛣️ 프레임 50: 10개 차선 감지\n",
            "🛣️ 프레임 52: 11개 차선 감지\n",
            "🛣️ 프레임 54: 15개 차선 감지\n",
            "🛣️ 프레임 56: 15개 차선 감지\n",
            "🛣️ 프레임 58: 17개 차선 감지\n",
            "🛣️ 프레임 60: 16개 차선 감지\n",
            "🛣️ 프레임 62: 14개 차선 감지\n",
            "🛣️ 프레임 64: 14개 차선 감지\n",
            "🛣️ 프레임 66: 12개 차선 감지\n",
            "🛣️ 프레임 68: 13개 차선 감지\n",
            "🛣️ 프레임 70: 13개 차선 감지\n",
            "🛣️ 프레임 72: 18개 차선 감지\n",
            "🛣️ 프레임 74: 13개 차선 감지\n",
            "🛣️ 프레임 76: 13개 차선 감지\n",
            "🛣️ 프레임 78: 14개 차선 감지\n",
            "🛣️ 프레임 80: 15개 차선 감지\n",
            "🛣️ 프레임 82: 15개 차선 감지\n",
            "🛣️ 프레임 84: 14개 차선 감지\n",
            "🛣️ 프레임 86: 16개 차선 감지\n",
            "🛣️ 프레임 88: 16개 차선 감지\n",
            "🛣️ 프레임 90: 15개 차선 감지\n",
            "🛣️ 프레임 92: 15개 차선 감지\n",
            "🛣️ 프레임 94: 16개 차선 감지\n",
            "🛣️ 프레임 96: 14개 차선 감지\n",
            "🛣️ 프레임 98: 15개 차선 감지\n",
            "🛣️ 프레임 100: 14개 차선 감지\n",
            "🛣️ 프레임 102: 10개 차선 감지\n",
            "🛣️ 프레임 104: 11개 차선 감지\n",
            "🛣️ 프레임 106: 11개 차선 감지\n",
            "🛣️ 프레임 108: 14개 차선 감지\n",
            "🛣️ 프레임 110: 13개 차선 감지\n",
            "🛣️ 프레임 112: 13개 차선 감지\n",
            "🛣️ 프레임 114: 14개 차선 감지\n",
            "🛣️ 프레임 116: 13개 차선 감지\n",
            "🛣️ 프레임 118: 15개 차선 감지\n",
            "🛣️ 프레임 120: 15개 차선 감지\n",
            "🛣️ 프레임 122: 16개 차선 감지\n",
            "🛣️ 프레임 124: 22개 차선 감지\n",
            "🛣️ 프레임 126: 26개 차선 감지\n",
            "🛣️ 프레임 128: 21개 차선 감지\n",
            "🛣️ 프레임 130: 21개 차선 감지\n",
            "🛣️ 프레임 132: 21개 차선 감지\n",
            "🛣️ 프레임 134: 23개 차선 감지\n",
            "🛣️ 프레임 136: 26개 차선 감지\n",
            "🛣️ 프레임 138: 24개 차선 감지\n",
            "🛣️ 프레임 140: 25개 차선 감지\n",
            "🛣️ 프레임 142: 25개 차선 감지\n",
            "🛣️ 프레임 144: 23개 차선 감지\n",
            "🛣️ 프레임 146: 21개 차선 감지\n",
            "🛣️ 프레임 148: 25개 차선 감지\n",
            "🛣️ 프레임 150: 19개 차선 감지\n",
            "📊 진행률: 4.0% (총 차선 감지: 1230개)\n",
            "🛣️ 프레임 152: 27개 차선 감지\n",
            "🛣️ 프레임 154: 25개 차선 감지\n",
            "🛣️ 프레임 156: 25개 차선 감지\n",
            "🛣️ 프레임 158: 26개 차선 감지\n",
            "🛣️ 프레임 160: 24개 차선 감지\n",
            "🛣️ 프레임 162: 23개 차선 감지\n",
            "🛣️ 프레임 164: 19개 차선 감지\n",
            "🛣️ 프레임 166: 17개 차선 감지\n",
            "🛣️ 프레임 168: 17개 차선 감지\n",
            "🛣️ 프레임 170: 13개 차선 감지\n",
            "🛣️ 프레임 172: 16개 차선 감지\n",
            "🛣️ 프레임 174: 16개 차선 감지\n",
            "🛣️ 프레임 176: 20개 차선 감지\n",
            "🛣️ 프레임 178: 25개 차선 감지\n",
            "🛣️ 프레임 180: 24개 차선 감지\n",
            "🛣️ 프레임 182: 29개 차선 감지\n",
            "🛣️ 프레임 184: 24개 차선 감지\n",
            "🛣️ 프레임 186: 19개 차선 감지\n",
            "🛣️ 프레임 188: 22개 차선 감지\n",
            "🛣️ 프레임 190: 19개 차선 감지\n",
            "🛣️ 프레임 192: 19개 차선 감지\n",
            "🛣️ 프레임 194: 19개 차선 감지\n",
            "🛣️ 프레임 196: 7개 차선 감지\n",
            "🛣️ 프레임 198: 6개 차선 감지\n",
            "🛣️ 프레임 200: 8개 차선 감지\n",
            "🛣️ 프레임 202: 9개 차선 감지\n",
            "🛣️ 프레임 204: 9개 차선 감지\n",
            "🛣️ 프레임 206: 10개 차선 감지\n",
            "🛣️ 프레임 208: 10개 차선 감지\n",
            "🛣️ 프레임 210: 13개 차선 감지\n",
            "🛣️ 프레임 212: 10개 차선 감지\n",
            "🛣️ 프레임 214: 11개 차선 감지\n",
            "🛣️ 프레임 216: 13개 차선 감지\n",
            "🛣️ 프레임 218: 15개 차선 감지\n",
            "🛣️ 프레임 220: 15개 차선 감지\n",
            "🛣️ 프레임 222: 11개 차선 감지\n",
            "🛣️ 프레임 224: 12개 차선 감지\n",
            "🛣️ 프레임 226: 14개 차선 감지\n",
            "🛣️ 프레임 228: 17개 차선 감지\n",
            "🛣️ 프레임 230: 13개 차선 감지\n",
            "🛣️ 프레임 232: 13개 차선 감지\n",
            "🛣️ 프레임 234: 16개 차선 감지\n",
            "🛣️ 프레임 236: 14개 차선 감지\n",
            "🛣️ 프레임 238: 14개 차선 감지\n",
            "🛣️ 프레임 240: 20개 차선 감지\n",
            "🛣️ 프레임 242: 15개 차선 감지\n",
            "🛣️ 프레임 244: 17개 차선 감지\n",
            "🛣️ 프레임 246: 25개 차선 감지\n",
            "🛣️ 프레임 248: 18개 차선 감지\n",
            "🛣️ 프레임 250: 24개 차선 감지\n",
            "🛣️ 프레임 252: 29개 차선 감지\n",
            "🛣️ 프레임 254: 29개 차선 감지\n",
            "🛣️ 프레임 256: 28개 차선 감지\n",
            "🛣️ 프레임 258: 26개 차선 감지\n",
            "🛣️ 프레임 260: 25개 차선 감지\n",
            "🛣️ 프레임 262: 24개 차선 감지\n",
            "🛣️ 프레임 264: 21개 차선 감지\n",
            "🛣️ 프레임 266: 21개 차선 감지\n",
            "🛣️ 프레임 268: 17개 차선 감지\n",
            "🛣️ 프레임 270: 21개 차선 감지\n",
            "🛣️ 프레임 272: 23개 차선 감지\n",
            "🛣️ 프레임 274: 23개 차선 감지\n",
            "🛣️ 프레임 276: 17개 차선 감지\n",
            "🛣️ 프레임 278: 23개 차선 감지\n",
            "🛣️ 프레임 280: 21개 차선 감지\n",
            "🛣️ 프레임 282: 16개 차선 감지\n",
            "🛣️ 프레임 284: 13개 차선 감지\n",
            "🛣️ 프레임 286: 7개 차선 감지\n",
            "🛣️ 프레임 288: 10개 차선 감지\n",
            "🛣️ 프레임 290: 10개 차선 감지\n",
            "🛣️ 프레임 292: 9개 차선 감지\n",
            "🛣️ 프레임 294: 12개 차선 감지\n",
            "🛣️ 프레임 296: 8개 차선 감지\n",
            "🛣️ 프레임 298: 10개 차선 감지\n",
            "🛣️ 프레임 300: 9개 차선 감지\n",
            "📊 진행률: 8.0% (총 차선 감지: 2529개)\n",
            "🛣️ 프레임 302: 9개 차선 감지\n",
            "🛣️ 프레임 304: 10개 차선 감지\n",
            "🛣️ 프레임 306: 10개 차선 감지\n",
            "🛣️ 프레임 308: 10개 차선 감지\n",
            "🛣️ 프레임 310: 9개 차선 감지\n",
            "🛣️ 프레임 312: 9개 차선 감지\n",
            "🛣️ 프레임 314: 10개 차선 감지\n",
            "🛣️ 프레임 316: 9개 차선 감지\n",
            "🛣️ 프레임 318: 6개 차선 감지\n",
            "🛣️ 프레임 320: 12개 차선 감지\n",
            "🛣️ 프레임 322: 7개 차선 감지\n",
            "🛣️ 프레임 324: 7개 차선 감지\n",
            "🛣️ 프레임 326: 8개 차선 감지\n",
            "🛣️ 프레임 328: 7개 차선 감지\n",
            "🛣️ 프레임 330: 9개 차선 감지\n",
            "🛣️ 프레임 332: 10개 차선 감지\n",
            "🛣️ 프레임 334: 12개 차선 감지\n",
            "🛣️ 프레임 336: 12개 차선 감지\n",
            "🛣️ 프레임 338: 10개 차선 감지\n",
            "🛣️ 프레임 340: 12개 차선 감지\n",
            "🛣️ 프레임 342: 11개 차선 감지\n",
            "🛣️ 프레임 344: 14개 차선 감지\n",
            "🛣️ 프레임 346: 12개 차선 감지\n",
            "🛣️ 프레임 348: 16개 차선 감지\n",
            "🛣️ 프레임 350: 15개 차선 감지\n",
            "🛣️ 프레임 352: 13개 차선 감지\n",
            "🛣️ 프레임 354: 15개 차선 감지\n",
            "🛣️ 프레임 356: 11개 차선 감지\n",
            "🛣️ 프레임 358: 13개 차선 감지\n",
            "🛣️ 프레임 360: 16개 차선 감지\n",
            "🛣️ 프레임 362: 15개 차선 감지\n",
            "🛣️ 프레임 364: 17개 차선 감지\n",
            "🛣️ 프레임 366: 16개 차선 감지\n",
            "🛣️ 프레임 368: 14개 차선 감지\n",
            "🛣️ 프레임 370: 13개 차선 감지\n",
            "🛣️ 프레임 372: 13개 차선 감지\n",
            "🛣️ 프레임 374: 12개 차선 감지\n",
            "🛣️ 프레임 376: 15개 차선 감지\n",
            "🛣️ 프레임 378: 14개 차선 감지\n",
            "🛣️ 프레임 380: 13개 차선 감지\n",
            "🛣️ 프레임 382: 10개 차선 감지\n",
            "🛣️ 프레임 384: 14개 차선 감지\n",
            "🛣️ 프레임 386: 11개 차선 감지\n",
            "🛣️ 프레임 388: 12개 차선 감지\n",
            "🛣️ 프레임 390: 10개 차선 감지\n",
            "🛣️ 프레임 392: 10개 차선 감지\n",
            "🛣️ 프레임 394: 10개 차선 감지\n",
            "🛣️ 프레임 396: 12개 차선 감지\n",
            "🛣️ 프레임 398: 8개 차선 감지\n",
            "🛣️ 프레임 400: 10개 차선 감지\n",
            "🛣️ 프레임 402: 11개 차선 감지\n",
            "🛣️ 프레임 404: 8개 차선 감지\n",
            "🛣️ 프레임 406: 8개 차선 감지\n",
            "🛣️ 프레임 408: 8개 차선 감지\n",
            "🛣️ 프레임 410: 7개 차선 감지\n",
            "🛣️ 프레임 412: 12개 차선 감지\n",
            "🛣️ 프레임 414: 10개 차선 감지\n",
            "🛣️ 프레임 416: 13개 차선 감지\n",
            "🛣️ 프레임 418: 12개 차선 감지\n",
            "🛣️ 프레임 420: 13개 차선 감지\n",
            "🛣️ 프레임 422: 16개 차선 감지\n",
            "🛣️ 프레임 424: 14개 차선 감지\n",
            "🛣️ 프레임 426: 15개 차선 감지\n",
            "🛣️ 프레임 428: 13개 차선 감지\n",
            "🛣️ 프레임 430: 14개 차선 감지\n",
            "🛣️ 프레임 432: 19개 차선 감지\n",
            "🛣️ 프레임 434: 21개 차선 감지\n",
            "🛣️ 프레임 436: 15개 차선 감지\n",
            "🛣️ 프레임 438: 12개 차선 감지\n",
            "🛣️ 프레임 440: 13개 차선 감지\n",
            "🛣️ 프레임 442: 14개 차선 감지\n",
            "🛣️ 프레임 444: 16개 차선 감지\n",
            "🛣️ 프레임 446: 18개 차선 감지\n",
            "🛣️ 프레임 448: 16개 차선 감지\n",
            "🛣️ 프레임 450: 17개 차선 감지\n",
            "📊 진행률: 12.0% (총 차선 감지: 3437개)\n",
            "🛣️ 프레임 452: 11개 차선 감지\n",
            "🛣️ 프레임 454: 11개 차선 감지\n",
            "🛣️ 프레임 456: 10개 차선 감지\n",
            "🛣️ 프레임 458: 13개 차선 감지\n",
            "🛣️ 프레임 460: 11개 차선 감지\n",
            "🛣️ 프레임 462: 10개 차선 감지\n",
            "🛣️ 프레임 464: 12개 차선 감지\n",
            "🛣️ 프레임 466: 12개 차선 감지\n",
            "🛣️ 프레임 468: 12개 차선 감지\n",
            "🛣️ 프레임 470: 12개 차선 감지\n",
            "🛣️ 프레임 472: 15개 차선 감지\n",
            "🛣️ 프레임 474: 14개 차선 감지\n",
            "🛣️ 프레임 476: 15개 차선 감지\n",
            "🛣️ 프레임 478: 15개 차선 감지\n",
            "🛣️ 프레임 480: 14개 차선 감지\n",
            "🛣️ 프레임 482: 15개 차선 감지\n",
            "🛣️ 프레임 484: 10개 차선 감지\n",
            "🛣️ 프레임 486: 11개 차선 감지\n",
            "🛣️ 프레임 488: 9개 차선 감지\n",
            "🛣️ 프레임 490: 11개 차선 감지\n",
            "🛣️ 프레임 492: 9개 차선 감지\n",
            "🛣️ 프레임 494: 9개 차선 감지\n",
            "🛣️ 프레임 496: 12개 차선 감지\n",
            "🛣️ 프레임 498: 13개 차선 감지\n",
            "🛣️ 프레임 500: 11개 차선 감지\n",
            "🛣️ 프레임 502: 11개 차선 감지\n",
            "🛣️ 프레임 504: 10개 차선 감지\n",
            "🛣️ 프레임 506: 9개 차선 감지\n",
            "🛣️ 프레임 508: 10개 차선 감지\n",
            "🛣️ 프레임 510: 14개 차선 감지\n",
            "🛣️ 프레임 512: 12개 차선 감지\n",
            "🛣️ 프레임 514: 16개 차선 감지\n",
            "🛣️ 프레임 516: 15개 차선 감지\n",
            "🛣️ 프레임 518: 18개 차선 감지\n",
            "🛣️ 프레임 520: 13개 차선 감지\n",
            "🛣️ 프레임 522: 12개 차선 감지\n",
            "🛣️ 프레임 524: 14개 차선 감지\n",
            "🛣️ 프레임 526: 14개 차선 감지\n",
            "🛣️ 프레임 528: 18개 차선 감지\n",
            "🛣️ 프레임 530: 17개 차선 감지\n",
            "🛣️ 프레임 532: 11개 차선 감지\n",
            "🛣️ 프레임 534: 11개 차선 감지\n",
            "🛣️ 프레임 536: 6개 차선 감지\n",
            "🛣️ 프레임 538: 7개 차선 감지\n",
            "🛣️ 프레임 540: 6개 차선 감지\n",
            "🛣️ 프레임 542: 5개 차선 감지\n",
            "🛣️ 프레임 544: 4개 차선 감지\n",
            "🛣️ 프레임 546: 5개 차선 감지\n",
            "🛣️ 프레임 548: 5개 차선 감지\n",
            "🛣️ 프레임 550: 8개 차선 감지\n",
            "🛣️ 프레임 552: 6개 차선 감지\n",
            "🛣️ 프레임 554: 9개 차선 감지\n",
            "🛣️ 프레임 556: 6개 차선 감지\n",
            "🛣️ 프레임 558: 9개 차선 감지\n",
            "🛣️ 프레임 560: 7개 차선 감지\n",
            "🛣️ 프레임 562: 9개 차선 감지\n",
            "🛣️ 프레임 564: 11개 차선 감지\n",
            "🛣️ 프레임 566: 8개 차선 감지\n",
            "🛣️ 프레임 568: 7개 차선 감지\n",
            "🛣️ 프레임 570: 8개 차선 감지\n",
            "🛣️ 프레임 572: 9개 차선 감지\n",
            "🛣️ 프레임 574: 8개 차선 감지\n",
            "🛣️ 프레임 576: 9개 차선 감지\n",
            "🛣️ 프레임 578: 10개 차선 감지\n",
            "🛣️ 프레임 580: 6개 차선 감지\n",
            "🛣️ 프레임 582: 8개 차선 감지\n",
            "🛣️ 프레임 584: 7개 차선 감지\n",
            "🛣️ 프레임 586: 9개 차선 감지\n",
            "🛣️ 프레임 588: 8개 차선 감지\n",
            "🛣️ 프레임 590: 8개 차선 감지\n",
            "🛣️ 프레임 592: 8개 차선 감지\n",
            "🛣️ 프레임 594: 6개 차선 감지\n",
            "🛣️ 프레임 596: 5개 차선 감지\n",
            "🛣️ 프레임 598: 11개 차선 감지\n",
            "🛣️ 프레임 600: 10개 차선 감지\n",
            "📊 진행률: 16.0% (총 차선 감지: 4207개)\n",
            "🛣️ 프레임 602: 8개 차선 감지\n",
            "🛣️ 프레임 604: 7개 차선 감지\n",
            "🛣️ 프레임 606: 5개 차선 감지\n",
            "🛣️ 프레임 608: 7개 차선 감지\n",
            "🛣️ 프레임 610: 8개 차선 감지\n",
            "🛣️ 프레임 612: 7개 차선 감지\n",
            "🛣️ 프레임 614: 7개 차선 감지\n",
            "🛣️ 프레임 616: 11개 차선 감지\n",
            "🛣️ 프레임 618: 14개 차선 감지\n",
            "🛣️ 프레임 620: 14개 차선 감지\n",
            "🛣️ 프레임 622: 14개 차선 감지\n",
            "🛣️ 프레임 624: 14개 차선 감지\n",
            "🛣️ 프레임 626: 16개 차선 감지\n",
            "🛣️ 프레임 628: 16개 차선 감지\n",
            "🛣️ 프레임 630: 15개 차선 감지\n",
            "🛣️ 프레임 632: 16개 차선 감지\n",
            "🛣️ 프레임 634: 14개 차선 감지\n",
            "🛣️ 프레임 636: 17개 차선 감지\n",
            "🛣️ 프레임 638: 12개 차선 감지\n",
            "🛣️ 프레임 640: 11개 차선 감지\n",
            "🛣️ 프레임 642: 10개 차선 감지\n",
            "🛣️ 프레임 644: 12개 차선 감지\n",
            "🛣️ 프레임 646: 11개 차선 감지\n",
            "🛣️ 프레임 648: 9개 차선 감지\n",
            "🛣️ 프레임 650: 10개 차선 감지\n",
            "🛣️ 프레임 652: 11개 차선 감지\n",
            "🛣️ 프레임 654: 8개 차선 감지\n",
            "🛣️ 프레임 656: 10개 차선 감지\n",
            "🛣️ 프레임 658: 12개 차선 감지\n",
            "🛣️ 프레임 660: 10개 차선 감지\n",
            "🛣️ 프레임 662: 8개 차선 감지\n",
            "🛣️ 프레임 664: 10개 차선 감지\n",
            "🛣️ 프레임 666: 12개 차선 감지\n",
            "🛣️ 프레임 668: 11개 차선 감지\n",
            "🛣️ 프레임 670: 14개 차선 감지\n",
            "🛣️ 프레임 672: 15개 차선 감지\n",
            "🛣️ 프레임 674: 10개 차선 감지\n",
            "🛣️ 프레임 676: 12개 차선 감지\n",
            "🛣️ 프레임 678: 10개 차선 감지\n",
            "🛣️ 프레임 680: 14개 차선 감지\n",
            "🛣️ 프레임 682: 13개 차선 감지\n",
            "🛣️ 프레임 684: 13개 차선 감지\n",
            "🛣️ 프레임 686: 14개 차선 감지\n",
            "🛣️ 프레임 688: 13개 차선 감지\n",
            "🛣️ 프레임 690: 16개 차선 감지\n",
            "🛣️ 프레임 692: 14개 차선 감지\n",
            "🛣️ 프레임 694: 11개 차선 감지\n",
            "🛣️ 프레임 696: 10개 차선 감지\n",
            "🛣️ 프레임 698: 8개 차선 감지\n",
            "🛣️ 프레임 700: 8개 차선 감지\n",
            "🛣️ 프레임 702: 9개 차선 감지\n",
            "🛣️ 프레임 704: 9개 차선 감지\n",
            "🛣️ 프레임 706: 9개 차선 감지\n",
            "🛣️ 프레임 708: 10개 차선 감지\n",
            "🛣️ 프레임 710: 12개 차선 감지\n",
            "🛣️ 프레임 712: 11개 차선 감지\n",
            "🛣️ 프레임 714: 8개 차선 감지\n",
            "🛣️ 프레임 716: 9개 차선 감지\n",
            "🛣️ 프레임 718: 7개 차선 감지\n",
            "🛣️ 프레임 720: 7개 차선 감지\n",
            "🛣️ 프레임 722: 9개 차선 감지\n",
            "🛣️ 프레임 724: 9개 차선 감지\n",
            "🛣️ 프레임 726: 11개 차선 감지\n",
            "🛣️ 프레임 728: 11개 차선 감지\n",
            "🛣️ 프레임 730: 12개 차선 감지\n",
            "🛣️ 프레임 732: 10개 차선 감지\n",
            "🛣️ 프레임 734: 12개 차선 감지\n",
            "🛣️ 프레임 736: 15개 차선 감지\n",
            "🛣️ 프레임 738: 14개 차선 감지\n",
            "🛣️ 프레임 740: 15개 차선 감지\n",
            "🛣️ 프레임 742: 16개 차선 감지\n",
            "🛣️ 프레임 744: 18개 차선 감지\n",
            "🛣️ 프레임 746: 16개 차선 감지\n",
            "🛣️ 프레임 748: 17개 차선 감지\n",
            "🛣️ 프레임 750: 17개 차선 감지\n",
            "📊 진행률: 19.9% (총 차선 감지: 5072개)\n",
            "🛣️ 프레임 752: 16개 차선 감지\n",
            "🛣️ 프레임 754: 18개 차선 감지\n",
            "🛣️ 프레임 756: 17개 차선 감지\n",
            "🛣️ 프레임 758: 14개 차선 감지\n",
            "🛣️ 프레임 760: 22개 차선 감지\n",
            "🛣️ 프레임 762: 26개 차선 감지\n",
            "🛣️ 프레임 764: 21개 차선 감지\n",
            "🛣️ 프레임 766: 19개 차선 감지\n",
            "🛣️ 프레임 768: 10개 차선 감지\n",
            "🛣️ 프레임 770: 6개 차선 감지\n",
            "🛣️ 프레임 772: 8개 차선 감지\n",
            "🛣️ 프레임 774: 9개 차선 감지\n",
            "🛣️ 프레임 776: 13개 차선 감지\n",
            "🛣️ 프레임 778: 14개 차선 감지\n",
            "🛣️ 프레임 780: 15개 차선 감지\n",
            "🛣️ 프레임 782: 15개 차선 감지\n",
            "🛣️ 프레임 784: 15개 차선 감지\n",
            "🛣️ 프레임 786: 16개 차선 감지\n",
            "🛣️ 프레임 788: 17개 차선 감지\n",
            "🛣️ 프레임 790: 18개 차선 감지\n",
            "🛣️ 프레임 792: 21개 차선 감지\n",
            "🛣️ 프레임 794: 14개 차선 감지\n",
            "🛣️ 프레임 796: 12개 차선 감지\n",
            "🛣️ 프레임 798: 12개 차선 감지\n",
            "🛣️ 프레임 800: 12개 차선 감지\n",
            "🛣️ 프레임 802: 10개 차선 감지\n",
            "🛣️ 프레임 804: 16개 차선 감지\n",
            "🛣️ 프레임 806: 15개 차선 감지\n",
            "🛣️ 프레임 808: 17개 차선 감지\n",
            "🛣️ 프레임 810: 19개 차선 감지\n",
            "🛣️ 프레임 812: 16개 차선 감지\n",
            "🛣️ 프레임 814: 11개 차선 감지\n",
            "🛣️ 프레임 816: 13개 차선 감지\n",
            "🛣️ 프레임 818: 15개 차선 감지\n",
            "🛣️ 프레임 820: 13개 차선 감지\n",
            "🛣️ 프레임 822: 16개 차선 감지\n",
            "🛣️ 프레임 824: 15개 차선 감지\n",
            "🛣️ 프레임 826: 12개 차선 감지\n",
            "🛣️ 프레임 828: 14개 차선 감지\n",
            "🛣️ 프레임 830: 14개 차선 감지\n",
            "🛣️ 프레임 832: 16개 차선 감지\n",
            "🛣️ 프레임 834: 12개 차선 감지\n",
            "🛣️ 프레임 836: 10개 차선 감지\n",
            "🛣️ 프레임 838: 12개 차선 감지\n",
            "🛣️ 프레임 840: 15개 차선 감지\n",
            "🛣️ 프레임 842: 12개 차선 감지\n",
            "🛣️ 프레임 844: 12개 차선 감지\n",
            "🛣️ 프레임 846: 9개 차선 감지\n",
            "🛣️ 프레임 848: 12개 차선 감지\n",
            "🛣️ 프레임 850: 12개 차선 감지\n",
            "🛣️ 프레임 852: 9개 차선 감지\n",
            "🛣️ 프레임 854: 13개 차선 감지\n",
            "🛣️ 프레임 856: 11개 차선 감지\n",
            "🛣️ 프레임 858: 15개 차선 감지\n",
            "🛣️ 프레임 860: 11개 차선 감지\n",
            "🛣️ 프레임 862: 10개 차선 감지\n",
            "🛣️ 프레임 864: 14개 차선 감지\n",
            "🛣️ 프레임 866: 11개 차선 감지\n",
            "🛣️ 프레임 868: 8개 차선 감지\n",
            "🛣️ 프레임 870: 9개 차선 감지\n",
            "🛣️ 프레임 872: 6개 차선 감지\n",
            "🛣️ 프레임 874: 9개 차선 감지\n",
            "🛣️ 프레임 876: 8개 차선 감지\n",
            "🛣️ 프레임 878: 10개 차선 감지\n",
            "🛣️ 프레임 880: 11개 차선 감지\n",
            "🛣️ 프레임 882: 11개 차선 감지\n",
            "🛣️ 프레임 884: 7개 차선 감지\n",
            "🛣️ 프레임 886: 7개 차선 감지\n",
            "🛣️ 프레임 888: 7개 차선 감지\n",
            "🛣️ 프레임 890: 9개 차선 감지\n",
            "🛣️ 프레임 892: 6개 차선 감지\n",
            "🛣️ 프레임 894: 3개 차선 감지\n",
            "🛣️ 프레임 896: 6개 차선 감지\n",
            "🛣️ 프레임 898: 6개 차선 감지\n",
            "🛣️ 프레임 900: 7개 차선 감지\n",
            "📊 진행률: 23.9% (총 차선 감지: 6014개)\n",
            "🛣️ 프레임 902: 9개 차선 감지\n",
            "🛣️ 프레임 904: 9개 차선 감지\n",
            "🛣️ 프레임 906: 6개 차선 감지\n",
            "🛣️ 프레임 908: 5개 차선 감지\n",
            "🛣️ 프레임 910: 5개 차선 감지\n",
            "🛣️ 프레임 912: 5개 차선 감지\n",
            "🛣️ 프레임 914: 6개 차선 감지\n",
            "🛣️ 프레임 916: 4개 차선 감지\n",
            "🛣️ 프레임 918: 8개 차선 감지\n",
            "🛣️ 프레임 920: 3개 차선 감지\n",
            "🛣️ 프레임 922: 5개 차선 감지\n",
            "🛣️ 프레임 924: 5개 차선 감지\n",
            "🛣️ 프레임 926: 4개 차선 감지\n",
            "🛣️ 프레임 928: 7개 차선 감지\n",
            "🛣️ 프레임 930: 5개 차선 감지\n",
            "🛣️ 프레임 932: 6개 차선 감지\n",
            "🛣️ 프레임 934: 6개 차선 감지\n",
            "🛣️ 프레임 936: 6개 차선 감지\n",
            "🛣️ 프레임 938: 5개 차선 감지\n",
            "🛣️ 프레임 940: 3개 차선 감지\n",
            "🛣️ 프레임 942: 5개 차선 감지\n",
            "🛣️ 프레임 944: 5개 차선 감지\n",
            "🛣️ 프레임 946: 5개 차선 감지\n",
            "🛣️ 프레임 948: 3개 차선 감지\n",
            "🛣️ 프레임 950: 3개 차선 감지\n",
            "🛣️ 프레임 952: 5개 차선 감지\n",
            "🛣️ 프레임 954: 4개 차선 감지\n",
            "🛣️ 프레임 956: 4개 차선 감지\n",
            "🛣️ 프레임 958: 6개 차선 감지\n",
            "🛣️ 프레임 960: 3개 차선 감지\n",
            "🛣️ 프레임 962: 5개 차선 감지\n",
            "🛣️ 프레임 964: 4개 차선 감지\n",
            "🛣️ 프레임 966: 2개 차선 감지\n",
            "🛣️ 프레임 968: 4개 차선 감지\n",
            "🛣️ 프레임 970: 6개 차선 감지\n",
            "🛣️ 프레임 972: 5개 차선 감지\n",
            "🛣️ 프레임 974: 5개 차선 감지\n",
            "🛣️ 프레임 976: 5개 차선 감지\n",
            "🛣️ 프레임 978: 3개 차선 감지\n",
            "🛣️ 프레임 980: 1개 차선 감지\n",
            "🛣️ 프레임 982: 4개 차선 감지\n",
            "🛣️ 프레임 984: 2개 차선 감지\n",
            "🛣️ 프레임 986: 2개 차선 감지\n",
            "🛣️ 프레임 988: 3개 차선 감지\n",
            "🛣️ 프레임 990: 5개 차선 감지\n",
            "🛣️ 프레임 992: 5개 차선 감지\n",
            "🛣️ 프레임 994: 4개 차선 감지\n",
            "🛣️ 프레임 996: 5개 차선 감지\n",
            "🛣️ 프레임 998: 6개 차선 감지\n",
            "🛣️ 프레임 1000: 4개 차선 감지\n",
            "🛣️ 프레임 1002: 4개 차선 감지\n",
            "🛣️ 프레임 1004: 4개 차선 감지\n",
            "🛣️ 프레임 1006: 4개 차선 감지\n",
            "🛣️ 프레임 1008: 3개 차선 감지\n",
            "🛣️ 프레임 1010: 3개 차선 감지\n",
            "🛣️ 프레임 1012: 2개 차선 감지\n",
            "🛣️ 프레임 1014: 2개 차선 감지\n",
            "🛣️ 프레임 1016: 2개 차선 감지\n",
            "🛣️ 프레임 1018: 2개 차선 감지\n",
            "🛣️ 프레임 1020: 3개 차선 감지\n",
            "🛣️ 프레임 1022: 2개 차선 감지\n",
            "🛣️ 프레임 1024: 2개 차선 감지\n",
            "🛣️ 프레임 1026: 2개 차선 감지\n",
            "🛣️ 프레임 1028: 1개 차선 감지\n",
            "🛣️ 프레임 1030: 2개 차선 감지\n",
            "🛣️ 프레임 1032: 2개 차선 감지\n",
            "🛣️ 프레임 1034: 4개 차선 감지\n",
            "🛣️ 프레임 1036: 4개 차선 감지\n",
            "🛣️ 프레임 1038: 3개 차선 감지\n",
            "🛣️ 프레임 1040: 2개 차선 감지\n",
            "🛣️ 프레임 1042: 4개 차선 감지\n",
            "🛣️ 프레임 1044: 2개 차선 감지\n",
            "🛣️ 프레임 1046: 5개 차선 감지\n",
            "🛣️ 프레임 1048: 1개 차선 감지\n",
            "🛣️ 프레임 1050: 3개 차선 감지\n",
            "📊 진행률: 27.9% (총 차선 감지: 6317개)\n",
            "🛣️ 프레임 1052: 2개 차선 감지\n",
            "🛣️ 프레임 1054: 1개 차선 감지\n",
            "🛣️ 프레임 1056: 2개 차선 감지\n",
            "🛣️ 프레임 1058: 3개 차선 감지\n",
            "🛣️ 프레임 1062: 3개 차선 감지\n",
            "🛣️ 프레임 1064: 3개 차선 감지\n",
            "🛣️ 프레임 1066: 3개 차선 감지\n",
            "🛣️ 프레임 1068: 5개 차선 감지\n",
            "🛣️ 프레임 1070: 2개 차선 감지\n",
            "🛣️ 프레임 1072: 3개 차선 감지\n",
            "🛣️ 프레임 1074: 4개 차선 감지\n",
            "🛣️ 프레임 1076: 4개 차선 감지\n",
            "🛣️ 프레임 1078: 4개 차선 감지\n",
            "🛣️ 프레임 1080: 5개 차선 감지\n",
            "🛣️ 프레임 1082: 2개 차선 감지\n",
            "🛣️ 프레임 1086: 1개 차선 감지\n",
            "🛣️ 프레임 1088: 1개 차선 감지\n",
            "🛣️ 프레임 1090: 1개 차선 감지\n",
            "🛣️ 프레임 1094: 1개 차선 감지\n",
            "🛣️ 프레임 1096: 2개 차선 감지\n",
            "🛣️ 프레임 1098: 1개 차선 감지\n",
            "🛣️ 프레임 1102: 1개 차선 감지\n",
            "🛣️ 프레임 1106: 1개 차선 감지\n",
            "🛣️ 프레임 1108: 1개 차선 감지\n",
            "🛣️ 프레임 1110: 2개 차선 감지\n",
            "🛣️ 프레임 1112: 1개 차선 감지\n",
            "🛣️ 프레임 1114: 1개 차선 감지\n",
            "🛣️ 프레임 1118: 1개 차선 감지\n",
            "🛣️ 프레임 1120: 3개 차선 감지\n",
            "🛣️ 프레임 1126: 1개 차선 감지\n",
            "🛣️ 프레임 1128: 1개 차선 감지\n",
            "🛣️ 프레임 1130: 1개 차선 감지\n",
            "🛣️ 프레임 1136: 2개 차선 감지\n",
            "🛣️ 프레임 1138: 1개 차선 감지\n",
            "🛣️ 프레임 1140: 2개 차선 감지\n",
            "🛣️ 프레임 1142: 4개 차선 감지\n",
            "🛣️ 프레임 1144: 2개 차선 감지\n",
            "🛣️ 프레임 1146: 2개 차선 감지\n",
            "🛣️ 프레임 1148: 1개 차선 감지\n",
            "🛣️ 프레임 1150: 2개 차선 감지\n",
            "🛣️ 프레임 1152: 1개 차선 감지\n",
            "🛣️ 프레임 1154: 3개 차선 감지\n",
            "🛣️ 프레임 1156: 1개 차선 감지\n",
            "🛣️ 프레임 1158: 2개 차선 감지\n",
            "🛣️ 프레임 1160: 1개 차선 감지\n",
            "🛣️ 프레임 1162: 3개 차선 감지\n",
            "🛣️ 프레임 1164: 3개 차선 감지\n",
            "🛣️ 프레임 1166: 4개 차선 감지\n",
            "🛣️ 프레임 1168: 3개 차선 감지\n",
            "🛣️ 프레임 1170: 4개 차선 감지\n",
            "🛣️ 프레임 1172: 2개 차선 감지\n",
            "🛣️ 프레임 1174: 2개 차선 감지\n",
            "🛣️ 프레임 1176: 1개 차선 감지\n",
            "🛣️ 프레임 1178: 3개 차선 감지\n",
            "🛣️ 프레임 1180: 2개 차선 감지\n",
            "🛣️ 프레임 1182: 1개 차선 감지\n",
            "🛣️ 프레임 1184: 1개 차선 감지\n",
            "🛣️ 프레임 1188: 1개 차선 감지\n",
            "🛣️ 프레임 1190: 2개 차선 감지\n",
            "🛣️ 프레임 1192: 2개 차선 감지\n",
            "🛣️ 프레임 1194: 2개 차선 감지\n",
            "🛣️ 프레임 1196: 2개 차선 감지\n",
            "🛣️ 프레임 1198: 4개 차선 감지\n",
            "🛣️ 프레임 1200: 2개 차선 감지\n",
            "📊 진행률: 31.9% (총 차선 감지: 6452개)\n",
            "🛣️ 프레임 1202: 5개 차선 감지\n",
            "🛣️ 프레임 1204: 3개 차선 감지\n",
            "🛣️ 프레임 1206: 2개 차선 감지\n",
            "🛣️ 프레임 1208: 3개 차선 감지\n",
            "🛣️ 프레임 1210: 4개 차선 감지\n",
            "🛣️ 프레임 1212: 4개 차선 감지\n",
            "🛣️ 프레임 1214: 4개 차선 감지\n",
            "🛣️ 프레임 1216: 2개 차선 감지\n",
            "🛣️ 프레임 1218: 3개 차선 감지\n",
            "🛣️ 프레임 1220: 5개 차선 감지\n",
            "🛣️ 프레임 1222: 4개 차선 감지\n",
            "🛣️ 프레임 1224: 5개 차선 감지\n",
            "🛣️ 프레임 1226: 3개 차선 감지\n",
            "🛣️ 프레임 1228: 3개 차선 감지\n",
            "🛣️ 프레임 1230: 3개 차선 감지\n",
            "🛣️ 프레임 1232: 7개 차선 감지\n",
            "🛣️ 프레임 1234: 3개 차선 감지\n",
            "🛣️ 프레임 1236: 6개 차선 감지\n",
            "🛣️ 프레임 1238: 3개 차선 감지\n",
            "🛣️ 프레임 1240: 3개 차선 감지\n",
            "🛣️ 프레임 1242: 3개 차선 감지\n",
            "🛣️ 프레임 1244: 8개 차선 감지\n",
            "🛣️ 프레임 1246: 5개 차선 감지\n",
            "🛣️ 프레임 1248: 4개 차선 감지\n",
            "🛣️ 프레임 1250: 3개 차선 감지\n",
            "🛣️ 프레임 1252: 2개 차선 감지\n",
            "🛣️ 프레임 1254: 3개 차선 감지\n",
            "🛣️ 프레임 1256: 2개 차선 감지\n",
            "🛣️ 프레임 1258: 3개 차선 감지\n",
            "🛣️ 프레임 1260: 2개 차선 감지\n",
            "🛣️ 프레임 1262: 3개 차선 감지\n",
            "🛣️ 프레임 1264: 3개 차선 감지\n",
            "🛣️ 프레임 1266: 3개 차선 감지\n",
            "🛣️ 프레임 1268: 4개 차선 감지\n",
            "🛣️ 프레임 1270: 2개 차선 감지\n",
            "🛣️ 프레임 1272: 3개 차선 감지\n",
            "🛣️ 프레임 1274: 4개 차선 감지\n",
            "🛣️ 프레임 1276: 3개 차선 감지\n",
            "🛣️ 프레임 1278: 3개 차선 감지\n",
            "🛣️ 프레임 1280: 4개 차선 감지\n",
            "🛣️ 프레임 1282: 4개 차선 감지\n",
            "🛣️ 프레임 1284: 5개 차선 감지\n",
            "🛣️ 프레임 1286: 5개 차선 감지\n",
            "🛣️ 프레임 1288: 5개 차선 감지\n",
            "🛣️ 프레임 1290: 4개 차선 감지\n",
            "🛣️ 프레임 1292: 8개 차선 감지\n",
            "🛣️ 프레임 1294: 3개 차선 감지\n",
            "🛣️ 프레임 1296: 4개 차선 감지\n",
            "🛣️ 프레임 1298: 4개 차선 감지\n",
            "🛣️ 프레임 1300: 3개 차선 감지\n",
            "🛣️ 프레임 1302: 3개 차선 감지\n",
            "🛣️ 프레임 1304: 6개 차선 감지\n",
            "🛣️ 프레임 1306: 4개 차선 감지\n",
            "🛣️ 프레임 1308: 4개 차선 감지\n",
            "🛣️ 프레임 1310: 3개 차선 감지\n",
            "🛣️ 프레임 1312: 1개 차선 감지\n",
            "🛣️ 프레임 1314: 3개 차선 감지\n",
            "🛣️ 프레임 1316: 2개 차선 감지\n",
            "🛣️ 프레임 1318: 2개 차선 감지\n",
            "🛣️ 프레임 1320: 2개 차선 감지\n",
            "🛣️ 프레임 1322: 3개 차선 감지\n",
            "🛣️ 프레임 1324: 5개 차선 감지\n",
            "🛣️ 프레임 1326: 4개 차선 감지\n",
            "🛣️ 프레임 1328: 5개 차선 감지\n",
            "🛣️ 프레임 1330: 4개 차선 감지\n",
            "🛣️ 프레임 1332: 3개 차선 감지\n",
            "🛣️ 프레임 1334: 3개 차선 감지\n",
            "🛣️ 프레임 1336: 5개 차선 감지\n",
            "🛣️ 프레임 1338: 3개 차선 감지\n",
            "🛣️ 프레임 1340: 5개 차선 감지\n",
            "🛣️ 프레임 1342: 4개 차선 감지\n",
            "🛣️ 프레임 1344: 4개 차선 감지\n",
            "🛣️ 프레임 1346: 2개 차선 감지\n",
            "🛣️ 프레임 1348: 4개 차선 감지\n",
            "🛣️ 프레임 1350: 3개 차선 감지\n",
            "📊 진행률: 35.9% (총 차선 감지: 6726개)\n",
            "🛣️ 프레임 1352: 5개 차선 감지\n",
            "🛣️ 프레임 1354: 3개 차선 감지\n",
            "🛣️ 프레임 1356: 4개 차선 감지\n",
            "🛣️ 프레임 1358: 4개 차선 감지\n",
            "🛣️ 프레임 1360: 6개 차선 감지\n",
            "🛣️ 프레임 1362: 5개 차선 감지\n",
            "🛣️ 프레임 1364: 7개 차선 감지\n",
            "🛣️ 프레임 1366: 2개 차선 감지\n",
            "🛣️ 프레임 1368: 5개 차선 감지\n",
            "🛣️ 프레임 1370: 5개 차선 감지\n",
            "🛣️ 프레임 1372: 5개 차선 감지\n",
            "🛣️ 프레임 1374: 7개 차선 감지\n",
            "🛣️ 프레임 1376: 5개 차선 감지\n",
            "🛣️ 프레임 1378: 6개 차선 감지\n",
            "🛣️ 프레임 1380: 7개 차선 감지\n",
            "🛣️ 프레임 1382: 3개 차선 감지\n",
            "🛣️ 프레임 1384: 4개 차선 감지\n",
            "🛣️ 프레임 1386: 4개 차선 감지\n",
            "🛣️ 프레임 1388: 3개 차선 감지\n",
            "🛣️ 프레임 1390: 2개 차선 감지\n",
            "🛣️ 프레임 1392: 3개 차선 감지\n",
            "🛣️ 프레임 1394: 3개 차선 감지\n",
            "🛣️ 프레임 1396: 2개 차선 감지\n",
            "🛣️ 프레임 1398: 5개 차선 감지\n",
            "🛣️ 프레임 1400: 3개 차선 감지\n",
            "🛣️ 프레임 1402: 4개 차선 감지\n",
            "🛣️ 프레임 1404: 3개 차선 감지\n",
            "🛣️ 프레임 1406: 4개 차선 감지\n",
            "🛣️ 프레임 1408: 4개 차선 감지\n",
            "🛣️ 프레임 1410: 4개 차선 감지\n",
            "🛣️ 프레임 1412: 5개 차선 감지\n",
            "🛣️ 프레임 1414: 6개 차선 감지\n",
            "🛣️ 프레임 1416: 7개 차선 감지\n",
            "🛣️ 프레임 1418: 4개 차선 감지\n",
            "🛣️ 프레임 1420: 7개 차선 감지\n",
            "🛣️ 프레임 1422: 4개 차선 감지\n",
            "🛣️ 프레임 1424: 5개 차선 감지\n",
            "🛣️ 프레임 1426: 4개 차선 감지\n",
            "🛣️ 프레임 1428: 5개 차선 감지\n",
            "🛣️ 프레임 1430: 4개 차선 감지\n",
            "🛣️ 프레임 1432: 4개 차선 감지\n",
            "🛣️ 프레임 1434: 5개 차선 감지\n",
            "🛣️ 프레임 1436: 6개 차선 감지\n",
            "🛣️ 프레임 1438: 6개 차선 감지\n",
            "🛣️ 프레임 1440: 6개 차선 감지\n",
            "🛣️ 프레임 1442: 6개 차선 감지\n",
            "🛣️ 프레임 1444: 4개 차선 감지\n",
            "🛣️ 프레임 1446: 7개 차선 감지\n",
            "🛣️ 프레임 1448: 8개 차선 감지\n",
            "🛣️ 프레임 1450: 6개 차선 감지\n",
            "🛣️ 프레임 1452: 6개 차선 감지\n",
            "🛣️ 프레임 1454: 4개 차선 감지\n",
            "🛣️ 프레임 1456: 7개 차선 감지\n",
            "🛣️ 프레임 1458: 7개 차선 감지\n",
            "🛣️ 프레임 1460: 7개 차선 감지\n",
            "🛣️ 프레임 1462: 7개 차선 감지\n",
            "🛣️ 프레임 1464: 6개 차선 감지\n",
            "🛣️ 프레임 1466: 5개 차선 감지\n",
            "🛣️ 프레임 1468: 6개 차선 감지\n",
            "🛣️ 프레임 1470: 8개 차선 감지\n",
            "🛣️ 프레임 1472: 7개 차선 감지\n",
            "🛣️ 프레임 1474: 5개 차선 감지\n",
            "🛣️ 프레임 1476: 5개 차선 감지\n",
            "🛣️ 프레임 1478: 7개 차선 감지\n",
            "🛣️ 프레임 1480: 8개 차선 감지\n",
            "🛣️ 프레임 1482: 9개 차선 감지\n",
            "🛣️ 프레임 1484: 7개 차선 감지\n",
            "🛣️ 프레임 1486: 10개 차선 감지\n",
            "🛣️ 프레임 1488: 7개 차선 감지\n",
            "🛣️ 프레임 1490: 8개 차선 감지\n",
            "🛣️ 프레임 1492: 9개 차선 감지\n",
            "🛣️ 프레임 1494: 12개 차선 감지\n",
            "🛣️ 프레임 1496: 10개 차선 감지\n",
            "🛣️ 프레임 1498: 10개 차선 감지\n",
            "🛣️ 프레임 1500: 10개 차선 감지\n",
            "📊 진행률: 39.9% (총 차선 감지: 7149개)\n",
            "🛣️ 프레임 1502: 10개 차선 감지\n",
            "🛣️ 프레임 1504: 15개 차선 감지\n",
            "🛣️ 프레임 1506: 11개 차선 감지\n",
            "🛣️ 프레임 1508: 11개 차선 감지\n",
            "🛣️ 프레임 1510: 7개 차선 감지\n",
            "🛣️ 프레임 1512: 8개 차선 감지\n",
            "🛣️ 프레임 1514: 6개 차선 감지\n",
            "🛣️ 프레임 1516: 10개 차선 감지\n",
            "🛣️ 프레임 1518: 10개 차선 감지\n",
            "🛣️ 프레임 1520: 8개 차선 감지\n",
            "🛣️ 프레임 1522: 7개 차선 감지\n",
            "🛣️ 프레임 1524: 8개 차선 감지\n",
            "🛣️ 프레임 1526: 8개 차선 감지\n",
            "🛣️ 프레임 1528: 8개 차선 감지\n",
            "🛣️ 프레임 1530: 7개 차선 감지\n",
            "🛣️ 프레임 1532: 9개 차선 감지\n",
            "🛣️ 프레임 1534: 9개 차선 감지\n",
            "🛣️ 프레임 1536: 12개 차선 감지\n",
            "🛣️ 프레임 1538: 12개 차선 감지\n",
            "🛣️ 프레임 1540: 12개 차선 감지\n",
            "🛣️ 프레임 1542: 12개 차선 감지\n",
            "🛣️ 프레임 1544: 12개 차선 감지\n",
            "🛣️ 프레임 1546: 10개 차선 감지\n",
            "🛣️ 프레임 1548: 8개 차선 감지\n",
            "🛣️ 프레임 1550: 13개 차선 감지\n",
            "🛣️ 프레임 1552: 13개 차선 감지\n",
            "🛣️ 프레임 1554: 9개 차선 감지\n",
            "🛣️ 프레임 1556: 10개 차선 감지\n",
            "🛣️ 프레임 1558: 11개 차선 감지\n",
            "🛣️ 프레임 1560: 10개 차선 감지\n",
            "🛣️ 프레임 1562: 9개 차선 감지\n",
            "🛣️ 프레임 1564: 9개 차선 감지\n",
            "🛣️ 프레임 1566: 7개 차선 감지\n",
            "🛣️ 프레임 1568: 9개 차선 감지\n",
            "🛣️ 프레임 1570: 6개 차선 감지\n",
            "🛣️ 프레임 1572: 6개 차선 감지\n",
            "🛣️ 프레임 1574: 9개 차선 감지\n",
            "🛣️ 프레임 1576: 9개 차선 감지\n",
            "🛣️ 프레임 1578: 5개 차선 감지\n",
            "🛣️ 프레임 1580: 8개 차선 감지\n",
            "🛣️ 프레임 1582: 8개 차선 감지\n",
            "🛣️ 프레임 1584: 7개 차선 감지\n",
            "🛣️ 프레임 1586: 10개 차선 감지\n",
            "🛣️ 프레임 1588: 6개 차선 감지\n",
            "🛣️ 프레임 1590: 5개 차선 감지\n",
            "🛣️ 프레임 1592: 6개 차선 감지\n",
            "🛣️ 프레임 1594: 8개 차선 감지\n",
            "🛣️ 프레임 1596: 7개 차선 감지\n",
            "🛣️ 프레임 1598: 7개 차선 감지\n",
            "🛣️ 프레임 1600: 2개 차선 감지\n",
            "🛣️ 프레임 1602: 4개 차선 감지\n",
            "🛣️ 프레임 1604: 4개 차선 감지\n",
            "🛣️ 프레임 1606: 1개 차선 감지\n",
            "🛣️ 프레임 1608: 2개 차선 감지\n",
            "🛣️ 프레임 1610: 4개 차선 감지\n",
            "🛣️ 프레임 1612: 5개 차선 감지\n",
            "🛣️ 프레임 1614: 3개 차선 감지\n",
            "🛣️ 프레임 1616: 4개 차선 감지\n",
            "🛣️ 프레임 1618: 4개 차선 감지\n",
            "🛣️ 프레임 1620: 5개 차선 감지\n",
            "🛣️ 프레임 1622: 1개 차선 감지\n",
            "🛣️ 프레임 1624: 5개 차선 감지\n",
            "🛣️ 프레임 1626: 3개 차선 감지\n",
            "🛣️ 프레임 1628: 8개 차선 감지\n",
            "🛣️ 프레임 1630: 6개 차선 감지\n",
            "🛣️ 프레임 1632: 9개 차선 감지\n",
            "🛣️ 프레임 1634: 5개 차선 감지\n",
            "🛣️ 프레임 1636: 3개 차선 감지\n",
            "🛣️ 프레임 1638: 3개 차선 감지\n",
            "🛣️ 프레임 1640: 3개 차선 감지\n",
            "🛣️ 프레임 1642: 3개 차선 감지\n",
            "🛣️ 프레임 1644: 2개 차선 감지\n",
            "🛣️ 프레임 1646: 4개 차선 감지\n",
            "🛣️ 프레임 1648: 4개 차선 감지\n",
            "🛣️ 프레임 1650: 5개 차선 감지\n",
            "📊 진행률: 43.9% (총 차선 감지: 7688개)\n",
            "🛣️ 프레임 1652: 5개 차선 감지\n",
            "🛣️ 프레임 1654: 5개 차선 감지\n",
            "🛣️ 프레임 1656: 5개 차선 감지\n",
            "🛣️ 프레임 1658: 7개 차선 감지\n",
            "🛣️ 프레임 1660: 7개 차선 감지\n",
            "🛣️ 프레임 1662: 4개 차선 감지\n",
            "🛣️ 프레임 1664: 6개 차선 감지\n",
            "🛣️ 프레임 1666: 7개 차선 감지\n",
            "🛣️ 프레임 1668: 7개 차선 감지\n",
            "🛣️ 프레임 1670: 6개 차선 감지\n",
            "🛣️ 프레임 1672: 6개 차선 감지\n",
            "🛣️ 프레임 1674: 6개 차선 감지\n",
            "🛣️ 프레임 1676: 7개 차선 감지\n",
            "🛣️ 프레임 1678: 7개 차선 감지\n",
            "🛣️ 프레임 1680: 11개 차선 감지\n",
            "🛣️ 프레임 1682: 4개 차선 감지\n",
            "🛣️ 프레임 1684: 6개 차선 감지\n",
            "🛣️ 프레임 1686: 5개 차선 감지\n",
            "🛣️ 프레임 1688: 5개 차선 감지\n",
            "🛣️ 프레임 1690: 7개 차선 감지\n",
            "🛣️ 프레임 1692: 3개 차선 감지\n",
            "🛣️ 프레임 1694: 7개 차선 감지\n",
            "🛣️ 프레임 1696: 4개 차선 감지\n",
            "🛣️ 프레임 1698: 4개 차선 감지\n",
            "🛣️ 프레임 1700: 5개 차선 감지\n",
            "🛣️ 프레임 1702: 6개 차선 감지\n",
            "🛣️ 프레임 1704: 6개 차선 감지\n",
            "🛣️ 프레임 1706: 6개 차선 감지\n",
            "🛣️ 프레임 1708: 6개 차선 감지\n",
            "🛣️ 프레임 1710: 4개 차선 감지\n",
            "🛣️ 프레임 1712: 8개 차선 감지\n",
            "🛣️ 프레임 1714: 7개 차선 감지\n",
            "🛣️ 프레임 1716: 7개 차선 감지\n",
            "🛣️ 프레임 1718: 10개 차선 감지\n",
            "🛣️ 프레임 1720: 13개 차선 감지\n",
            "🛣️ 프레임 1722: 12개 차선 감지\n",
            "🛣️ 프레임 1724: 14개 차선 감지\n",
            "🛣️ 프레임 1726: 14개 차선 감지\n",
            "🛣️ 프레임 1728: 13개 차선 감지\n",
            "🛣️ 프레임 1730: 13개 차선 감지\n",
            "🛣️ 프레임 1732: 13개 차선 감지\n",
            "🛣️ 프레임 1734: 13개 차선 감지\n",
            "🛣️ 프레임 1736: 11개 차선 감지\n",
            "🛣️ 프레임 1738: 10개 차선 감지\n",
            "🛣️ 프레임 1740: 14개 차선 감지\n",
            "🛣️ 프레임 1742: 13개 차선 감지\n",
            "🛣️ 프레임 1744: 15개 차선 감지\n",
            "🛣️ 프레임 1746: 12개 차선 감지\n",
            "🛣️ 프레임 1748: 15개 차선 감지\n",
            "🛣️ 프레임 1750: 16개 차선 감지\n",
            "🛣️ 프레임 1752: 15개 차선 감지\n",
            "🛣️ 프레임 1754: 17개 차선 감지\n",
            "🛣️ 프레임 1756: 14개 차선 감지\n",
            "🛣️ 프레임 1758: 14개 차선 감지\n",
            "🛣️ 프레임 1760: 14개 차선 감지\n",
            "🛣️ 프레임 1762: 14개 차선 감지\n",
            "🛣️ 프레임 1764: 15개 차선 감지\n",
            "🛣️ 프레임 1766: 14개 차선 감지\n",
            "🛣️ 프레임 1768: 18개 차선 감지\n",
            "🛣️ 프레임 1770: 18개 차선 감지\n",
            "🛣️ 프레임 1772: 22개 차선 감지\n",
            "🛣️ 프레임 1774: 26개 차선 감지\n",
            "🛣️ 프레임 1776: 23개 차선 감지\n",
            "🛣️ 프레임 1778: 20개 차선 감지\n",
            "🛣️ 프레임 1780: 19개 차선 감지\n",
            "🛣️ 프레임 1782: 19개 차선 감지\n",
            "🛣️ 프레임 1784: 19개 차선 감지\n",
            "🛣️ 프레임 1786: 20개 차선 감지\n",
            "🛣️ 프레임 1788: 13개 차선 감지\n",
            "🛣️ 프레임 1790: 20개 차선 감지\n",
            "🛣️ 프레임 1792: 20개 차선 감지\n",
            "🛣️ 프레임 1794: 22개 차선 감지\n",
            "🛣️ 프레임 1796: 18개 차선 감지\n",
            "🛣️ 프레임 1798: 14개 차선 감지\n",
            "🛣️ 프레임 1800: 17개 차선 감지\n",
            "📊 진행률: 47.9% (총 차선 감지: 8550개)\n",
            "🛣️ 프레임 1802: 19개 차선 감지\n",
            "🛣️ 프레임 1804: 16개 차선 감지\n",
            "🛣️ 프레임 1806: 15개 차선 감지\n",
            "🛣️ 프레임 1808: 17개 차선 감지\n",
            "🛣️ 프레임 1810: 16개 차선 감지\n",
            "🛣️ 프레임 1812: 22개 차선 감지\n",
            "🛣️ 프레임 1814: 17개 차선 감지\n",
            "🛣️ 프레임 1816: 15개 차선 감지\n",
            "🛣️ 프레임 1818: 18개 차선 감지\n",
            "🛣️ 프레임 1820: 15개 차선 감지\n",
            "🛣️ 프레임 1822: 17개 차선 감지\n",
            "🛣️ 프레임 1824: 19개 차선 감지\n",
            "🛣️ 프레임 1826: 19개 차선 감지\n",
            "🛣️ 프레임 1828: 21개 차선 감지\n",
            "🛣️ 프레임 1830: 17개 차선 감지\n",
            "🛣️ 프레임 1832: 18개 차선 감지\n",
            "🛣️ 프레임 1834: 22개 차선 감지\n",
            "🛣️ 프레임 1836: 21개 차선 감지\n",
            "🛣️ 프레임 1838: 16개 차선 감지\n",
            "🛣️ 프레임 1840: 22개 차선 감지\n",
            "🛣️ 프레임 1842: 22개 차선 감지\n",
            "🛣️ 프레임 1844: 20개 차선 감지\n",
            "🛣️ 프레임 1846: 19개 차선 감지\n",
            "🛣️ 프레임 1848: 21개 차선 감지\n",
            "🛣️ 프레임 1850: 20개 차선 감지\n",
            "🛣️ 프레임 1852: 20개 차선 감지\n",
            "🛣️ 프레임 1854: 18개 차선 감지\n",
            "🛣️ 프레임 1856: 18개 차선 감지\n",
            "🛣️ 프레임 1858: 17개 차선 감지\n",
            "🛣️ 프레임 1860: 18개 차선 감지\n",
            "🛣️ 프레임 1862: 17개 차선 감지\n",
            "🛣️ 프레임 1864: 20개 차선 감지\n",
            "🛣️ 프레임 1866: 21개 차선 감지\n",
            "🛣️ 프레임 1868: 17개 차선 감지\n",
            "🛣️ 프레임 1870: 22개 차선 감지\n",
            "🛣️ 프레임 1872: 22개 차선 감지\n",
            "🛣️ 프레임 1874: 22개 차선 감지\n",
            "🛣️ 프레임 1876: 19개 차선 감지\n",
            "🛣️ 프레임 1878: 19개 차선 감지\n",
            "🛣️ 프레임 1880: 16개 차선 감지\n",
            "🛣️ 프레임 1882: 20개 차선 감지\n",
            "🛣️ 프레임 1884: 16개 차선 감지\n",
            "🛣️ 프레임 1886: 17개 차선 감지\n",
            "🛣️ 프레임 1888: 17개 차선 감지\n",
            "🛣️ 프레임 1890: 20개 차선 감지\n",
            "🛣️ 프레임 1892: 26개 차선 감지\n",
            "🛣️ 프레임 1894: 28개 차선 감지\n",
            "🛣️ 프레임 1896: 19개 차선 감지\n",
            "🛣️ 프레임 1898: 18개 차선 감지\n",
            "🛣️ 프레임 1900: 16개 차선 감지\n",
            "🛣️ 프레임 1902: 17개 차선 감지\n",
            "🛣️ 프레임 1904: 15개 차선 감지\n",
            "🛣️ 프레임 1906: 11개 차선 감지\n",
            "🛣️ 프레임 1908: 8개 차선 감지\n",
            "🛣️ 프레임 1910: 9개 차선 감지\n",
            "🛣️ 프레임 1912: 10개 차선 감지\n",
            "🛣️ 프레임 1914: 8개 차선 감지\n",
            "🛣️ 프레임 1916: 10개 차선 감지\n",
            "🛣️ 프레임 1918: 7개 차선 감지\n",
            "🛣️ 프레임 1920: 8개 차선 감지\n",
            "🛣️ 프레임 1922: 6개 차선 감지\n",
            "🛣️ 프레임 1924: 6개 차선 감지\n",
            "🛣️ 프레임 1926: 5개 차선 감지\n",
            "🛣️ 프레임 1928: 10개 차선 감지\n",
            "🛣️ 프레임 1930: 11개 차선 감지\n",
            "🛣️ 프레임 1932: 8개 차선 감지\n",
            "🛣️ 프레임 1934: 11개 차선 감지\n",
            "🛣️ 프레임 1936: 12개 차선 감지\n",
            "🛣️ 프레임 1938: 11개 차선 감지\n",
            "🛣️ 프레임 1940: 12개 차선 감지\n",
            "🛣️ 프레임 1942: 11개 차선 감지\n",
            "🛣️ 프레임 1944: 13개 차선 감지\n",
            "🛣️ 프레임 1946: 12개 차선 감지\n",
            "🛣️ 프레임 1948: 12개 차선 감지\n",
            "🛣️ 프레임 1950: 19개 차선 감지\n",
            "📊 진행률: 51.9% (총 차선 감지: 9759개)\n",
            "🛣️ 프레임 1952: 22개 차선 감지\n",
            "🛣️ 프레임 1954: 25개 차선 감지\n",
            "🛣️ 프레임 1956: 18개 차선 감지\n",
            "🛣️ 프레임 1958: 18개 차선 감지\n",
            "🛣️ 프레임 1960: 18개 차선 감지\n",
            "🛣️ 프레임 1962: 13개 차선 감지\n",
            "🛣️ 프레임 1964: 7개 차선 감지\n",
            "🛣️ 프레임 1966: 5개 차선 감지\n",
            "🛣️ 프레임 1968: 8개 차선 감지\n",
            "🛣️ 프레임 1970: 8개 차선 감지\n",
            "🛣️ 프레임 1972: 7개 차선 감지\n",
            "🛣️ 프레임 1974: 12개 차선 감지\n",
            "🛣️ 프레임 1976: 8개 차선 감지\n",
            "🛣️ 프레임 1978: 8개 차선 감지\n",
            "🛣️ 프레임 1980: 10개 차선 감지\n",
            "🛣️ 프레임 1982: 8개 차선 감지\n",
            "🛣️ 프레임 1984: 11개 차선 감지\n",
            "🛣️ 프레임 1986: 9개 차선 감지\n",
            "🛣️ 프레임 1988: 7개 차선 감지\n",
            "🛣️ 프레임 1990: 12개 차선 감지\n",
            "🛣️ 프레임 1992: 11개 차선 감지\n",
            "🛣️ 프레임 1994: 6개 차선 감지\n",
            "🛣️ 프레임 1996: 6개 차선 감지\n",
            "🛣️ 프레임 1998: 8개 차선 감지\n",
            "🛣️ 프레임 2000: 8개 차선 감지\n",
            "🛣️ 프레임 2002: 11개 차선 감지\n",
            "🛣️ 프레임 2004: 7개 차선 감지\n",
            "🛣️ 프레임 2006: 10개 차선 감지\n",
            "🛣️ 프레임 2008: 9개 차선 감지\n",
            "🛣️ 프레임 2010: 9개 차선 감지\n",
            "🛣️ 프레임 2012: 8개 차선 감지\n",
            "🛣️ 프레임 2014: 10개 차선 감지\n",
            "🛣️ 프레임 2016: 8개 차선 감지\n",
            "🛣️ 프레임 2018: 10개 차선 감지\n",
            "🛣️ 프레임 2020: 10개 차선 감지\n",
            "🛣️ 프레임 2022: 12개 차선 감지\n",
            "🛣️ 프레임 2024: 12개 차선 감지\n",
            "🛣️ 프레임 2026: 10개 차선 감지\n",
            "🛣️ 프레임 2028: 11개 차선 감지\n",
            "🛣️ 프레임 2030: 9개 차선 감지\n",
            "🛣️ 프레임 2032: 7개 차선 감지\n",
            "🛣️ 프레임 2034: 6개 차선 감지\n",
            "🛣️ 프레임 2036: 6개 차선 감지\n",
            "🛣️ 프레임 2038: 6개 차선 감지\n",
            "🛣️ 프레임 2040: 5개 차선 감지\n",
            "🛣️ 프레임 2042: 9개 차선 감지\n",
            "🛣️ 프레임 2044: 7개 차선 감지\n",
            "🛣️ 프레임 2046: 8개 차선 감지\n",
            "🛣️ 프레임 2048: 5개 차선 감지\n",
            "🛣️ 프레임 2050: 6개 차선 감지\n",
            "🛣️ 프레임 2052: 6개 차선 감지\n",
            "🛣️ 프레임 2054: 6개 차선 감지\n",
            "🛣️ 프레임 2056: 5개 차선 감지\n",
            "🛣️ 프레임 2058: 3개 차선 감지\n",
            "🛣️ 프레임 2060: 4개 차선 감지\n",
            "🛣️ 프레임 2062: 4개 차선 감지\n",
            "🛣️ 프레임 2064: 6개 차선 감지\n",
            "🛣️ 프레임 2066: 4개 차선 감지\n",
            "🛣️ 프레임 2068: 8개 차선 감지\n",
            "🛣️ 프레임 2070: 8개 차선 감지\n",
            "🛣️ 프레임 2072: 7개 차선 감지\n",
            "🛣️ 프레임 2074: 7개 차선 감지\n",
            "🛣️ 프레임 2076: 5개 차선 감지\n",
            "🛣️ 프레임 2078: 7개 차선 감지\n",
            "🛣️ 프레임 2080: 7개 차선 감지\n",
            "🛣️ 프레임 2082: 4개 차선 감지\n",
            "🛣️ 프레임 2084: 6개 차선 감지\n",
            "🛣️ 프레임 2086: 7개 차선 감지\n",
            "🛣️ 프레임 2088: 7개 차선 감지\n",
            "🛣️ 프레임 2090: 9개 차선 감지\n",
            "🛣️ 프레임 2092: 7개 차선 감지\n",
            "🛣️ 프레임 2094: 6개 차선 감지\n",
            "🛣️ 프레임 2096: 8개 차선 감지\n",
            "🛣️ 프레임 2098: 8개 차선 감지\n",
            "🛣️ 프레임 2100: 6개 차선 감지\n",
            "📊 진행률: 55.9% (총 차선 감지: 10398개)\n",
            "🛣️ 프레임 2102: 8개 차선 감지\n",
            "🛣️ 프레임 2104: 7개 차선 감지\n",
            "🛣️ 프레임 2106: 6개 차선 감지\n",
            "🛣️ 프레임 2108: 6개 차선 감지\n",
            "🛣️ 프레임 2110: 8개 차선 감지\n",
            "🛣️ 프레임 2112: 8개 차선 감지\n",
            "🛣️ 프레임 2114: 6개 차선 감지\n",
            "🛣️ 프레임 2116: 6개 차선 감지\n",
            "🛣️ 프레임 2118: 10개 차선 감지\n",
            "🛣️ 프레임 2120: 8개 차선 감지\n",
            "🛣️ 프레임 2122: 8개 차선 감지\n",
            "🛣️ 프레임 2124: 8개 차선 감지\n",
            "🛣️ 프레임 2126: 8개 차선 감지\n",
            "🛣️ 프레임 2128: 8개 차선 감지\n",
            "🛣️ 프레임 2130: 8개 차선 감지\n",
            "🛣️ 프레임 2132: 9개 차선 감지\n",
            "🛣️ 프레임 2134: 8개 차선 감지\n",
            "🛣️ 프레임 2136: 11개 차선 감지\n",
            "🛣️ 프레임 2138: 7개 차선 감지\n",
            "🛣️ 프레임 2140: 6개 차선 감지\n",
            "🛣️ 프레임 2142: 7개 차선 감지\n",
            "🛣️ 프레임 2144: 7개 차선 감지\n",
            "🛣️ 프레임 2146: 8개 차선 감지\n",
            "🛣️ 프레임 2148: 9개 차선 감지\n",
            "🛣️ 프레임 2150: 5개 차선 감지\n",
            "🛣️ 프레임 2152: 6개 차선 감지\n",
            "🛣️ 프레임 2154: 10개 차선 감지\n",
            "🛣️ 프레임 2156: 12개 차선 감지\n",
            "🛣️ 프레임 2158: 12개 차선 감지\n",
            "🛣️ 프레임 2160: 15개 차선 감지\n",
            "🛣️ 프레임 2162: 14개 차선 감지\n",
            "🛣️ 프레임 2164: 8개 차선 감지\n",
            "🛣️ 프레임 2166: 10개 차선 감지\n",
            "🛣️ 프레임 2168: 8개 차선 감지\n",
            "🛣️ 프레임 2170: 10개 차선 감지\n",
            "🛣️ 프레임 2172: 11개 차선 감지\n",
            "🛣️ 프레임 2174: 9개 차선 감지\n",
            "🛣️ 프레임 2176: 9개 차선 감지\n",
            "🛣️ 프레임 2178: 10개 차선 감지\n",
            "🛣️ 프레임 2180: 10개 차선 감지\n",
            "🛣️ 프레임 2182: 10개 차선 감지\n",
            "🛣️ 프레임 2184: 9개 차선 감지\n",
            "🛣️ 프레임 2186: 6개 차선 감지\n",
            "🛣️ 프레임 2188: 11개 차선 감지\n",
            "🛣️ 프레임 2190: 12개 차선 감지\n",
            "🛣️ 프레임 2192: 13개 차선 감지\n",
            "🛣️ 프레임 2194: 11개 차선 감지\n",
            "🛣️ 프레임 2196: 8개 차선 감지\n",
            "🛣️ 프레임 2198: 8개 차선 감지\n",
            "🛣️ 프레임 2200: 10개 차선 감지\n",
            "🛣️ 프레임 2202: 11개 차선 감지\n",
            "🛣️ 프레임 2204: 9개 차선 감지\n",
            "🛣️ 프레임 2206: 9개 차선 감지\n",
            "🛣️ 프레임 2208: 10개 차선 감지\n",
            "🛣️ 프레임 2210: 10개 차선 감지\n",
            "🛣️ 프레임 2212: 9개 차선 감지\n",
            "🛣️ 프레임 2214: 9개 차선 감지\n",
            "🛣️ 프레임 2216: 10개 차선 감지\n",
            "🛣️ 프레임 2218: 9개 차선 감지\n",
            "🛣️ 프레임 2220: 9개 차선 감지\n",
            "🛣️ 프레임 2222: 8개 차선 감지\n",
            "🛣️ 프레임 2224: 8개 차선 감지\n",
            "🛣️ 프레임 2226: 7개 차선 감지\n",
            "🛣️ 프레임 2228: 11개 차선 감지\n",
            "🛣️ 프레임 2230: 8개 차선 감지\n",
            "🛣️ 프레임 2232: 9개 차선 감지\n",
            "🛣️ 프레임 2234: 7개 차선 감지\n",
            "🛣️ 프레임 2236: 7개 차선 감지\n",
            "🛣️ 프레임 2238: 5개 차선 감지\n",
            "🛣️ 프레임 2240: 4개 차선 감지\n",
            "🛣️ 프레임 2242: 8개 차선 감지\n",
            "🛣️ 프레임 2244: 6개 차선 감지\n",
            "🛣️ 프레임 2246: 7개 차선 감지\n",
            "🛣️ 프레임 2248: 4개 차선 감지\n",
            "🛣️ 프레임 2250: 6개 차선 감지\n",
            "📊 진행률: 59.8% (총 차선 감지: 11040개)\n",
            "🛣️ 프레임 2252: 6개 차선 감지\n",
            "🛣️ 프레임 2254: 4개 차선 감지\n",
            "🛣️ 프레임 2256: 5개 차선 감지\n",
            "🛣️ 프레임 2258: 6개 차선 감지\n",
            "🛣️ 프레임 2260: 9개 차선 감지\n",
            "🛣️ 프레임 2262: 7개 차선 감지\n",
            "🛣️ 프레임 2264: 8개 차선 감지\n",
            "🛣️ 프레임 2266: 9개 차선 감지\n",
            "🛣️ 프레임 2268: 13개 차선 감지\n",
            "🛣️ 프레임 2270: 11개 차선 감지\n",
            "🛣️ 프레임 2272: 12개 차선 감지\n",
            "🛣️ 프레임 2274: 11개 차선 감지\n",
            "🛣️ 프레임 2276: 8개 차선 감지\n",
            "🛣️ 프레임 2278: 9개 차선 감지\n",
            "🛣️ 프레임 2280: 10개 차선 감지\n",
            "🛣️ 프레임 2282: 11개 차선 감지\n",
            "🛣️ 프레임 2284: 7개 차선 감지\n",
            "🛣️ 프레임 2286: 9개 차선 감지\n",
            "🛣️ 프레임 2288: 7개 차선 감지\n",
            "🛣️ 프레임 2290: 7개 차선 감지\n",
            "🛣️ 프레임 2292: 7개 차선 감지\n",
            "🛣️ 프레임 2294: 7개 차선 감지\n",
            "🛣️ 프레임 2296: 4개 차선 감지\n",
            "🛣️ 프레임 2298: 5개 차선 감지\n",
            "🛣️ 프레임 2300: 4개 차선 감지\n",
            "🛣️ 프레임 2302: 7개 차선 감지\n",
            "🛣️ 프레임 2304: 6개 차선 감지\n",
            "🛣️ 프레임 2306: 7개 차선 감지\n",
            "🛣️ 프레임 2308: 8개 차선 감지\n",
            "🛣️ 프레임 2310: 7개 차선 감지\n",
            "🛣️ 프레임 2312: 6개 차선 감지\n",
            "🛣️ 프레임 2314: 7개 차선 감지\n",
            "🛣️ 프레임 2316: 6개 차선 감지\n",
            "🛣️ 프레임 2318: 6개 차선 감지\n",
            "🛣️ 프레임 2320: 4개 차선 감지\n",
            "🛣️ 프레임 2322: 7개 차선 감지\n",
            "🛣️ 프레임 2324: 6개 차선 감지\n",
            "🛣️ 프레임 2326: 7개 차선 감지\n",
            "🛣️ 프레임 2328: 8개 차선 감지\n",
            "🛣️ 프레임 2330: 4개 차선 감지\n",
            "🛣️ 프레임 2332: 6개 차선 감지\n",
            "🛣️ 프레임 2334: 6개 차선 감지\n",
            "🛣️ 프레임 2336: 6개 차선 감지\n",
            "🛣️ 프레임 2338: 5개 차선 감지\n",
            "🛣️ 프레임 2340: 7개 차선 감지\n",
            "🛣️ 프레임 2342: 9개 차선 감지\n",
            "🛣️ 프레임 2344: 8개 차선 감지\n",
            "🛣️ 프레임 2346: 7개 차선 감지\n",
            "🛣️ 프레임 2348: 7개 차선 감지\n",
            "🛣️ 프레임 2350: 7개 차선 감지\n",
            "🛣️ 프레임 2352: 9개 차선 감지\n",
            "🛣️ 프레임 2354: 5개 차선 감지\n",
            "🛣️ 프레임 2356: 6개 차선 감지\n",
            "🛣️ 프레임 2358: 5개 차선 감지\n",
            "🛣️ 프레임 2360: 7개 차선 감지\n",
            "🛣️ 프레임 2362: 8개 차선 감지\n",
            "🛣️ 프레임 2364: 7개 차선 감지\n",
            "🛣️ 프레임 2366: 6개 차선 감지\n",
            "🛣️ 프레임 2368: 6개 차선 감지\n",
            "🛣️ 프레임 2370: 6개 차선 감지\n",
            "🛣️ 프레임 2372: 6개 차선 감지\n",
            "🛣️ 프레임 2374: 5개 차선 감지\n",
            "🛣️ 프레임 2376: 5개 차선 감지\n",
            "🛣️ 프레임 2378: 7개 차선 감지\n",
            "🛣️ 프레임 2380: 4개 차선 감지\n",
            "🛣️ 프레임 2382: 5개 차선 감지\n",
            "🛣️ 프레임 2384: 6개 차선 감지\n",
            "🛣️ 프레임 2386: 5개 차선 감지\n",
            "🛣️ 프레임 2388: 9개 차선 감지\n",
            "🛣️ 프레임 2390: 7개 차선 감지\n",
            "🛣️ 프레임 2392: 6개 차선 감지\n",
            "🛣️ 프레임 2394: 6개 차선 감지\n",
            "🛣️ 프레임 2396: 7개 차선 감지\n",
            "🛣️ 프레임 2398: 8개 차선 감지\n",
            "🛣️ 프레임 2400: 8개 차선 감지\n",
            "📊 진행률: 63.8% (총 차선 감지: 11559개)\n",
            "🛣️ 프레임 2402: 6개 차선 감지\n",
            "🛣️ 프레임 2404: 5개 차선 감지\n",
            "🛣️ 프레임 2406: 5개 차선 감지\n",
            "🛣️ 프레임 2408: 7개 차선 감지\n",
            "🛣️ 프레임 2410: 7개 차선 감지\n",
            "🛣️ 프레임 2412: 6개 차선 감지\n",
            "🛣️ 프레임 2414: 6개 차선 감지\n",
            "🛣️ 프레임 2416: 7개 차선 감지\n",
            "🛣️ 프레임 2418: 4개 차선 감지\n",
            "🛣️ 프레임 2420: 5개 차선 감지\n",
            "🛣️ 프레임 2422: 4개 차선 감지\n",
            "🛣️ 프레임 2424: 6개 차선 감지\n",
            "🛣️ 프레임 2426: 6개 차선 감지\n",
            "🛣️ 프레임 2428: 4개 차선 감지\n",
            "🛣️ 프레임 2430: 4개 차선 감지\n",
            "🛣️ 프레임 2432: 9개 차선 감지\n",
            "🛣️ 프레임 2434: 5개 차선 감지\n",
            "🛣️ 프레임 2436: 7개 차선 감지\n",
            "🛣️ 프레임 2438: 6개 차선 감지\n",
            "🛣️ 프레임 2440: 6개 차선 감지\n",
            "🛣️ 프레임 2442: 8개 차선 감지\n",
            "🛣️ 프레임 2444: 6개 차선 감지\n",
            "🛣️ 프레임 2446: 8개 차선 감지\n",
            "🛣️ 프레임 2448: 9개 차선 감지\n",
            "🛣️ 프레임 2450: 5개 차선 감지\n",
            "🛣️ 프레임 2452: 2개 차선 감지\n",
            "🛣️ 프레임 2454: 5개 차선 감지\n",
            "🛣️ 프레임 2456: 8개 차선 감지\n",
            "🛣️ 프레임 2458: 7개 차선 감지\n",
            "🛣️ 프레임 2460: 6개 차선 감지\n",
            "🛣️ 프레임 2462: 6개 차선 감지\n",
            "🛣️ 프레임 2464: 4개 차선 감지\n",
            "🛣️ 프레임 2466: 5개 차선 감지\n",
            "🛣️ 프레임 2468: 6개 차선 감지\n",
            "🛣️ 프레임 2470: 6개 차선 감지\n",
            "🛣️ 프레임 2472: 8개 차선 감지\n",
            "🛣️ 프레임 2474: 7개 차선 감지\n",
            "🛣️ 프레임 2476: 5개 차선 감지\n",
            "🛣️ 프레임 2478: 4개 차선 감지\n",
            "🛣️ 프레임 2480: 6개 차선 감지\n",
            "🛣️ 프레임 2482: 8개 차선 감지\n",
            "🛣️ 프레임 2484: 8개 차선 감지\n",
            "🛣️ 프레임 2486: 5개 차선 감지\n",
            "🛣️ 프레임 2488: 6개 차선 감지\n",
            "🛣️ 프레임 2490: 8개 차선 감지\n",
            "🛣️ 프레임 2492: 7개 차선 감지\n",
            "🛣️ 프레임 2494: 9개 차선 감지\n",
            "🛣️ 프레임 2496: 10개 차선 감지\n",
            "🛣️ 프레임 2498: 10개 차선 감지\n",
            "🛣️ 프레임 2500: 7개 차선 감지\n",
            "🛣️ 프레임 2502: 9개 차선 감지\n",
            "🛣️ 프레임 2504: 10개 차선 감지\n",
            "🛣️ 프레임 2506: 9개 차선 감지\n",
            "🛣️ 프레임 2508: 11개 차선 감지\n",
            "🛣️ 프레임 2510: 10개 차선 감지\n",
            "🛣️ 프레임 2512: 12개 차선 감지\n",
            "🛣️ 프레임 2514: 8개 차선 감지\n",
            "🛣️ 프레임 2516: 7개 차선 감지\n",
            "🛣️ 프레임 2518: 7개 차선 감지\n",
            "🛣️ 프레임 2520: 7개 차선 감지\n",
            "🛣️ 프레임 2522: 8개 차선 감지\n",
            "🛣️ 프레임 2524: 5개 차선 감지\n",
            "🛣️ 프레임 2526: 6개 차선 감지\n",
            "🛣️ 프레임 2528: 7개 차선 감지\n",
            "🛣️ 프레임 2530: 8개 차선 감지\n",
            "🛣️ 프레임 2532: 8개 차선 감지\n",
            "🛣️ 프레임 2534: 9개 차선 감지\n",
            "🛣️ 프레임 2536: 9개 차선 감지\n",
            "🛣️ 프레임 2538: 8개 차선 감지\n",
            "🛣️ 프레임 2540: 8개 차선 감지\n",
            "🛣️ 프레임 2542: 7개 차선 감지\n",
            "🛣️ 프레임 2544: 10개 차선 감지\n",
            "🛣️ 프레임 2546: 10개 차선 감지\n",
            "🛣️ 프레임 2548: 9개 차선 감지\n",
            "🛣️ 프레임 2550: 13개 차선 감지\n",
            "📊 진행률: 67.8% (총 차선 감지: 12088개)\n",
            "🛣️ 프레임 2552: 15개 차선 감지\n",
            "🛣️ 프레임 2554: 13개 차선 감지\n",
            "🛣️ 프레임 2556: 12개 차선 감지\n",
            "🛣️ 프레임 2558: 7개 차선 감지\n",
            "🛣️ 프레임 2560: 10개 차선 감지\n",
            "🛣️ 프레임 2562: 6개 차선 감지\n",
            "🛣️ 프레임 2564: 7개 차선 감지\n",
            "🛣️ 프레임 2566: 7개 차선 감지\n",
            "🛣️ 프레임 2568: 7개 차선 감지\n",
            "🛣️ 프레임 2570: 6개 차선 감지\n",
            "🛣️ 프레임 2572: 7개 차선 감지\n",
            "🛣️ 프레임 2574: 8개 차선 감지\n",
            "🛣️ 프레임 2576: 7개 차선 감지\n",
            "🛣️ 프레임 2578: 10개 차선 감지\n",
            "🛣️ 프레임 2580: 12개 차선 감지\n",
            "🛣️ 프레임 2582: 14개 차선 감지\n",
            "🛣️ 프레임 2584: 15개 차선 감지\n",
            "🛣️ 프레임 2586: 16개 차선 감지\n",
            "🛣️ 프레임 2588: 19개 차선 감지\n",
            "🛣️ 프레임 2590: 17개 차선 감지\n",
            "🛣️ 프레임 2592: 16개 차선 감지\n",
            "🛣️ 프레임 2594: 17개 차선 감지\n",
            "🛣️ 프레임 2596: 19개 차선 감지\n",
            "🛣️ 프레임 2598: 14개 차선 감지\n",
            "🛣️ 프레임 2600: 19개 차선 감지\n",
            "🛣️ 프레임 2602: 19개 차선 감지\n",
            "🛣️ 프레임 2604: 15개 차선 감지\n",
            "🛣️ 프레임 2606: 19개 차선 감지\n",
            "🛣️ 프레임 2608: 20개 차선 감지\n",
            "🛣️ 프레임 2610: 14개 차선 감지\n",
            "🛣️ 프레임 2612: 19개 차선 감지\n",
            "🛣️ 프레임 2614: 29개 차선 감지\n",
            "🛣️ 프레임 2616: 31개 차선 감지\n",
            "🛣️ 프레임 2618: 33개 차선 감지\n",
            "🛣️ 프레임 2620: 29개 차선 감지\n",
            "🛣️ 프레임 2622: 24개 차선 감지\n",
            "🛣️ 프레임 2624: 30개 차선 감지\n",
            "🛣️ 프레임 2626: 26개 차선 감지\n",
            "🛣️ 프레임 2628: 19개 차선 감지\n",
            "🛣️ 프레임 2630: 15개 차선 감지\n",
            "🛣️ 프레임 2632: 13개 차선 감지\n",
            "🛣️ 프레임 2634: 9개 차선 감지\n",
            "🛣️ 프레임 2636: 9개 차선 감지\n",
            "🛣️ 프레임 2638: 9개 차선 감지\n",
            "🛣️ 프레임 2640: 9개 차선 감지\n",
            "🛣️ 프레임 2642: 8개 차선 감지\n",
            "🛣️ 프레임 2644: 7개 차선 감지\n",
            "🛣️ 프레임 2646: 5개 차선 감지\n",
            "🛣️ 프레임 2648: 6개 차선 감지\n",
            "🛣️ 프레임 2650: 10개 차선 감지\n",
            "🛣️ 프레임 2652: 9개 차선 감지\n",
            "🛣️ 프레임 2654: 10개 차선 감지\n",
            "🛣️ 프레임 2656: 11개 차선 감지\n",
            "🛣️ 프레임 2658: 8개 차선 감지\n",
            "🛣️ 프레임 2660: 9개 차선 감지\n",
            "🛣️ 프레임 2662: 8개 차선 감지\n",
            "🛣️ 프레임 2664: 10개 차선 감지\n",
            "🛣️ 프레임 2666: 7개 차선 감지\n",
            "🛣️ 프레임 2668: 5개 차선 감지\n",
            "🛣️ 프레임 2670: 4개 차선 감지\n",
            "🛣️ 프레임 2672: 7개 차선 감지\n",
            "🛣️ 프레임 2674: 8개 차선 감지\n",
            "🛣️ 프레임 2676: 6개 차선 감지\n",
            "🛣️ 프레임 2678: 7개 차선 감지\n",
            "🛣️ 프레임 2680: 8개 차선 감지\n",
            "🛣️ 프레임 2682: 6개 차선 감지\n",
            "🛣️ 프레임 2684: 7개 차선 감지\n",
            "🛣️ 프레임 2686: 6개 차선 감지\n",
            "🛣️ 프레임 2688: 6개 차선 감지\n",
            "🛣️ 프레임 2690: 7개 차선 감지\n",
            "🛣️ 프레임 2692: 7개 차선 감지\n",
            "🛣️ 프레임 2694: 7개 차선 감지\n",
            "🛣️ 프레임 2696: 6개 차선 감지\n",
            "🛣️ 프레임 2698: 6개 차선 감지\n",
            "🛣️ 프레임 2700: 7개 차선 감지\n",
            "📊 진행률: 71.8% (총 차선 감지: 12997개)\n",
            "🛣️ 프레임 2702: 8개 차선 감지\n",
            "🛣️ 프레임 2704: 7개 차선 감지\n",
            "🛣️ 프레임 2706: 6개 차선 감지\n",
            "🛣️ 프레임 2708: 9개 차선 감지\n",
            "🛣️ 프레임 2710: 7개 차선 감지\n",
            "🛣️ 프레임 2712: 9개 차선 감지\n",
            "🛣️ 프레임 2714: 8개 차선 감지\n",
            "🛣️ 프레임 2716: 10개 차선 감지\n",
            "🛣️ 프레임 2718: 9개 차선 감지\n",
            "🛣️ 프레임 2720: 11개 차선 감지\n",
            "🛣️ 프레임 2722: 11개 차선 감지\n",
            "🛣️ 프레임 2724: 16개 차선 감지\n",
            "🛣️ 프레임 2726: 16개 차선 감지\n",
            "🛣️ 프레임 2728: 13개 차선 감지\n",
            "🛣️ 프레임 2730: 17개 차선 감지\n",
            "🛣️ 프레임 2732: 18개 차선 감지\n",
            "🛣️ 프레임 2734: 18개 차선 감지\n",
            "🛣️ 프레임 2736: 16개 차선 감지\n",
            "🛣️ 프레임 2738: 17개 차선 감지\n",
            "🛣️ 프레임 2740: 14개 차선 감지\n",
            "🛣️ 프레임 2742: 17개 차선 감지\n",
            "🛣️ 프레임 2744: 17개 차선 감지\n",
            "🛣️ 프레임 2746: 14개 차선 감지\n",
            "🛣️ 프레임 2748: 18개 차선 감지\n",
            "🛣️ 프레임 2750: 19개 차선 감지\n",
            "🛣️ 프레임 2752: 17개 차선 감지\n",
            "🛣️ 프레임 2754: 18개 차선 감지\n",
            "🛣️ 프레임 2756: 22개 차선 감지\n",
            "🛣️ 프레임 2758: 18개 차선 감지\n",
            "🛣️ 프레임 2760: 21개 차선 감지\n",
            "🛣️ 프레임 2762: 20개 차선 감지\n",
            "🛣️ 프레임 2764: 14개 차선 감지\n",
            "🛣️ 프레임 2766: 16개 차선 감지\n",
            "🛣️ 프레임 2768: 14개 차선 감지\n",
            "🛣️ 프레임 2770: 17개 차선 감지\n",
            "🛣️ 프레임 2772: 14개 차선 감지\n",
            "🛣️ 프레임 2774: 14개 차선 감지\n",
            "🛣️ 프레임 2776: 15개 차선 감지\n",
            "🛣️ 프레임 2778: 18개 차선 감지\n",
            "🛣️ 프레임 2780: 18개 차선 감지\n",
            "🛣️ 프레임 2782: 18개 차선 감지\n",
            "🛣️ 프레임 2784: 16개 차선 감지\n",
            "🛣️ 프레임 2786: 21개 차선 감지\n",
            "🛣️ 프레임 2788: 18개 차선 감지\n",
            "🛣️ 프레임 2790: 16개 차선 감지\n",
            "🛣️ 프레임 2792: 17개 차선 감지\n",
            "🛣️ 프레임 2794: 22개 차선 감지\n",
            "🛣️ 프레임 2796: 20개 차선 감지\n",
            "🛣️ 프레임 2798: 20개 차선 감지\n",
            "🛣️ 프레임 2800: 19개 차선 감지\n",
            "🛣️ 프레임 2802: 19개 차선 감지\n",
            "🛣️ 프레임 2804: 24개 차선 감지\n",
            "🛣️ 프레임 2806: 24개 차선 감지\n",
            "🛣️ 프레임 2808: 23개 차선 감지\n",
            "🛣️ 프레임 2810: 25개 차선 감지\n",
            "🛣️ 프레임 2812: 22개 차선 감지\n",
            "🛣️ 프레임 2814: 18개 차선 감지\n",
            "🛣️ 프레임 2816: 18개 차선 감지\n",
            "🛣️ 프레임 2818: 23개 차선 감지\n",
            "🛣️ 프레임 2820: 18개 차선 감지\n",
            "🛣️ 프레임 2822: 14개 차선 감지\n",
            "🛣️ 프레임 2824: 12개 차선 감지\n",
            "🛣️ 프레임 2826: 13개 차선 감지\n",
            "🛣️ 프레임 2828: 11개 차선 감지\n",
            "🛣️ 프레임 2830: 11개 차선 감지\n",
            "🛣️ 프레임 2832: 10개 차선 감지\n",
            "🛣️ 프레임 2834: 9개 차선 감지\n",
            "🛣️ 프레임 2836: 11개 차선 감지\n",
            "🛣️ 프레임 2838: 12개 차선 감지\n",
            "🛣️ 프레임 2840: 14개 차선 감지\n",
            "🛣️ 프레임 2842: 14개 차선 감지\n",
            "🛣️ 프레임 2844: 12개 차선 감지\n",
            "🛣️ 프레임 2846: 11개 차선 감지\n",
            "🛣️ 프레임 2848: 10개 차선 감지\n",
            "🛣️ 프레임 2850: 11개 차선 감지\n",
            "📊 진행률: 75.8% (총 차선 감지: 14154개)\n",
            "🛣️ 프레임 2852: 10개 차선 감지\n",
            "🛣️ 프레임 2854: 11개 차선 감지\n",
            "🛣️ 프레임 2856: 11개 차선 감지\n",
            "🛣️ 프레임 2858: 10개 차선 감지\n",
            "🛣️ 프레임 2860: 11개 차선 감지\n",
            "🛣️ 프레임 2862: 10개 차선 감지\n",
            "🛣️ 프레임 2864: 9개 차선 감지\n",
            "🛣️ 프레임 2866: 11개 차선 감지\n",
            "🛣️ 프레임 2868: 14개 차선 감지\n",
            "🛣️ 프레임 2870: 9개 차선 감지\n",
            "🛣️ 프레임 2872: 10개 차선 감지\n",
            "🛣️ 프레임 2874: 8개 차선 감지\n",
            "🛣️ 프레임 2876: 9개 차선 감지\n",
            "🛣️ 프레임 2878: 10개 차선 감지\n",
            "🛣️ 프레임 2880: 10개 차선 감지\n",
            "🛣️ 프레임 2882: 11개 차선 감지\n",
            "🛣️ 프레임 2884: 9개 차선 감지\n",
            "🛣️ 프레임 2886: 9개 차선 감지\n",
            "🛣️ 프레임 2888: 11개 차선 감지\n",
            "🛣️ 프레임 2890: 10개 차선 감지\n",
            "🛣️ 프레임 2892: 10개 차선 감지\n",
            "🛣️ 프레임 2894: 11개 차선 감지\n",
            "🛣️ 프레임 2896: 11개 차선 감지\n",
            "🛣️ 프레임 2898: 12개 차선 감지\n",
            "🛣️ 프레임 2900: 13개 차선 감지\n",
            "🛣️ 프레임 2902: 12개 차선 감지\n",
            "🛣️ 프레임 2904: 10개 차선 감지\n",
            "🛣️ 프레임 2906: 10개 차선 감지\n",
            "🛣️ 프레임 2908: 10개 차선 감지\n",
            "🛣️ 프레임 2910: 9개 차선 감지\n",
            "🛣️ 프레임 2912: 9개 차선 감지\n",
            "🛣️ 프레임 2914: 9개 차선 감지\n",
            "🛣️ 프레임 2916: 10개 차선 감지\n",
            "🛣️ 프레임 2918: 12개 차선 감지\n",
            "🛣️ 프레임 2920: 10개 차선 감지\n",
            "🛣️ 프레임 2922: 10개 차선 감지\n",
            "🛣️ 프레임 2924: 7개 차선 감지\n",
            "🛣️ 프레임 2926: 8개 차선 감지\n",
            "🛣️ 프레임 2928: 10개 차선 감지\n",
            "🛣️ 프레임 2930: 11개 차선 감지\n",
            "🛣️ 프레임 2932: 11개 차선 감지\n",
            "🛣️ 프레임 2934: 12개 차선 감지\n",
            "🛣️ 프레임 2936: 13개 차선 감지\n",
            "🛣️ 프레임 2938: 11개 차선 감지\n",
            "🛣️ 프레임 2940: 10개 차선 감지\n",
            "🛣️ 프레임 2942: 12개 차선 감지\n",
            "🛣️ 프레임 2944: 12개 차선 감지\n",
            "🛣️ 프레임 2946: 12개 차선 감지\n",
            "🛣️ 프레임 2948: 12개 차선 감지\n",
            "🛣️ 프레임 2950: 12개 차선 감지\n",
            "🛣️ 프레임 2952: 13개 차선 감지\n",
            "🛣️ 프레임 2954: 10개 차선 감지\n",
            "🛣️ 프레임 2956: 11개 차선 감지\n",
            "🛣️ 프레임 2958: 12개 차선 감지\n",
            "🛣️ 프레임 2960: 10개 차선 감지\n",
            "🛣️ 프레임 2962: 11개 차선 감지\n",
            "🛣️ 프레임 2964: 12개 차선 감지\n",
            "🛣️ 프레임 2966: 12개 차선 감지\n",
            "🛣️ 프레임 2968: 10개 차선 감지\n",
            "🛣️ 프레임 2970: 8개 차선 감지\n",
            "🛣️ 프레임 2972: 10개 차선 감지\n",
            "🛣️ 프레임 2974: 9개 차선 감지\n",
            "🛣️ 프레임 2976: 12개 차선 감지\n",
            "🛣️ 프레임 2978: 10개 차선 감지\n",
            "🛣️ 프레임 2980: 10개 차선 감지\n",
            "🛣️ 프레임 2982: 10개 차선 감지\n",
            "🛣️ 프레임 2984: 9개 차선 감지\n",
            "🛣️ 프레임 2986: 10개 차선 감지\n",
            "🛣️ 프레임 2988: 10개 차선 감지\n",
            "🛣️ 프레임 2990: 10개 차선 감지\n",
            "🛣️ 프레임 2992: 7개 차선 감지\n",
            "🛣️ 프레임 2994: 7개 차선 감지\n",
            "🛣️ 프레임 2996: 7개 차선 감지\n",
            "🛣️ 프레임 2998: 7개 차선 감지\n",
            "🛣️ 프레임 3000: 4개 차선 감지\n",
            "📊 진행률: 79.8% (총 차선 감지: 14919개)\n",
            "🛣️ 프레임 3002: 7개 차선 감지\n",
            "🛣️ 프레임 3004: 7개 차선 감지\n",
            "🛣️ 프레임 3006: 6개 차선 감지\n",
            "🛣️ 프레임 3008: 4개 차선 감지\n",
            "🛣️ 프레임 3010: 6개 차선 감지\n",
            "🛣️ 프레임 3012: 5개 차선 감지\n",
            "🛣️ 프레임 3014: 5개 차선 감지\n",
            "🛣️ 프레임 3016: 6개 차선 감지\n",
            "🛣️ 프레임 3018: 5개 차선 감지\n",
            "🛣️ 프레임 3020: 5개 차선 감지\n",
            "🛣️ 프레임 3022: 6개 차선 감지\n",
            "🛣️ 프레임 3024: 9개 차선 감지\n",
            "🛣️ 프레임 3026: 8개 차선 감지\n",
            "🛣️ 프레임 3028: 7개 차선 감지\n",
            "🛣️ 프레임 3030: 8개 차선 감지\n",
            "🛣️ 프레임 3032: 9개 차선 감지\n",
            "🛣️ 프레임 3034: 9개 차선 감지\n",
            "🛣️ 프레임 3036: 9개 차선 감지\n",
            "🛣️ 프레임 3038: 7개 차선 감지\n",
            "🛣️ 프레임 3040: 9개 차선 감지\n",
            "🛣️ 프레임 3042: 8개 차선 감지\n",
            "🛣️ 프레임 3044: 8개 차선 감지\n",
            "🛣️ 프레임 3046: 8개 차선 감지\n",
            "🛣️ 프레임 3048: 9개 차선 감지\n",
            "🛣️ 프레임 3050: 8개 차선 감지\n",
            "🛣️ 프레임 3052: 9개 차선 감지\n",
            "🛣️ 프레임 3054: 10개 차선 감지\n",
            "🛣️ 프레임 3056: 7개 차선 감지\n",
            "🛣️ 프레임 3058: 8개 차선 감지\n",
            "🛣️ 프레임 3060: 11개 차선 감지\n",
            "🛣️ 프레임 3062: 8개 차선 감지\n",
            "🛣️ 프레임 3064: 7개 차선 감지\n",
            "🛣️ 프레임 3066: 9개 차선 감지\n",
            "🛣️ 프레임 3068: 9개 차선 감지\n",
            "🛣️ 프레임 3070: 10개 차선 감지\n",
            "🛣️ 프레임 3072: 8개 차선 감지\n",
            "🛣️ 프레임 3074: 9개 차선 감지\n",
            "🛣️ 프레임 3076: 7개 차선 감지\n",
            "🛣️ 프레임 3078: 10개 차선 감지\n",
            "🛣️ 프레임 3080: 8개 차선 감지\n",
            "🛣️ 프레임 3082: 7개 차선 감지\n",
            "🛣️ 프레임 3084: 10개 차선 감지\n",
            "🛣️ 프레임 3086: 9개 차선 감지\n",
            "🛣️ 프레임 3088: 9개 차선 감지\n",
            "🛣️ 프레임 3090: 7개 차선 감지\n",
            "🛣️ 프레임 3092: 8개 차선 감지\n",
            "🛣️ 프레임 3094: 7개 차선 감지\n",
            "🛣️ 프레임 3096: 8개 차선 감지\n",
            "🛣️ 프레임 3098: 9개 차선 감지\n",
            "🛣️ 프레임 3100: 7개 차선 감지\n",
            "🛣️ 프레임 3102: 7개 차선 감지\n",
            "🛣️ 프레임 3104: 7개 차선 감지\n",
            "🛣️ 프레임 3106: 7개 차선 감지\n",
            "🛣️ 프레임 3108: 8개 차선 감지\n",
            "🛣️ 프레임 3110: 7개 차선 감지\n",
            "🛣️ 프레임 3112: 6개 차선 감지\n",
            "🛣️ 프레임 3114: 6개 차선 감지\n",
            "🛣️ 프레임 3116: 8개 차선 감지\n",
            "🛣️ 프레임 3118: 9개 차선 감지\n",
            "🛣️ 프레임 3120: 9개 차선 감지\n",
            "🛣️ 프레임 3122: 9개 차선 감지\n",
            "🛣️ 프레임 3124: 9개 차선 감지\n",
            "🛣️ 프레임 3126: 9개 차선 감지\n",
            "🛣️ 프레임 3128: 10개 차선 감지\n",
            "🛣️ 프레임 3130: 10개 차선 감지\n",
            "🛣️ 프레임 3132: 10개 차선 감지\n",
            "🛣️ 프레임 3134: 9개 차선 감지\n",
            "🛣️ 프레임 3136: 8개 차선 감지\n",
            "🛣️ 프레임 3138: 8개 차선 감지\n",
            "🛣️ 프레임 3140: 6개 차선 감지\n",
            "🛣️ 프레임 3142: 6개 차선 감지\n",
            "🛣️ 프레임 3144: 6개 차선 감지\n",
            "🛣️ 프레임 3146: 7개 차선 감지\n",
            "🛣️ 프레임 3148: 8개 차선 감지\n",
            "🛣️ 프레임 3150: 7개 차선 감지\n",
            "📊 진행률: 83.8% (총 차선 감지: 15504개)\n",
            "🛣️ 프레임 3152: 6개 차선 감지\n",
            "🛣️ 프레임 3154: 6개 차선 감지\n",
            "🛣️ 프레임 3156: 7개 차선 감지\n",
            "🛣️ 프레임 3158: 9개 차선 감지\n",
            "🛣️ 프레임 3160: 7개 차선 감지\n",
            "🛣️ 프레임 3162: 10개 차선 감지\n",
            "🛣️ 프레임 3164: 8개 차선 감지\n",
            "🛣️ 프레임 3166: 9개 차선 감지\n",
            "🛣️ 프레임 3168: 10개 차선 감지\n",
            "🛣️ 프레임 3170: 7개 차선 감지\n",
            "🛣️ 프레임 3172: 7개 차선 감지\n",
            "🛣️ 프레임 3174: 6개 차선 감지\n",
            "🛣️ 프레임 3176: 8개 차선 감지\n",
            "🛣️ 프레임 3178: 7개 차선 감지\n",
            "🛣️ 프레임 3180: 7개 차선 감지\n",
            "🛣️ 프레임 3182: 7개 차선 감지\n",
            "🛣️ 프레임 3184: 7개 차선 감지\n",
            "🛣️ 프레임 3186: 8개 차선 감지\n",
            "🛣️ 프레임 3188: 7개 차선 감지\n",
            "🛣️ 프레임 3190: 7개 차선 감지\n",
            "🛣️ 프레임 3192: 7개 차선 감지\n",
            "🛣️ 프레임 3194: 7개 차선 감지\n",
            "🛣️ 프레임 3196: 7개 차선 감지\n",
            "🛣️ 프레임 3198: 7개 차선 감지\n",
            "🛣️ 프레임 3200: 7개 차선 감지\n",
            "🛣️ 프레임 3202: 6개 차선 감지\n",
            "🛣️ 프레임 3204: 7개 차선 감지\n",
            "🛣️ 프레임 3206: 7개 차선 감지\n",
            "🛣️ 프레임 3208: 7개 차선 감지\n",
            "🛣️ 프레임 3210: 7개 차선 감지\n",
            "🛣️ 프레임 3212: 7개 차선 감지\n",
            "🛣️ 프레임 3214: 7개 차선 감지\n",
            "🛣️ 프레임 3216: 7개 차선 감지\n",
            "🛣️ 프레임 3218: 7개 차선 감지\n",
            "🛣️ 프레임 3220: 7개 차선 감지\n",
            "🛣️ 프레임 3222: 6개 차선 감지\n",
            "🛣️ 프레임 3224: 5개 차선 감지\n",
            "🛣️ 프레임 3226: 5개 차선 감지\n",
            "🛣️ 프레임 3228: 7개 차선 감지\n",
            "🛣️ 프레임 3230: 7개 차선 감지\n",
            "🛣️ 프레임 3232: 7개 차선 감지\n",
            "🛣️ 프레임 3234: 6개 차선 감지\n",
            "🛣️ 프레임 3236: 6개 차선 감지\n",
            "🛣️ 프레임 3238: 7개 차선 감지\n",
            "🛣️ 프레임 3240: 7개 차선 감지\n",
            "🛣️ 프레임 3242: 7개 차선 감지\n",
            "🛣️ 프레임 3244: 8개 차선 감지\n",
            "🛣️ 프레임 3246: 7개 차선 감지\n",
            "🛣️ 프레임 3248: 7개 차선 감지\n",
            "🛣️ 프레임 3250: 7개 차선 감지\n",
            "🛣️ 프레임 3252: 7개 차선 감지\n",
            "🛣️ 프레임 3254: 7개 차선 감지\n",
            "🛣️ 프레임 3256: 7개 차선 감지\n",
            "🛣️ 프레임 3258: 7개 차선 감지\n",
            "🛣️ 프레임 3260: 7개 차선 감지\n",
            "🛣️ 프레임 3262: 7개 차선 감지\n",
            "🛣️ 프레임 3264: 7개 차선 감지\n",
            "🛣️ 프레임 3266: 7개 차선 감지\n",
            "🛣️ 프레임 3268: 7개 차선 감지\n",
            "🛣️ 프레임 3270: 7개 차선 감지\n",
            "🛣️ 프레임 3272: 7개 차선 감지\n",
            "🛣️ 프레임 3274: 7개 차선 감지\n",
            "🛣️ 프레임 3276: 7개 차선 감지\n",
            "🛣️ 프레임 3278: 7개 차선 감지\n",
            "🛣️ 프레임 3280: 7개 차선 감지\n",
            "🛣️ 프레임 3282: 7개 차선 감지\n",
            "🛣️ 프레임 3284: 7개 차선 감지\n",
            "🛣️ 프레임 3286: 8개 차선 감지\n",
            "🛣️ 프레임 3288: 7개 차선 감지\n",
            "🛣️ 프레임 3290: 7개 차선 감지\n",
            "🛣️ 프레임 3292: 7개 차선 감지\n",
            "🛣️ 프레임 3294: 7개 차선 감지\n",
            "🛣️ 프레임 3296: 8개 차선 감지\n",
            "🛣️ 프레임 3298: 7개 차선 감지\n",
            "🛣️ 프레임 3300: 9개 차선 감지\n",
            "📊 진행률: 87.8% (총 차선 감지: 16036개)\n",
            "🛣️ 프레임 3302: 8개 차선 감지\n",
            "🛣️ 프레임 3304: 7개 차선 감지\n",
            "🛣️ 프레임 3306: 6개 차선 감지\n",
            "🛣️ 프레임 3308: 7개 차선 감지\n",
            "🛣️ 프레임 3310: 6개 차선 감지\n",
            "🛣️ 프레임 3312: 6개 차선 감지\n",
            "🛣️ 프레임 3314: 6개 차선 감지\n",
            "🛣️ 프레임 3316: 6개 차선 감지\n",
            "🛣️ 프레임 3318: 6개 차선 감지\n",
            "🛣️ 프레임 3320: 6개 차선 감지\n",
            "🛣️ 프레임 3322: 6개 차선 감지\n",
            "🛣️ 프레임 3324: 6개 차선 감지\n",
            "🛣️ 프레임 3326: 5개 차선 감지\n",
            "🛣️ 프레임 3328: 6개 차선 감지\n",
            "🛣️ 프레임 3330: 6개 차선 감지\n",
            "🛣️ 프레임 3332: 8개 차선 감지\n",
            "🛣️ 프레임 3334: 7개 차선 감지\n",
            "🛣️ 프레임 3336: 6개 차선 감지\n",
            "🛣️ 프레임 3338: 7개 차선 감지\n",
            "🛣️ 프레임 3340: 7개 차선 감지\n",
            "🛣️ 프레임 3342: 7개 차선 감지\n",
            "🛣️ 프레임 3344: 7개 차선 감지\n",
            "🛣️ 프레임 3346: 8개 차선 감지\n",
            "🛣️ 프레임 3348: 9개 차선 감지\n",
            "🛣️ 프레임 3350: 9개 차선 감지\n",
            "🛣️ 프레임 3352: 9개 차선 감지\n",
            "🛣️ 프레임 3354: 10개 차선 감지\n",
            "🛣️ 프레임 3356: 9개 차선 감지\n",
            "🛣️ 프레임 3358: 9개 차선 감지\n",
            "🛣️ 프레임 3360: 8개 차선 감지\n",
            "🛣️ 프레임 3362: 11개 차선 감지\n",
            "🛣️ 프레임 3364: 11개 차선 감지\n",
            "🛣️ 프레임 3366: 8개 차선 감지\n",
            "🛣️ 프레임 3368: 9개 차선 감지\n",
            "🛣️ 프레임 3370: 9개 차선 감지\n",
            "🛣️ 프레임 3372: 9개 차선 감지\n",
            "🛣️ 프레임 3374: 8개 차선 감지\n",
            "🛣️ 프레임 3376: 8개 차선 감지\n",
            "🛣️ 프레임 3378: 8개 차선 감지\n",
            "🛣️ 프레임 3380: 9개 차선 감지\n",
            "🛣️ 프레임 3382: 9개 차선 감지\n",
            "🛣️ 프레임 3384: 8개 차선 감지\n",
            "🛣️ 프레임 3386: 9개 차선 감지\n",
            "🛣️ 프레임 3388: 9개 차선 감지\n",
            "🛣️ 프레임 3390: 9개 차선 감지\n",
            "🛣️ 프레임 3392: 9개 차선 감지\n",
            "🛣️ 프레임 3394: 9개 차선 감지\n",
            "🛣️ 프레임 3396: 9개 차선 감지\n",
            "🛣️ 프레임 3398: 8개 차선 감지\n",
            "🛣️ 프레임 3400: 9개 차선 감지\n",
            "🛣️ 프레임 3402: 9개 차선 감지\n",
            "🛣️ 프레임 3404: 9개 차선 감지\n",
            "🛣️ 프레임 3406: 8개 차선 감지\n",
            "🛣️ 프레임 3408: 8개 차선 감지\n",
            "🛣️ 프레임 3410: 8개 차선 감지\n",
            "🛣️ 프레임 3412: 8개 차선 감지\n",
            "🛣️ 프레임 3414: 9개 차선 감지\n",
            "🛣️ 프레임 3416: 9개 차선 감지\n",
            "🛣️ 프레임 3418: 9개 차선 감지\n",
            "🛣️ 프레임 3420: 9개 차선 감지\n",
            "🛣️ 프레임 3422: 9개 차선 감지\n",
            "🛣️ 프레임 3424: 9개 차선 감지\n",
            "🛣️ 프레임 3426: 8개 차선 감지\n",
            "🛣️ 프레임 3428: 8개 차선 감지\n",
            "🛣️ 프레임 3430: 8개 차선 감지\n",
            "🛣️ 프레임 3432: 8개 차선 감지\n",
            "🛣️ 프레임 3434: 8개 차선 감지\n",
            "🛣️ 프레임 3436: 9개 차선 감지\n",
            "🛣️ 프레임 3438: 7개 차선 감지\n",
            "🛣️ 프레임 3440: 10개 차선 감지\n",
            "🛣️ 프레임 3442: 9개 차선 감지\n",
            "🛣️ 프레임 3444: 9개 차선 감지\n",
            "🛣️ 프레임 3446: 9개 차선 감지\n",
            "🛣️ 프레임 3448: 8개 차선 감지\n",
            "🛣️ 프레임 3450: 9개 차선 감지\n",
            "📊 진행률: 91.8% (총 차선 감지: 16641개)\n",
            "🛣️ 프레임 3452: 9개 차선 감지\n",
            "🛣️ 프레임 3454: 8개 차선 감지\n",
            "🛣️ 프레임 3456: 9개 차선 감지\n",
            "🛣️ 프레임 3458: 7개 차선 감지\n",
            "🛣️ 프레임 3460: 8개 차선 감지\n",
            "🛣️ 프레임 3462: 10개 차선 감지\n",
            "🛣️ 프레임 3464: 8개 차선 감지\n",
            "🛣️ 프레임 3466: 9개 차선 감지\n",
            "🛣️ 프레임 3468: 9개 차선 감지\n",
            "🛣️ 프레임 3470: 7개 차선 감지\n",
            "🛣️ 프레임 3472: 7개 차선 감지\n",
            "🛣️ 프레임 3474: 7개 차선 감지\n",
            "🛣️ 프레임 3476: 7개 차선 감지\n",
            "🛣️ 프레임 3478: 7개 차선 감지\n",
            "🛣️ 프레임 3480: 7개 차선 감지\n",
            "🛣️ 프레임 3482: 7개 차선 감지\n",
            "🛣️ 프레임 3484: 7개 차선 감지\n",
            "🛣️ 프레임 3486: 7개 차선 감지\n",
            "🛣️ 프레임 3488: 8개 차선 감지\n",
            "🛣️ 프레임 3490: 8개 차선 감지\n",
            "🛣️ 프레임 3492: 8개 차선 감지\n",
            "🛣️ 프레임 3494: 8개 차선 감지\n",
            "🛣️ 프레임 3496: 9개 차선 감지\n",
            "🛣️ 프레임 3498: 8개 차선 감지\n",
            "🛣️ 프레임 3500: 8개 차선 감지\n",
            "🛣️ 프레임 3502: 8개 차선 감지\n",
            "🛣️ 프레임 3504: 8개 차선 감지\n",
            "🛣️ 프레임 3506: 8개 차선 감지\n",
            "🛣️ 프레임 3508: 7개 차선 감지\n",
            "🛣️ 프레임 3510: 7개 차선 감지\n",
            "🛣️ 프레임 3512: 8개 차선 감지\n",
            "🛣️ 프레임 3514: 9개 차선 감지\n",
            "🛣️ 프레임 3516: 8개 차선 감지\n",
            "🛣️ 프레임 3518: 9개 차선 감지\n",
            "🛣️ 프레임 3520: 9개 차선 감지\n",
            "🛣️ 프레임 3522: 9개 차선 감지\n",
            "🛣️ 프레임 3524: 7개 차선 감지\n",
            "🛣️ 프레임 3526: 7개 차선 감지\n",
            "🛣️ 프레임 3528: 7개 차선 감지\n",
            "🛣️ 프레임 3530: 7개 차선 감지\n",
            "🛣️ 프레임 3532: 6개 차선 감지\n",
            "🛣️ 프레임 3534: 7개 차선 감지\n",
            "🛣️ 프레임 3536: 7개 차선 감지\n",
            "🛣️ 프레임 3538: 8개 차선 감지\n",
            "🛣️ 프레임 3540: 6개 차선 감지\n",
            "🛣️ 프레임 3542: 6개 차선 감지\n",
            "🛣️ 프레임 3544: 6개 차선 감지\n",
            "🛣️ 프레임 3546: 7개 차선 감지\n",
            "🛣️ 프레임 3548: 6개 차선 감지\n",
            "🛣️ 프레임 3550: 7개 차선 감지\n",
            "🛣️ 프레임 3552: 6개 차선 감지\n",
            "🛣️ 프레임 3554: 6개 차선 감지\n",
            "🛣️ 프레임 3556: 7개 차선 감지\n",
            "🛣️ 프레임 3558: 8개 차선 감지\n",
            "🛣️ 프레임 3560: 8개 차선 감지\n",
            "🛣️ 프레임 3562: 8개 차선 감지\n",
            "🛣️ 프레임 3564: 7개 차선 감지\n",
            "🛣️ 프레임 3566: 7개 차선 감지\n",
            "🛣️ 프레임 3568: 9개 차선 감지\n",
            "🛣️ 프레임 3570: 9개 차선 감지\n",
            "🛣️ 프레임 3572: 8개 차선 감지\n",
            "🛣️ 프레임 3574: 9개 차선 감지\n",
            "🛣️ 프레임 3576: 9개 차선 감지\n",
            "🛣️ 프레임 3578: 8개 차선 감지\n",
            "🛣️ 프레임 3580: 9개 차선 감지\n",
            "🛣️ 프레임 3582: 10개 차선 감지\n",
            "🛣️ 프레임 3584: 10개 차선 감지\n",
            "🛣️ 프레임 3586: 11개 차선 감지\n",
            "🛣️ 프레임 3588: 9개 차선 감지\n",
            "🛣️ 프레임 3590: 10개 차선 감지\n",
            "🛣️ 프레임 3592: 9개 차선 감지\n",
            "🛣️ 프레임 3594: 9개 차선 감지\n",
            "🛣️ 프레임 3596: 10개 차선 감지\n",
            "🛣️ 프레임 3598: 8개 차선 감지\n",
            "🛣️ 프레임 3600: 11개 차선 감지\n",
            "📊 진행률: 95.7% (총 차선 감지: 17237개)\n",
            "🛣️ 프레임 3602: 10개 차선 감지\n",
            "🛣️ 프레임 3604: 9개 차선 감지\n",
            "🛣️ 프레임 3606: 9개 차선 감지\n",
            "🛣️ 프레임 3608: 8개 차선 감지\n",
            "🛣️ 프레임 3610: 7개 차선 감지\n",
            "🛣️ 프레임 3612: 7개 차선 감지\n",
            "🛣️ 프레임 3614: 7개 차선 감지\n",
            "🛣️ 프레임 3616: 8개 차선 감지\n",
            "🛣️ 프레임 3618: 8개 차선 감지\n",
            "🛣️ 프레임 3620: 8개 차선 감지\n",
            "🛣️ 프레임 3622: 7개 차선 감지\n",
            "🛣️ 프레임 3624: 7개 차선 감지\n",
            "🛣️ 프레임 3626: 7개 차선 감지\n",
            "🛣️ 프레임 3628: 9개 차선 감지\n",
            "🛣️ 프레임 3630: 9개 차선 감지\n",
            "🛣️ 프레임 3632: 9개 차선 감지\n",
            "🛣️ 프레임 3634: 8개 차선 감지\n",
            "🛣️ 프레임 3636: 9개 차선 감지\n",
            "🛣️ 프레임 3638: 8개 차선 감지\n",
            "🛣️ 프레임 3640: 8개 차선 감지\n",
            "🛣️ 프레임 3642: 8개 차선 감지\n",
            "🛣️ 프레임 3644: 7개 차선 감지\n",
            "🛣️ 프레임 3646: 7개 차선 감지\n",
            "🛣️ 프레임 3648: 8개 차선 감지\n",
            "🛣️ 프레임 3650: 11개 차선 감지\n",
            "🛣️ 프레임 3652: 9개 차선 감지\n",
            "🛣️ 프레임 3654: 8개 차선 감지\n",
            "🛣️ 프레임 3656: 10개 차선 감지\n",
            "🛣️ 프레임 3658: 9개 차선 감지\n",
            "🛣️ 프레임 3660: 10개 차선 감지\n",
            "🛣️ 프레임 3662: 9개 차선 감지\n",
            "🛣️ 프레임 3664: 9개 차선 감지\n",
            "🛣️ 프레임 3666: 10개 차선 감지\n",
            "🛣️ 프레임 3668: 10개 차선 감지\n",
            "🛣️ 프레임 3670: 11개 차선 감지\n",
            "🛣️ 프레임 3672: 9개 차선 감지\n",
            "🛣️ 프레임 3674: 10개 차선 감지\n",
            "🛣️ 프레임 3676: 9개 차선 감지\n",
            "🛣️ 프레임 3678: 9개 차선 감지\n",
            "🛣️ 프레임 3680: 9개 차선 감지\n",
            "🛣️ 프레임 3682: 8개 차선 감지\n",
            "🛣️ 프레임 3684: 9개 차선 감지\n",
            "🛣️ 프레임 3686: 10개 차선 감지\n",
            "🛣️ 프레임 3688: 9개 차선 감지\n",
            "🛣️ 프레임 3690: 9개 차선 감지\n",
            "🛣️ 프레임 3692: 9개 차선 감지\n",
            "🛣️ 프레임 3694: 9개 차선 감지\n",
            "🛣️ 프레임 3696: 8개 차선 감지\n",
            "🛣️ 프레임 3698: 11개 차선 감지\n",
            "🛣️ 프레임 3700: 10개 차선 감지\n",
            "🛣️ 프레임 3702: 9개 차선 감지\n",
            "🛣️ 프레임 3704: 10개 차선 감지\n",
            "🛣️ 프레임 3706: 8개 차선 감지\n",
            "🛣️ 프레임 3708: 8개 차선 감지\n",
            "🛣️ 프레임 3710: 9개 차선 감지\n",
            "🛣️ 프레임 3712: 9개 차선 감지\n",
            "🛣️ 프레임 3714: 10개 차선 감지\n",
            "🛣️ 프레임 3716: 8개 차선 감지\n",
            "🛣️ 프레임 3718: 9개 차선 감지\n",
            "🛣️ 프레임 3720: 10개 차선 감지\n",
            "🛣️ 프레임 3722: 8개 차선 감지\n",
            "🛣️ 프레임 3724: 8개 차선 감지\n",
            "🛣️ 프레임 3726: 7개 차선 감지\n",
            "🛣️ 프레임 3728: 7개 차선 감지\n",
            "🛣️ 프레임 3730: 7개 차선 감지\n",
            "🛣️ 프레임 3732: 7개 차선 감지\n",
            "🛣️ 프레임 3734: 8개 차선 감지\n",
            "🛣️ 프레임 3736: 8개 차선 감지\n",
            "🛣️ 프레임 3738: 6개 차선 감지\n",
            "🛣️ 프레임 3740: 9개 차선 감지\n",
            "🛣️ 프레임 3742: 8개 차선 감지\n",
            "🛣️ 프레임 3744: 7개 차선 감지\n",
            "🛣️ 프레임 3746: 7개 차선 감지\n",
            "🛣️ 프레임 3748: 7개 차선 감지\n",
            "🛣️ 프레임 3750: 8개 차선 감지\n",
            "📊 진행률: 99.7% (총 차선 감지: 17875개)\n",
            "🛣️ 프레임 3752: 7개 차선 감지\n",
            "🛣️ 프레임 3754: 8개 차선 감지\n",
            "🛣️ 프레임 3756: 8개 차선 감지\n",
            "🛣️ 프레임 3758: 8개 차선 감지\n",
            "🛣️ 프레임 3760: 7개 차선 감지\n",
            "✅ 완료! 총 17913개 차선 감지\n",
            "🎥 결과: lane_detection_result.mp4\n",
            "🎉 차선 감지 완료!\n",
            "📺 결과 영상: lane_detection_result.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning using trained model(General object detection)"
      ],
      "metadata": {
        "id": "-NJs885dfRvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 필요한 라이브러리 설치 (REVISED: Added YOLOv8 for comprehensive object detection)\n",
        "!pip install roboflow ultralytics opencv-python\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "from roboflow import Roboflow\n",
        "import numpy as np\n",
        "from ultralytics import YOLO  # REVISED: Using YOLOv8 for multi-object detection\n",
        "from google.colab import files  # 파일 업로드를 위한 import 추가\n",
        "# REVISED: Now supports detection of traffic signs, traffic lights, crosswalks, lanes, humans and vehicles\n",
        "# 영상에서 프레임을 추출하여 **다중 객체 추론(multi-object inference)** 수행\n",
        "import cv2\n",
        "import os\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# REVISED: Added comprehensive object detection configuration\n",
        "DETECTION_CONFIG = {\n",
        "    # Object colors for visualization (BGR format)\n",
        "    'colors': {\n",
        "        'person': (0, 255, 0),          # Green for humans\n",
        "        'car': (255, 0, 0),             # Blue for cars\n",
        "        'truck': (255, 0, 150),         # Purple for trucks\n",
        "        'bus': (255, 100, 0),           # Orange for buses\n",
        "        'motorcycle': (0, 255, 255),    # Yellow for motorcycles\n",
        "        'bicycle': (255, 255, 0),       # Cyan for bicycles\n",
        "        'traffic light': (0, 0, 255),   # Red for traffic lights\n",
        "        'stop sign': (0, 150, 255),     # Orange-red for stop signs\n",
        "        'lane': (255, 0, 255),          # Magenta for lanes\n",
        "        'crosswalk': (255, 255, 255),   # White for crosswalks\n",
        "        'default': (128, 128, 128)      # Gray for other objects\n",
        "    },\n",
        "\n",
        "    # Traffic-related object classes from YOLO\n",
        "    'traffic_classes': [\n",
        "        'person', 'bicycle', 'car', 'motorcycle', 'bus', 'truck',\n",
        "        'traffic light', 'stop sign'\n",
        "    ],\n",
        "\n",
        "    # Confidence thresholds for different object types\n",
        "    'confidence_thresholds': {\n",
        "        'yolo': 0.5,      # 50% confidence for YOLO detections\n",
        "        'lane': 0.3       # 30% confidence for lane detections\n",
        "    }\n",
        "}\n",
        "\n",
        "def load_detection_models():\n",
        "    \"\"\"\n",
        "    REVISED: Load both YOLOv8 and lane detection models\n",
        "    다중 모델 로드 - YOLO(일반 객체) + Roboflow(차선)\n",
        "    \"\"\"\n",
        "    print(\"🤖 Loading comprehensive detection models...\")\n",
        "\n",
        "    # 1. Load YOLOv8 model for general traffic objects\n",
        "    print(\"  📦 Loading YOLOv8 model for traffic objects...\")\n",
        "    yolo_model = YOLO('yolov8n.pt')  # Nano version for speed, use 'yolov8s.pt' for better accuracy\n",
        "    print(\"  ✅ YOLOv8 model loaded successfully!\")\n",
        "\n",
        "    # 2. Load Roboflow model for lane detection\n",
        "    print(\"  🛣️  Loading specialized lane detection model...\")\n",
        "    try:\n",
        "        rf = Roboflow(api_key=\"JwvZQEBhBR5uPrwepqQW\")\n",
        "        project = rf.workspace().project(\"0722_labeling-usrpl\")\n",
        "        lane_model = project.version(1).model\n",
        "        print(\"  ✅ Lane detection model loaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠️  Lane model loading failed: {e}\")\n",
        "        print(\"  📝 Continuing with YOLOv8 only...\")\n",
        "        lane_model = None\n",
        "\n",
        "    print(\"🎯 All available models loaded!\")\n",
        "    return yolo_model, lane_model\n",
        "\n",
        "def upload_video_files():\n",
        "    \"\"\"\n",
        "    PC에서 비디오 파일 업로드 (Unchanged)\n",
        "    \"\"\"\n",
        "    print(\"\\n🎬 Please select your video files to upload:\")\n",
        "    uploaded = files.upload()  # Returns a dictionary: {filename: file_content}\n",
        "\n",
        "    # Check if any files were actually uploaded\n",
        "    if not uploaded:\n",
        "        print(\"❌ No files uploaded!\")\n",
        "        return None  # Return None if no files uploaded\n",
        "\n",
        "    print(f\"\\n✅ Uploaded {len(uploaded)} file(s)\")\n",
        "\n",
        "    # 업로드된 파일 중 첫 번째 비디오 파일 반환\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv')):\n",
        "            print(f\"📁 Using video file: {filename}\")\n",
        "            return filename\n",
        "\n",
        "    print(\"❌ No valid video files found in upload!\")\n",
        "    return None\n",
        "\n",
        "def detect_yolo_objects(frame, yolo_model):\n",
        "    \"\"\"\n",
        "    REVISED: YOLOv8을 사용한 교통 객체 감지\n",
        "    Detect traffic-related objects using YOLOv8\n",
        "    \"\"\"\n",
        "    detections = []\n",
        "\n",
        "    try:\n",
        "        # Run YOLOv8 inference\n",
        "        results = yolo_model(frame, conf=DETECTION_CONFIG['confidence_thresholds']['yolo'])\n",
        "\n",
        "        # Parse results\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            if boxes is not None:\n",
        "                for box in boxes:\n",
        "                    # Get class name\n",
        "                    class_id = int(box.cls[0])\n",
        "                    class_name = yolo_model.names[class_id]\n",
        "\n",
        "                    # Only keep traffic-related objects\n",
        "                    if class_name in DETECTION_CONFIG['traffic_classes']:\n",
        "                        confidence = float(box.conf[0])\n",
        "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "                        detections.append({\n",
        "                            'class': class_name,\n",
        "                            'confidence': confidence,\n",
        "                            'bbox': (int(x1), int(y1), int(x2), int(y2)),\n",
        "                            'type': 'yolo'\n",
        "                        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ YOLOv8 detection error: {e}\")\n",
        "\n",
        "    return detections\n",
        "\n",
        "def detect_lane_objects(frame, lane_model):\n",
        "    \"\"\"\n",
        "    REVISED: Roboflow를 사용한 차선 감지\n",
        "    Detect lanes using specialized Roboflow model\n",
        "    \"\"\"\n",
        "    detections = []\n",
        "\n",
        "    if lane_model is None:\n",
        "        return detections\n",
        "\n",
        "    try:\n",
        "        # Save frame temporarily for Roboflow processing\n",
        "        temp_img_path = \"temp_frame_lane.jpg\"\n",
        "        cv2.imwrite(temp_img_path, frame)\n",
        "\n",
        "        # Run lane detection\n",
        "        prediction = lane_model.predict(\n",
        "            temp_img_path,\n",
        "            confidence=int(DETECTION_CONFIG['confidence_thresholds']['lane'] * 100),\n",
        "            overlap=50\n",
        "        )\n",
        "        predictions = prediction.json()['predictions']\n",
        "\n",
        "        # Parse lane detections\n",
        "        for lane in predictions:\n",
        "            x1 = int(lane['x'] - lane['width']/2)\n",
        "            y1 = int(lane['y'] - lane['height']/2)\n",
        "            x2 = int(lane['x'] + lane['width']/2)\n",
        "            y2 = int(lane['y'] + lane['height']/2)\n",
        "\n",
        "            detections.append({\n",
        "                'class': 'lane',\n",
        "                'confidence': lane['confidence'] / 100.0,  # Convert to 0-1 scale\n",
        "                'bbox': (x1, y1, x2, y2),\n",
        "                'type': 'lane'\n",
        "            })\n",
        "\n",
        "        # Clean up temporary file\n",
        "        if os.path.exists(temp_img_path):\n",
        "            os.remove(temp_img_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Lane detection error: {e}\")\n",
        "\n",
        "    return detections\n",
        "\n",
        "def draw_detections(frame, detections):\n",
        "    \"\"\"\n",
        "    REVISED: 모든 감지된 객체를 프레임에 그리기\n",
        "    Draw all detected objects on frame with different colors\n",
        "    \"\"\"\n",
        "    detection_counts = {}\n",
        "\n",
        "    for detection in detections:\n",
        "        class_name = detection['class']\n",
        "        confidence = detection['confidence']\n",
        "        x1, y1, x2, y2 = detection['bbox']\n",
        "\n",
        "        # Count detections by class\n",
        "        detection_counts[class_name] = detection_counts.get(class_name, 0) + 1\n",
        "\n",
        "        # Get color for this object class\n",
        "        color = DETECTION_CONFIG['colors'].get(class_name, DETECTION_CONFIG['colors']['default'])\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "        # Prepare label\n",
        "        label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "        # Calculate label background size\n",
        "        (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "\n",
        "        # Draw label background\n",
        "        cv2.rectangle(frame, (x1, y1-25), (x1 + label_width + 10, y1), color, -1)\n",
        "\n",
        "        # Draw label text\n",
        "        cv2.putText(frame, label, (x1 + 5, y1 - 5),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "    return detection_counts\n",
        "\n",
        "def detect_comprehensive_objects_in_video(video_path, yolo_model, lane_model, output_path=\"comprehensive_detection_result.mp4\"):\n",
        "    \"\"\"\n",
        "    REVISED: 영상에서 종합적인 도로 객체 감지\n",
        "    Comprehensive road object detection in video\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # 영상 정보 확인\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"🎬 Video info: {width}x{height}, {fps}fps, {total_frames} frames\")\n",
        "\n",
        "    # 출력 설정\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # REVISED: Tracking variables for comprehensive detection\n",
        "    frame_count = 0\n",
        "    total_detections = {\n",
        "        'person': 0, 'car': 0, 'truck': 0, 'bus': 0, 'motorcycle': 0,\n",
        "        'bicycle': 0, 'traffic light': 0, 'stop sign': 0, 'lane': 0\n",
        "    }\n",
        "\n",
        "    print(\"🔍 Starting comprehensive object detection...\")\n",
        "    print(\"📊 Detection progress:\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        frame_detections = []\n",
        "\n",
        "        # REVISED: Process every 3rd frame for efficiency (can be adjusted)\n",
        "        if frame_count % 3 == 0:\n",
        "            print(f\"    🔎 Processing frame {frame_count}/{total_frames}...\")\n",
        "\n",
        "            # 1. YOLO Object Detection\n",
        "            print(\"      🚗 Running traffic object detection...\")\n",
        "            yolo_detections = detect_yolo_objects(frame, yolo_model)\n",
        "            frame_detections.extend(yolo_detections)\n",
        "\n",
        "            # 2. Lane Detection\n",
        "            print(\"      🛣️  Running lane detection...\")\n",
        "            lane_detections = detect_lane_objects(frame, lane_model)\n",
        "            frame_detections.extend(lane_detections)\n",
        "\n",
        "            # 3. Draw all detections\n",
        "            frame_counts = draw_detections(frame, frame_detections)\n",
        "\n",
        "            # 4. Update total counts\n",
        "            for obj_class, count in frame_counts.items():\n",
        "                if obj_class in total_detections:\n",
        "                    total_detections[obj_class] += count\n",
        "\n",
        "            # 5. Print frame summary\n",
        "            if frame_detections:\n",
        "                detected_objects = list(frame_counts.keys())\n",
        "                print(f\"      ✅ Frame {frame_count}: Found {len(frame_detections)} objects - {', '.join(detected_objects)}\")\n",
        "\n",
        "        # Write frame to output video\n",
        "        out.write(frame)\n",
        "\n",
        "        # REVISED: Progress reporting every 5%\n",
        "        if frame_count % max(1, total_frames // 20) == 0:\n",
        "            progress = (frame_count / total_frames) * 100\n",
        "            print(f\"\\n📈 Progress: {progress:.1f}% complete\")\n",
        "            print(\"🎯 Detection summary so far:\")\n",
        "            for obj_type, count in total_detections.items():\n",
        "                if count > 0:\n",
        "                    print(f\"    {obj_type}: {count}\")\n",
        "            print()\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # REVISED: Final comprehensive summary\n",
        "    print(\"🎉 Comprehensive detection completed!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"📊 FINAL DETECTION SUMMARY:\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for obj_type, count in total_detections.items():\n",
        "        if count > 0:\n",
        "            print(f\"🔸 {obj_type.title()}: {count} detections\")\n",
        "\n",
        "    total_objects = sum(total_detections.values())\n",
        "    print(f\"\\n🎯 Total objects detected: {total_objects}\")\n",
        "    print(f\"🎥 Output video: {output_path}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "def main_comprehensive_detection():\n",
        "    \"\"\"\n",
        "    REVISED: 종합적인 도로 객체 감지 메인 함수\n",
        "    Main function for comprehensive road object detection\n",
        "    \"\"\"\n",
        "    print(\"🚗 Starting comprehensive road object detection...\")\n",
        "    print(\"🎯 Will detect: Traffic signs, lights, crosswalks, lanes, humans, and vehicles\")\n",
        "\n",
        "    # Step 1: Upload video file\n",
        "    video_path = upload_video_files()\n",
        "\n",
        "    if video_path:\n",
        "        print(f\"📁 Video file: {video_path}\")\n",
        "\n",
        "        # Step 2: Load detection models\n",
        "        print(\"\\n🤖 Loading detection models...\")\n",
        "        try:\n",
        "            yolo_model, lane_model = load_detection_models()\n",
        "\n",
        "            # Step 3: Run comprehensive detection\n",
        "            print(\"\\n🔍 Starting comprehensive object detection...\")\n",
        "            detect_comprehensive_objects_in_video(\n",
        "                video_path, yolo_model, lane_model,\n",
        "                \"comprehensive_detection_result.mp4\"\n",
        "            )\n",
        "\n",
        "            print(\"\\n🎉 Comprehensive detection completed!\")\n",
        "            print(\"📺 Result video: comprehensive_detection_result.mp4\")\n",
        "            print(\"\\n🎨 Color coding:\")\n",
        "            for obj_type, color in DETECTION_CONFIG['colors'].items():\n",
        "                if obj_type != 'default':\n",
        "                    print(f\"  {obj_type}: {color}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Model loading failed: {e}\")\n",
        "            print(\"🔑 Please check your API key and internet connection!\")\n",
        "    else:\n",
        "        print(\"❌ No video file uploaded.\")\n",
        "\n",
        "def test_with_webcam_url():\n",
        "    \"\"\"\n",
        "    Roboflow Visualize 페이지의 'Paste YouTube or Image URL' 기능 사용 (Unchanged)\n",
        "    \"\"\"\n",
        "    print(\"🌐 웹 인터페이스 테스트:\")\n",
        "    print(\"1. Roboflow Visualize 페이지에서\")\n",
        "    print(\"2. 'Paste YouTube or Image URL' 입력창에\")\n",
        "    print(\"3. YouTube URL 붙여넣기\")\n",
        "    print(\"4. 차선이 잘 감지되는지 확인\")\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🚦 COMPREHENSIVE ROAD OBJECT DETECTION\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"🎯 DETECTABLE OBJECTS:\")\n",
        "    print(\"  👤 Humans (persons)\")\n",
        "    print(\"  🚗 Vehicles (cars, trucks, buses, motorcycles, bicycles)\")\n",
        "    print(\"  🚦 Traffic lights\")\n",
        "    print(\"  🛑 Traffic signs (stop signs)\")\n",
        "    print(\"  🛣️  Road lanes\")\n",
        "    print(\"  🚶 Crosswalks (when visible)\")\n",
        "    print()\n",
        "    print(\"🎨 VISUAL CODING:\")\n",
        "    print(\"  Different colors for different object types\")\n",
        "    print(\"  Confidence scores displayed for each detection\")\n",
        "    print()\n",
        "    print(\"🚀 EXECUTION STEPS:\")\n",
        "    print(\"1. Upload your driving video file\")\n",
        "    print(\"2. Models will load automatically\")\n",
        "    print(\"3. Comprehensive detection will run\")\n",
        "    print(\"4. Results saved as comprehensive_detection_result.mp4\")\n",
        "    print(\"=\" * 60)\n",
        "    main_comprehensive_detection()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MJg4OpJVfITL",
        "outputId": "68c151b0-ebf0-4cda-811d-cb2dddbeb4ba"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.2.3)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.170)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.7.14)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.3.0)\n",
            "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.59.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "🚦 COMPREHENSIVE ROAD OBJECT DETECTION\n",
            "============================================================\n",
            "🎯 DETECTABLE OBJECTS:\n",
            "  👤 Humans (persons)\n",
            "  🚗 Vehicles (cars, trucks, buses, motorcycles, bicycles)\n",
            "  🚦 Traffic lights\n",
            "  🛑 Traffic signs (stop signs)\n",
            "  🛣️  Road lanes\n",
            "  🚶 Crosswalks (when visible)\n",
            "\n",
            "🎨 VISUAL CODING:\n",
            "  Different colors for different object types\n",
            "  Confidence scores displayed for each detection\n",
            "\n",
            "🚀 EXECUTION STEPS:\n",
            "1. Upload your driving video file\n",
            "2. Models will load automatically\n",
            "3. Comprehensive detection will run\n",
            "4. Results saved as comprehensive_detection_result.mp4\n",
            "============================================================\n",
            "🚗 Starting comprehensive road object detection...\n",
            "🎯 Will detect: Traffic signs, lights, crosswalks, lanes, humans, and vehicles\n",
            "\n",
            "🎬 Please select your video files to upload:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-88a4da61-2ed1-4858-aed3-0558143948cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-88a4da61-2ed1-4858-aed3-0558143948cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving KakaoTalk_20250704_093345410.mp4 to KakaoTalk_20250704_093345410 (1).mp4\n",
            "\n",
            "✅ Uploaded 1 file(s)\n",
            "📁 Using video file: KakaoTalk_20250704_093345410 (1).mp4\n",
            "📁 Video file: KakaoTalk_20250704_093345410 (1).mp4\n",
            "\n",
            "🤖 Loading detection models...\n",
            "🤖 Loading comprehensive detection models...\n",
            "  📦 Loading YOLOv8 model for traffic objects...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 281MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "      ✅ Frame 1686: Found 10 objects - car, truck, lane\n",
            "    🔎 Processing frame 1689/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 107.2ms\n",
            "Speed: 5.4ms preprocess, 107.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1689: Found 11 objects - car, truck, lane\n",
            "    🔎 Processing frame 1692/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 123.0ms\n",
            "Speed: 3.7ms preprocess, 123.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1692: Found 9 objects - car, truck, lane\n",
            "\n",
            "📈 Progress: 45.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 72\n",
            "    car: 2291\n",
            "    truck: 30\n",
            "    bus: 28\n",
            "    traffic light: 30\n",
            "    stop sign: 1\n",
            "    lane: 5213\n",
            "\n",
            "    🔎 Processing frame 1695/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.8ms\n",
            "Speed: 3.3ms preprocess, 108.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1695: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 1698/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 104.5ms\n",
            "Speed: 4.3ms preprocess, 104.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1698: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 1701/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 113.3ms\n",
            "Speed: 3.4ms preprocess, 113.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1701: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 1704/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.9ms\n",
            "Speed: 3.4ms preprocess, 108.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1704: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 1707/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.4ms\n",
            "Speed: 3.0ms preprocess, 111.4ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1707: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 1710/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.9ms\n",
            "Speed: 3.3ms preprocess, 114.9ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1710: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 1713/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 116.3ms\n",
            "Speed: 4.2ms preprocess, 116.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1713: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 1716/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.6ms\n",
            "Speed: 3.3ms preprocess, 110.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1716: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 1719/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.9ms\n",
            "Speed: 3.9ms preprocess, 110.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1719: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 1722/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 bus, 175.2ms\n",
            "Speed: 3.3ms preprocess, 175.2ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1722: Found 18 objects - car, bus, lane\n",
            "    🔎 Processing frame 1725/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 176.8ms\n",
            "Speed: 7.3ms preprocess, 176.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1725: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 1728/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 bus, 166.6ms\n",
            "Speed: 5.3ms preprocess, 166.6ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1728: Found 18 objects - car, bus, lane\n",
            "    🔎 Processing frame 1731/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 169.6ms\n",
            "Speed: 3.4ms preprocess, 169.6ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1731: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 1734/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 194.5ms\n",
            "Speed: 8.4ms preprocess, 194.5ms inference, 4.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1734: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 1737/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 169.5ms\n",
            "Speed: 4.2ms preprocess, 169.5ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1737: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 1740/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 112.4ms\n",
            "Speed: 3.2ms preprocess, 112.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1740: Found 20 objects - car, lane\n",
            "    🔎 Processing frame 1743/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.4ms\n",
            "Speed: 3.5ms preprocess, 112.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1743: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 1746/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 bus, 113.9ms\n",
            "Speed: 3.3ms preprocess, 113.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1746: Found 17 objects - car, bus, lane\n",
            "    🔎 Processing frame 1749/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 1 bus, 109.3ms\n",
            "Speed: 4.0ms preprocess, 109.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1749: Found 22 objects - car, bus, lane\n",
            "    🔎 Processing frame 1752/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.8ms\n",
            "Speed: 3.4ms preprocess, 109.8ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1752: Found 19 objects - car, lane\n",
            "    🔎 Processing frame 1755/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 110.8ms\n",
            "Speed: 3.5ms preprocess, 110.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1755: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 1758/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 116.4ms\n",
            "Speed: 3.4ms preprocess, 116.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1758: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 1761/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.4ms\n",
            "Speed: 3.6ms preprocess, 111.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1761: Found 20 objects - car, lane\n",
            "    🔎 Processing frame 1764/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 107.8ms\n",
            "Speed: 5.7ms preprocess, 107.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1764: Found 21 objects - car, truck, lane\n",
            "    🔎 Processing frame 1767/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 106.8ms\n",
            "Speed: 6.3ms preprocess, 106.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1767: Found 22 objects - car, lane\n",
            "    🔎 Processing frame 1770/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.1ms\n",
            "Speed: 6.6ms preprocess, 109.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1770: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 1773/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.0ms\n",
            "Speed: 6.1ms preprocess, 111.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1773: Found 27 objects - car, lane\n",
            "    🔎 Processing frame 1776/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 107.6ms\n",
            "Speed: 3.5ms preprocess, 107.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1776: Found 28 objects - car, lane\n",
            "    🔎 Processing frame 1779/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 123.8ms\n",
            "Speed: 3.1ms preprocess, 123.8ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1779: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 1782/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.9ms\n",
            "Speed: 3.2ms preprocess, 114.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1782: Found 24 objects - car, lane\n",
            "    🔎 Processing frame 1785/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 126.4ms\n",
            "Speed: 3.3ms preprocess, 126.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1785: Found 24 objects - car, lane\n",
            "    🔎 Processing frame 1788/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 107.9ms\n",
            "Speed: 3.5ms preprocess, 107.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1788: Found 20 objects - car, lane\n",
            "    🔎 Processing frame 1791/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 1 fire hydrant, 183.1ms\n",
            "Speed: 3.3ms preprocess, 183.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1791: Found 22 objects - car, lane\n",
            "    🔎 Processing frame 1794/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 169.0ms\n",
            "Speed: 3.6ms preprocess, 169.0ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1794: Found 28 objects - car, lane\n",
            "    🔎 Processing frame 1797/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 8 cars, 169.0ms\n",
            "Speed: 3.5ms preprocess, 169.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1797: Found 25 objects - car, lane\n",
            "    🔎 Processing frame 1800/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 183.5ms\n",
            "Speed: 3.4ms preprocess, 183.5ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1800: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 1803/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 192.7ms\n",
            "Speed: 4.7ms preprocess, 192.7ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1803: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 1806/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 178.4ms\n",
            "Speed: 3.2ms preprocess, 178.4ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1806: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 1809/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 108.4ms\n",
            "Speed: 6.5ms preprocess, 108.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1809: Found 22 objects - car, lane\n",
            "    🔎 Processing frame 1812/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 8 cars, 120.5ms\n",
            "Speed: 3.7ms preprocess, 120.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1812: Found 30 objects - car, lane\n",
            "    🔎 Processing frame 1815/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 114.5ms\n",
            "Speed: 2.8ms preprocess, 114.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1815: Found 24 objects - car, lane\n",
            "    🔎 Processing frame 1818/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 107.8ms\n",
            "Speed: 3.6ms preprocess, 107.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1818: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 1821/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 truck, 110.7ms\n",
            "Speed: 3.1ms preprocess, 110.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1821: Found 20 objects - car, truck, lane\n",
            "    🔎 Processing frame 1824/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 truck, 109.8ms\n",
            "Speed: 3.5ms preprocess, 109.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1824: Found 24 objects - car, truck, lane\n",
            "    🔎 Processing frame 1827/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.6ms\n",
            "Speed: 3.4ms preprocess, 110.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1827: Found 29 objects - car, lane\n",
            "    🔎 Processing frame 1830/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 109.2ms\n",
            "Speed: 3.4ms preprocess, 109.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1830: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 1833/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 116.0ms\n",
            "Speed: 3.3ms preprocess, 116.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1833: Found 29 objects - car, truck, lane\n",
            "    🔎 Processing frame 1836/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 112.7ms\n",
            "Speed: 4.1ms preprocess, 112.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1836: Found 27 objects - car, truck, lane\n",
            "    🔎 Processing frame 1839/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 110.2ms\n",
            "Speed: 3.3ms preprocess, 110.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1839: Found 29 objects - car, lane\n",
            "    🔎 Processing frame 1842/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 8 cars, 1 truck, 107.0ms\n",
            "Speed: 3.5ms preprocess, 107.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1842: Found 31 objects - car, truck, lane\n",
            "    🔎 Processing frame 1845/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 1 truck, 111.7ms\n",
            "Speed: 3.4ms preprocess, 111.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1845: Found 27 objects - car, truck, lane\n",
            "    🔎 Processing frame 1848/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 1 truck, 104.8ms\n",
            "Speed: 3.6ms preprocess, 104.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1848: Found 29 objects - car, truck, lane\n",
            "    🔎 Processing frame 1851/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 105.0ms\n",
            "Speed: 3.2ms preprocess, 105.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1851: Found 26 objects - car, truck, lane\n",
            "    🔎 Processing frame 1854/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 1 truck, 185.7ms\n",
            "Speed: 3.4ms preprocess, 185.7ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1854: Found 26 objects - car, truck, lane\n",
            "    🔎 Processing frame 1857/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 1 truck, 186.2ms\n",
            "Speed: 3.2ms preprocess, 186.2ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1857: Found 25 objects - car, truck, lane\n",
            "    🔎 Processing frame 1860/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 164.7ms\n",
            "Speed: 5.3ms preprocess, 164.7ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1860: Found 24 objects - car, truck, lane\n",
            "    🔎 Processing frame 1863/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 truck, 171.0ms\n",
            "Speed: 6.6ms preprocess, 171.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1863: Found 22 objects - car, truck, lane\n",
            "    🔎 Processing frame 1866/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 truck, 208.2ms\n",
            "Speed: 5.4ms preprocess, 208.2ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1866: Found 26 objects - car, truck, lane\n",
            "    🔎 Processing frame 1869/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 1 truck, 182.2ms\n",
            "Speed: 5.1ms preprocess, 182.2ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1869: Found 26 objects - truck, car, lane\n",
            "    🔎 Processing frame 1872/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 1 truck, 108.6ms\n",
            "Speed: 6.1ms preprocess, 108.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1872: Found 26 objects - truck, car, lane\n",
            "    🔎 Processing frame 1875/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 1 truck, 111.1ms\n",
            "Speed: 3.3ms preprocess, 111.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1875: Found 22 objects - car, truck, lane\n",
            "    🔎 Processing frame 1878/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 1 truck, 109.3ms\n",
            "Speed: 3.6ms preprocess, 109.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1878: Found 23 objects - truck, car, lane\n",
            "\n",
            "📈 Progress: 50.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 72\n",
            "    car: 2606\n",
            "    truck: 48\n",
            "    bus: 32\n",
            "    traffic light: 30\n",
            "    stop sign: 1\n",
            "    lane: 6201\n",
            "\n",
            "    🔎 Processing frame 1881/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 truck, 109.2ms\n",
            "Speed: 3.5ms preprocess, 109.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1881: Found 25 objects - car, truck, lane\n",
            "    🔎 Processing frame 1884/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.4ms\n",
            "Speed: 7.1ms preprocess, 108.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1884: Found 20 objects - car, lane\n",
            "    🔎 Processing frame 1887/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 130.3ms\n",
            "Speed: 3.8ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1887: Found 26 objects - car, lane\n",
            "    🔎 Processing frame 1890/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 107.9ms\n",
            "Speed: 3.9ms preprocess, 107.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1890: Found 27 objects - car, lane\n",
            "    🔎 Processing frame 1893/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 115.5ms\n",
            "Speed: 4.1ms preprocess, 115.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1893: Found 31 objects - car, lane\n",
            "    🔎 Processing frame 1896/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.1ms\n",
            "Speed: 4.3ms preprocess, 114.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1896: Found 24 objects - car, lane\n",
            "    🔎 Processing frame 1899/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.9ms\n",
            "Speed: 3.4ms preprocess, 110.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1899: Found 20 objects - car, lane\n",
            "    🔎 Processing frame 1902/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.1ms\n",
            "Speed: 3.8ms preprocess, 108.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1902: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 1905/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 110.1ms\n",
            "Speed: 3.5ms preprocess, 110.1ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1905: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 1908/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 110.7ms\n",
            "Speed: 3.6ms preprocess, 110.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1908: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 1911/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.5ms\n",
            "Speed: 3.0ms preprocess, 113.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1911: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 1914/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.3ms\n",
            "Speed: 3.3ms preprocess, 114.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1914: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 1917/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 115.8ms\n",
            "Speed: 3.2ms preprocess, 115.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1917: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 1920/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 121.4ms\n",
            "Speed: 3.4ms preprocess, 121.4ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1920: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 1923/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 persons, 4 cars, 124.1ms\n",
            "Speed: 9.3ms preprocess, 124.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1923: Found 12 objects - car, person, lane\n",
            "    🔎 Processing frame 1926/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 5 cars, 184.7ms\n",
            "Speed: 3.4ms preprocess, 184.7ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1926: Found 11 objects - car, person, lane\n",
            "    🔎 Processing frame 1929/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 4 cars, 1 truck, 188.7ms\n",
            "Speed: 7.1ms preprocess, 188.7ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1929: Found 17 objects - car, person, truck, lane\n",
            "    🔎 Processing frame 1932/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 4 cars, 167.2ms\n",
            "Speed: 6.5ms preprocess, 167.2ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1932: Found 13 objects - car, person, lane\n",
            "    🔎 Processing frame 1935/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 178.8ms\n",
            "Speed: 3.9ms preprocess, 178.8ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1935: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 1938/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 179.6ms\n",
            "Speed: 3.4ms preprocess, 179.6ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1938: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 1941/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.3ms\n",
            "Speed: 3.5ms preprocess, 113.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1941: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 1944/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.9ms\n",
            "Speed: 3.4ms preprocess, 108.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1944: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 1947/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.7ms\n",
            "Speed: 7.5ms preprocess, 108.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1947: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 1950/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 112.4ms\n",
            "Speed: 4.5ms preprocess, 112.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1950: Found 25 objects - car, lane\n",
            "    🔎 Processing frame 1953/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 116.2ms\n",
            "Speed: 4.2ms preprocess, 116.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1953: Found 28 objects - car, lane\n",
            "    🔎 Processing frame 1956/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 125.9ms\n",
            "Speed: 3.4ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1956: Found 22 objects - car, lane\n",
            "    🔎 Processing frame 1959/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 107.5ms\n",
            "Speed: 3.5ms preprocess, 107.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1959: Found 20 objects - car, lane\n",
            "    🔎 Processing frame 1962/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.8ms\n",
            "Speed: 3.3ms preprocess, 110.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1962: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 1965/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.0ms\n",
            "Speed: 3.4ms preprocess, 109.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1965: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 1968/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.7ms\n",
            "Speed: 3.5ms preprocess, 109.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1968: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 1971/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 119.2ms\n",
            "Speed: 3.4ms preprocess, 119.2ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1971: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 1974/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 109.6ms\n",
            "Speed: 3.5ms preprocess, 109.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1974: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 1977/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.3ms\n",
            "Speed: 3.5ms preprocess, 109.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1977: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 1980/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 115.5ms\n",
            "Speed: 3.4ms preprocess, 115.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1980: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 1983/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 108.1ms\n",
            "Speed: 3.5ms preprocess, 108.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1983: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 1986/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 108.5ms\n",
            "Speed: 3.4ms preprocess, 108.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1986: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 1989/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 112.3ms\n",
            "Speed: 3.4ms preprocess, 112.3ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1989: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 1992/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.3ms\n",
            "Speed: 3.5ms preprocess, 108.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1992: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 1995/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 134.0ms\n",
            "Speed: 7.1ms preprocess, 134.0ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1995: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 1998/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 175.4ms\n",
            "Speed: 5.5ms preprocess, 175.4ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 1998: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2001/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 172.3ms\n",
            "Speed: 3.9ms preprocess, 172.3ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2001: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2004/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 175.4ms\n",
            "Speed: 7.0ms preprocess, 175.4ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2004: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2007/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 170.6ms\n",
            "Speed: 3.3ms preprocess, 170.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2007: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2010/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 195.4ms\n",
            "Speed: 6.0ms preprocess, 195.4ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2010: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2013/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 143.6ms\n",
            "Speed: 3.4ms preprocess, 143.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2013: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2016/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 111.3ms\n",
            "Speed: 6.2ms preprocess, 111.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2016: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2019/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 113.0ms\n",
            "Speed: 5.6ms preprocess, 113.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2019: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2022/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 108.6ms\n",
            "Speed: 3.4ms preprocess, 108.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2022: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2025/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 115.5ms\n",
            "Speed: 3.0ms preprocess, 115.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2025: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2028/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 123.8ms\n",
            "Speed: 3.5ms preprocess, 123.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2028: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2031/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 110.7ms\n",
            "Speed: 3.4ms preprocess, 110.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2031: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2034/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 129.4ms\n",
            "Speed: 5.9ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2034: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2037/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 108.8ms\n",
            "Speed: 6.0ms preprocess, 108.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2037: Found 5 objects - car, lane\n",
            "    🔎 Processing frame 2040/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 126.1ms\n",
            "Speed: 4.1ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2040: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2043/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 117.2ms\n",
            "Speed: 3.0ms preprocess, 117.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2043: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2046/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 117.4ms\n",
            "Speed: 3.3ms preprocess, 117.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2046: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2049/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 115.1ms\n",
            "Speed: 3.9ms preprocess, 115.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2049: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2052/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.1ms\n",
            "Speed: 3.3ms preprocess, 109.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2052: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2055/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.3ms\n",
            "Speed: 5.3ms preprocess, 112.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2055: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2058/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 181.0ms\n",
            "Speed: 3.5ms preprocess, 181.0ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2058: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2061/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 184.0ms\n",
            "Speed: 4.8ms preprocess, 184.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2061: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2064/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 169.6ms\n",
            "Speed: 3.5ms preprocess, 169.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2064: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2067/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 164.5ms\n",
            "Speed: 3.4ms preprocess, 164.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2067: Found 11 objects - car, lane\n",
            "\n",
            "📈 Progress: 55.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 77\n",
            "    car: 2865\n",
            "    truck: 50\n",
            "    bus: 32\n",
            "    traffic light: 30\n",
            "    stop sign: 1\n",
            "    lane: 6855\n",
            "\n",
            "    🔎 Processing frame 2070/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 179.3ms\n",
            "Speed: 3.3ms preprocess, 179.3ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2070: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2073/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 181.6ms\n",
            "Speed: 7.1ms preprocess, 181.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2073: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2076/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 111.5ms\n",
            "Speed: 4.5ms preprocess, 111.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2076: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2079/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 131.8ms\n",
            "Speed: 3.5ms preprocess, 131.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2079: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2082/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.3ms\n",
            "Speed: 3.8ms preprocess, 109.3ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2082: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2085/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 122.0ms\n",
            "Speed: 3.7ms preprocess, 122.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2085: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2088/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.5ms\n",
            "Speed: 7.4ms preprocess, 111.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2088: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2091/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 122.4ms\n",
            "Speed: 7.3ms preprocess, 122.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2091: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2094/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.0ms\n",
            "Speed: 3.3ms preprocess, 112.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2094: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2097/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 125.8ms\n",
            "Speed: 3.4ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2097: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2100/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.0ms\n",
            "Speed: 3.4ms preprocess, 109.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2100: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2103/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 128.3ms\n",
            "Speed: 3.4ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2103: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2106/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 106.3ms\n",
            "Speed: 3.5ms preprocess, 106.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2106: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2109/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 124.6ms\n",
            "Speed: 4.2ms preprocess, 124.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2109: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2112/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.4ms\n",
            "Speed: 3.4ms preprocess, 109.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2112: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2115/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 135.3ms\n",
            "Speed: 4.5ms preprocess, 135.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2115: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2118/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.4ms\n",
            "Speed: 3.4ms preprocess, 108.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2118: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2121/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 125.8ms\n",
            "Speed: 3.4ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2121: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2124/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.3ms\n",
            "Speed: 3.4ms preprocess, 111.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2124: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2127/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.1ms\n",
            "Speed: 3.5ms preprocess, 113.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2127: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2130/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 165.7ms\n",
            "Speed: 3.5ms preprocess, 165.7ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2130: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2133/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 168.1ms\n",
            "Speed: 3.7ms preprocess, 168.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2133: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2136/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 172.9ms\n",
            "Speed: 3.4ms preprocess, 172.9ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2136: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2139/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 172.6ms\n",
            "Speed: 3.5ms preprocess, 172.6ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2139: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2142/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 183.4ms\n",
            "Speed: 2.9ms preprocess, 183.4ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2142: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2145/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 182.7ms\n",
            "Speed: 3.6ms preprocess, 182.7ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2145: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2148/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 116.1ms\n",
            "Speed: 6.4ms preprocess, 116.1ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2148: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2151/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.9ms\n",
            "Speed: 3.2ms preprocess, 111.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2151: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2154/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.6ms\n",
            "Speed: 3.4ms preprocess, 113.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2154: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2157/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.1ms\n",
            "Speed: 3.5ms preprocess, 108.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2157: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2160/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.1ms\n",
            "Speed: 3.3ms preprocess, 113.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2160: Found 19 objects - car, lane\n",
            "    🔎 Processing frame 2163/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.1ms\n",
            "Speed: 3.4ms preprocess, 110.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2163: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 2166/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.4ms\n",
            "Speed: 3.3ms preprocess, 112.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2166: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2169/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.2ms\n",
            "Speed: 3.6ms preprocess, 109.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2169: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2172/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 107.0ms\n",
            "Speed: 5.8ms preprocess, 107.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2172: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2175/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.8ms\n",
            "Speed: 5.6ms preprocess, 111.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2175: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2178/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.9ms\n",
            "Speed: 3.6ms preprocess, 113.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2178: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2181/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.8ms\n",
            "Speed: 3.4ms preprocess, 109.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2181: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2184/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 117.0ms\n",
            "Speed: 5.8ms preprocess, 117.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2184: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2187/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.4ms\n",
            "Speed: 6.0ms preprocess, 110.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2187: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2190/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.0ms\n",
            "Speed: 3.2ms preprocess, 113.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2190: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2193/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 106.1ms\n",
            "Speed: 6.1ms preprocess, 106.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2193: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2196/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 173.0ms\n",
            "Speed: 3.2ms preprocess, 173.0ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2196: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2199/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 171.9ms\n",
            "Speed: 2.9ms preprocess, 171.9ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2199: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2202/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 170.5ms\n",
            "Speed: 4.0ms preprocess, 170.5ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2202: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2205/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 172.9ms\n",
            "Speed: 4.3ms preprocess, 172.9ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2205: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2208/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 188.7ms\n",
            "Speed: 4.6ms preprocess, 188.7ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2208: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2211/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.0ms\n",
            "Speed: 3.4ms preprocess, 113.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2211: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2214/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.2ms\n",
            "Speed: 3.5ms preprocess, 113.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2214: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2217/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.6ms\n",
            "Speed: 5.9ms preprocess, 109.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2217: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2220/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.0ms\n",
            "Speed: 3.5ms preprocess, 111.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2220: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2223/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 129.2ms\n",
            "Speed: 3.5ms preprocess, 129.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2223: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2226/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.5ms\n",
            "Speed: 3.3ms preprocess, 111.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2226: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2229/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.0ms\n",
            "Speed: 6.5ms preprocess, 114.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2229: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2232/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 115.1ms\n",
            "Speed: 3.5ms preprocess, 115.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2232: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2235/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.1ms\n",
            "Speed: 3.3ms preprocess, 114.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2235: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2238/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.0ms\n",
            "Speed: 3.5ms preprocess, 112.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2238: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2241/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.4ms\n",
            "Speed: 4.9ms preprocess, 113.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2241: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2244/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.4ms\n",
            "Speed: 4.5ms preprocess, 110.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2244: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2247/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 121.8ms\n",
            "Speed: 7.1ms preprocess, 121.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2247: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2250/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 119.5ms\n",
            "Speed: 4.4ms preprocess, 119.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2250: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2253/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.7ms\n",
            "Speed: 4.2ms preprocess, 108.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2253: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2256/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 173.8ms\n",
            "Speed: 4.6ms preprocess, 173.8ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2256: Found 9 objects - car, lane\n",
            "\n",
            "📈 Progress: 60.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 77\n",
            "    car: 3135\n",
            "    truck: 50\n",
            "    bus: 32\n",
            "    traffic light: 30\n",
            "    stop sign: 1\n",
            "    lane: 7371\n",
            "\n",
            "    🔎 Processing frame 2259/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 171.6ms\n",
            "Speed: 8.0ms preprocess, 171.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2259: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2262/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 170.3ms\n",
            "Speed: 5.2ms preprocess, 170.3ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2262: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2265/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 164.4ms\n",
            "Speed: 9.5ms preprocess, 164.4ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2265: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2268/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 180.4ms\n",
            "Speed: 3.4ms preprocess, 180.4ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2268: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 2271/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 190.3ms\n",
            "Speed: 8.4ms preprocess, 190.3ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2271: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 2274/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.2ms\n",
            "Speed: 3.7ms preprocess, 111.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2274: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2277/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 135.3ms\n",
            "Speed: 4.0ms preprocess, 135.3ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2277: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2280/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 125.9ms\n",
            "Speed: 3.8ms preprocess, 125.9ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2280: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2283/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 133.7ms\n",
            "Speed: 3.3ms preprocess, 133.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2283: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2286/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 112.6ms\n",
            "Speed: 3.8ms preprocess, 112.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2286: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2289/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 127.6ms\n",
            "Speed: 3.5ms preprocess, 127.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2289: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2292/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.5ms\n",
            "Speed: 3.3ms preprocess, 114.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2292: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2295/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 119.2ms\n",
            "Speed: 6.1ms preprocess, 119.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2295: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2298/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 119.5ms\n",
            "Speed: 5.9ms preprocess, 119.5ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2298: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2301/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 123.7ms\n",
            "Speed: 3.7ms preprocess, 123.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2301: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2304/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 114.4ms\n",
            "Speed: 7.1ms preprocess, 114.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2304: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2307/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 train, 116.1ms\n",
            "Speed: 3.4ms preprocess, 116.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2307: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2310/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.9ms\n",
            "Speed: 3.3ms preprocess, 109.9ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2310: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2313/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 124.4ms\n",
            "Speed: 3.3ms preprocess, 124.4ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2313: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2316/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 172.0ms\n",
            "Speed: 3.5ms preprocess, 172.0ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2316: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2319/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 179.2ms\n",
            "Speed: 7.0ms preprocess, 179.2ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2319: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2322/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 184.9ms\n",
            "Speed: 3.2ms preprocess, 184.9ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2322: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2325/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 163.7ms\n",
            "Speed: 3.5ms preprocess, 163.7ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2325: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2328/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.8ms\n",
            "Speed: 3.5ms preprocess, 109.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2328: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2331/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 116.4ms\n",
            "Speed: 3.4ms preprocess, 116.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2331: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2334/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.0ms\n",
            "Speed: 9.4ms preprocess, 108.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2334: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2337/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 117.1ms\n",
            "Speed: 3.0ms preprocess, 117.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2337: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2340/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 1 traffic light, 109.6ms\n",
            "Speed: 3.5ms preprocess, 109.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2340: Found 10 objects - car, traffic light, lane\n",
            "    🔎 Processing frame 2343/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 117.5ms\n",
            "Speed: 7.2ms preprocess, 117.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2343: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2346/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 110.9ms\n",
            "Speed: 3.6ms preprocess, 110.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2346: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2349/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.7ms\n",
            "Speed: 6.0ms preprocess, 110.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2349: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2352/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 126.1ms\n",
            "Speed: 3.5ms preprocess, 126.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2352: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2355/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 110.6ms\n",
            "Speed: 3.3ms preprocess, 110.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2355: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2358/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 128.2ms\n",
            "Speed: 3.2ms preprocess, 128.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2358: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2361/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 117.4ms\n",
            "Speed: 3.2ms preprocess, 117.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2361: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2364/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.7ms\n",
            "Speed: 5.2ms preprocess, 109.7ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2364: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2367/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.8ms\n",
            "Speed: 4.8ms preprocess, 112.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2367: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2370/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.0ms\n",
            "Speed: 4.3ms preprocess, 110.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2370: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2373/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.2ms\n",
            "Speed: 5.8ms preprocess, 110.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2373: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2376/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 107.9ms\n",
            "Speed: 3.5ms preprocess, 107.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2376: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2379/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 178.8ms\n",
            "Speed: 9.7ms preprocess, 178.8ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2379: Found 5 objects - car, lane\n",
            "    🔎 Processing frame 2382/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 167.1ms\n",
            "Speed: 3.3ms preprocess, 167.1ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2382: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2385/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 179.9ms\n",
            "Speed: 3.5ms preprocess, 179.9ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2385: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2388/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 190.0ms\n",
            "Speed: 3.6ms preprocess, 190.0ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2388: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2391/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 121.2ms\n",
            "Speed: 3.5ms preprocess, 121.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2391: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2394/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.8ms\n",
            "Speed: 5.9ms preprocess, 108.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2394: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2397/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.3ms\n",
            "Speed: 3.2ms preprocess, 112.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2397: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2400/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 107.5ms\n",
            "Speed: 3.9ms preprocess, 107.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2400: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2403/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 106.7ms\n",
            "Speed: 7.2ms preprocess, 106.7ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2403: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2406/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 104.5ms\n",
            "Speed: 6.7ms preprocess, 104.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2406: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2409/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 131.7ms\n",
            "Speed: 3.2ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2409: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2412/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.1ms\n",
            "Speed: 3.1ms preprocess, 114.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2412: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2415/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 116.6ms\n",
            "Speed: 5.0ms preprocess, 116.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2415: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2418/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.1ms\n",
            "Speed: 3.5ms preprocess, 111.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2418: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2421/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 115.0ms\n",
            "Speed: 3.2ms preprocess, 115.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2421: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2424/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.8ms\n",
            "Speed: 3.4ms preprocess, 110.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2424: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2427/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 115.6ms\n",
            "Speed: 3.3ms preprocess, 115.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2427: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2430/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 133.2ms\n",
            "Speed: 3.6ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2430: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2433/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 169.8ms\n",
            "Speed: 4.3ms preprocess, 169.8ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2433: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2436/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 180.5ms\n",
            "Speed: 6.3ms preprocess, 180.5ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2436: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2439/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 189.8ms\n",
            "Speed: 7.1ms preprocess, 189.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2439: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2442/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 172.6ms\n",
            "Speed: 5.8ms preprocess, 172.6ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2442: Found 13 objects - car, lane\n",
            "\n",
            "📈 Progress: 65.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 77\n",
            "    car: 3376\n",
            "    truck: 50\n",
            "    bus: 32\n",
            "    traffic light: 31\n",
            "    stop sign: 1\n",
            "    lane: 7793\n",
            "\n",
            "    🔎 Processing frame 2445/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 180.0ms\n",
            "Speed: 3.2ms preprocess, 180.0ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2445: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2448/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 184.7ms\n",
            "Speed: 3.1ms preprocess, 184.7ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2448: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2451/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 119.6ms\n",
            "Speed: 4.2ms preprocess, 119.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2451: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2454/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.9ms\n",
            "Speed: 3.3ms preprocess, 111.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2454: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2457/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 111.4ms\n",
            "Speed: 3.5ms preprocess, 111.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2457: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2460/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.2ms\n",
            "Speed: 3.7ms preprocess, 112.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2460: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2463/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 123.6ms\n",
            "Speed: 3.4ms preprocess, 123.6ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2463: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2466/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 106.8ms\n",
            "Speed: 3.5ms preprocess, 106.8ms inference, 3.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2466: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2469/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 106.4ms\n",
            "Speed: 3.4ms preprocess, 106.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2469: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2472/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 104.6ms\n",
            "Speed: 3.5ms preprocess, 104.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2472: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2475/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 111.1ms\n",
            "Speed: 3.2ms preprocess, 111.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2475: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2478/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.7ms\n",
            "Speed: 3.7ms preprocess, 109.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2478: Found 7 objects - car, lane\n",
            "    🔎 Processing frame 2481/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.8ms\n",
            "Speed: 3.6ms preprocess, 109.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2481: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2484/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 111.1ms\n",
            "Speed: 3.5ms preprocess, 111.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2484: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2487/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.6ms\n",
            "Speed: 3.7ms preprocess, 112.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2487: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2490/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 116.6ms\n",
            "Speed: 3.6ms preprocess, 116.6ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2490: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2493/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.9ms\n",
            "Speed: 3.7ms preprocess, 113.9ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2493: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2496/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 111.8ms\n",
            "Speed: 3.5ms preprocess, 111.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2496: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2499/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 179.7ms\n",
            "Speed: 3.5ms preprocess, 179.7ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2499: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2502/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 183.7ms\n",
            "Speed: 4.0ms preprocess, 183.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2502: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2505/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 182.6ms\n",
            "Speed: 3.5ms preprocess, 182.6ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2505: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2508/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 178.8ms\n",
            "Speed: 7.1ms preprocess, 178.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2508: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2511/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 179.9ms\n",
            "Speed: 3.1ms preprocess, 179.9ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2511: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2514/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 117.8ms\n",
            "Speed: 4.6ms preprocess, 117.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2514: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2517/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 112.4ms\n",
            "Speed: 6.9ms preprocess, 112.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2517: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2520/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 146.9ms\n",
            "Speed: 4.1ms preprocess, 146.9ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2520: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2523/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 125.0ms\n",
            "Speed: 6.8ms preprocess, 125.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2523: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2526/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 2 cars, 127.1ms\n",
            "Speed: 3.6ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2526: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 2529/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 107.5ms\n",
            "Speed: 5.2ms preprocess, 107.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2529: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2532/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 107.4ms\n",
            "Speed: 3.5ms preprocess, 107.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2532: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2535/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.2ms\n",
            "Speed: 4.0ms preprocess, 109.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2535: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2538/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 119.1ms\n",
            "Speed: 4.1ms preprocess, 119.1ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2538: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2541/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 112.0ms\n",
            "Speed: 3.1ms preprocess, 112.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2541: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2544/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 113.6ms\n",
            "Speed: 3.2ms preprocess, 113.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2544: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2547/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 118.0ms\n",
            "Speed: 3.1ms preprocess, 118.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2547: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2550/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.4ms\n",
            "Speed: 6.9ms preprocess, 110.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2550: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 2553/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 118.0ms\n",
            "Speed: 3.1ms preprocess, 118.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2553: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2556/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 110.9ms\n",
            "Speed: 3.2ms preprocess, 110.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2556: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2559/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 181.0ms\n",
            "Speed: 3.2ms preprocess, 181.0ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2559: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2562/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 177.1ms\n",
            "Speed: 5.3ms preprocess, 177.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2562: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 2565/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 180.3ms\n",
            "Speed: 3.6ms preprocess, 180.3ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2565: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2568/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 181.0ms\n",
            "Speed: 6.7ms preprocess, 181.0ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2568: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2571/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 186.4ms\n",
            "Speed: 3.7ms preprocess, 186.4ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2571: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2574/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 111.1ms\n",
            "Speed: 7.8ms preprocess, 111.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2574: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2577/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 110.6ms\n",
            "Speed: 6.2ms preprocess, 110.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2577: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2580/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.0ms\n",
            "Speed: 3.2ms preprocess, 113.0ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2580: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 2583/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.9ms\n",
            "Speed: 3.5ms preprocess, 114.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2583: Found 20 objects - car, lane\n",
            "    🔎 Processing frame 2586/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.9ms\n",
            "Speed: 3.5ms preprocess, 114.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2586: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 2589/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 4 cars, 115.5ms\n",
            "Speed: 3.4ms preprocess, 115.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2589: Found 24 objects - car, person, lane\n",
            "    🔎 Processing frame 2592/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 4 cars, 112.2ms\n",
            "Speed: 3.6ms preprocess, 112.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2592: Found 21 objects - car, person, lane\n",
            "    🔎 Processing frame 2595/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 6 cars, 128.7ms\n",
            "Speed: 3.7ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2595: Found 25 objects - car, person, lane\n",
            "    🔎 Processing frame 2598/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 7 cars, 1 fire hydrant, 112.9ms\n",
            "Speed: 3.3ms preprocess, 112.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2598: Found 22 objects - car, person, lane\n",
            "    🔎 Processing frame 2601/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 7 cars, 128.0ms\n",
            "Speed: 5.8ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2601: Found 29 objects - car, person, lane\n",
            "    🔎 Processing frame 2604/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 7 cars, 1 traffic light, 107.8ms\n",
            "Speed: 3.9ms preprocess, 107.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2604: Found 24 objects - car, person, traffic light, lane\n",
            "    🔎 Processing frame 2607/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 124.7ms\n",
            "Speed: 3.5ms preprocess, 124.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2607: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 2610/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.3ms\n",
            "Speed: 4.0ms preprocess, 112.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2610: Found 19 objects - car, lane\n",
            "    🔎 Processing frame 2613/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 1 truck, 1 stop sign, 128.7ms\n",
            "Speed: 3.2ms preprocess, 128.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2613: Found 32 objects - car, stop sign, truck, lane\n",
            "    🔎 Processing frame 2616/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 truck, 113.0ms\n",
            "Speed: 3.3ms preprocess, 113.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2616: Found 36 objects - car, truck, lane\n",
            "    🔎 Processing frame 2619/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 1 stop sign, 122.0ms\n",
            "Speed: 3.4ms preprocess, 122.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2619: Found 38 objects - car, stop sign, lane\n",
            "    🔎 Processing frame 2622/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 111.8ms\n",
            "Speed: 3.4ms preprocess, 111.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2622: Found 31 objects - car, lane\n",
            "    🔎 Processing frame 2625/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 125.8ms\n",
            "Speed: 7.6ms preprocess, 125.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2625: Found 32 objects - car, lane\n",
            "    🔎 Processing frame 2628/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 8 cars, 170.8ms\n",
            "Speed: 6.3ms preprocess, 170.8ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2628: Found 27 objects - car, lane\n",
            "    🔎 Processing frame 2631/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 166.8ms\n",
            "Speed: 3.4ms preprocess, 166.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2631: Found 26 objects - car, lane\n",
            "\n",
            "📈 Progress: 70.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 83\n",
            "    car: 3626\n",
            "    truck: 52\n",
            "    bus: 32\n",
            "    traffic light: 32\n",
            "    stop sign: 3\n",
            "    lane: 8505\n",
            "\n",
            "    🔎 Processing frame 2634/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 1 traffic light, 173.6ms\n",
            "Speed: 7.6ms preprocess, 173.6ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2634: Found 17 objects - car, traffic light, lane\n",
            "    🔎 Processing frame 2637/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 8 cars, 178.7ms\n",
            "Speed: 4.0ms preprocess, 178.7ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2637: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 2640/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 110.7ms\n",
            "Speed: 3.4ms preprocess, 110.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2640: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2643/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 110.2ms\n",
            "Speed: 7.1ms preprocess, 110.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2643: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2646/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 8 cars, 109.4ms\n",
            "Speed: 3.7ms preprocess, 109.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2646: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2649/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 108.2ms\n",
            "Speed: 3.6ms preprocess, 108.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2649: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2652/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 8 cars, 106.9ms\n",
            "Speed: 4.6ms preprocess, 106.9ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2652: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 2655/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 117.1ms\n",
            "Speed: 4.3ms preprocess, 117.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2655: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2658/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 1 truck, 108.4ms\n",
            "Speed: 3.3ms preprocess, 108.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2658: Found 16 objects - car, truck, lane\n",
            "    🔎 Processing frame 2661/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 1 truck, 1 traffic light, 115.8ms\n",
            "Speed: 4.0ms preprocess, 115.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2661: Found 19 objects - car, truck, traffic light, lane\n",
            "    🔎 Processing frame 2664/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 1 truck, 105.9ms\n",
            "Speed: 4.2ms preprocess, 105.9ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2664: Found 17 objects - car, truck, lane\n",
            "    🔎 Processing frame 2667/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 2 trucks, 115.8ms\n",
            "Speed: 3.1ms preprocess, 115.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2667: Found 14 objects - car, truck, lane\n",
            "    🔎 Processing frame 2670/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 2 trucks, 108.5ms\n",
            "Speed: 3.1ms preprocess, 108.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2670: Found 13 objects - car, truck, lane\n",
            "    🔎 Processing frame 2673/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 113.0ms\n",
            "Speed: 3.9ms preprocess, 113.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2673: Found 13 objects - car, truck, lane\n",
            "    🔎 Processing frame 2676/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 2 trucks, 107.4ms\n",
            "Speed: 4.9ms preprocess, 107.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2676: Found 14 objects - car, truck, lane\n",
            "    🔎 Processing frame 2679/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 1 truck, 108.1ms\n",
            "Speed: 3.4ms preprocess, 108.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2679: Found 12 objects - car, truck, lane\n",
            "    🔎 Processing frame 2682/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 truck, 107.1ms\n",
            "Speed: 7.4ms preprocess, 107.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2682: Found 11 objects - car, truck, lane\n",
            "    🔎 Processing frame 2685/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 2 trucks, 107.5ms\n",
            "Speed: 4.9ms preprocess, 107.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2685: Found 14 objects - car, truck, lane\n",
            "    🔎 Processing frame 2688/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 109.1ms\n",
            "Speed: 3.3ms preprocess, 109.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2688: Found 12 objects - car, truck, lane\n",
            "    🔎 Processing frame 2691/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 1 truck, 112.4ms\n",
            "Speed: 3.1ms preprocess, 112.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2691: Found 14 objects - car, truck, lane\n",
            "    🔎 Processing frame 2694/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 8 cars, 1 truck, 202.9ms\n",
            "Speed: 3.6ms preprocess, 202.9ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2694: Found 16 objects - car, truck, lane\n",
            "    🔎 Processing frame 2697/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 174.1ms\n",
            "Speed: 9.8ms preprocess, 174.1ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2697: Found 11 objects - car, truck, lane\n",
            "    🔎 Processing frame 2700/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 truck, 168.6ms\n",
            "Speed: 6.6ms preprocess, 168.6ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2700: Found 13 objects - car, truck, lane\n",
            "    🔎 Processing frame 2703/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 1 truck, 174.6ms\n",
            "Speed: 5.4ms preprocess, 174.6ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2703: Found 13 objects - car, truck, lane\n",
            "    🔎 Processing frame 2706/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 1 bus, 185.5ms\n",
            "Speed: 5.3ms preprocess, 185.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2706: Found 14 objects - car, bus, lane\n",
            "    🔎 Processing frame 2709/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 168.7ms\n",
            "Speed: 3.3ms preprocess, 168.7ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2709: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2712/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 111.1ms\n",
            "Speed: 3.3ms preprocess, 111.1ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2712: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2715/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 117.9ms\n",
            "Speed: 3.0ms preprocess, 117.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2715: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2718/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 106.3ms\n",
            "Speed: 4.8ms preprocess, 106.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2718: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2721/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 113.5ms\n",
            "Speed: 3.5ms preprocess, 113.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2721: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 2724/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 104.8ms\n",
            "Speed: 3.5ms preprocess, 104.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2724: Found 22 objects - car, lane\n",
            "    🔎 Processing frame 2727/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.5ms\n",
            "Speed: 4.1ms preprocess, 109.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2727: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 2730/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 107.0ms\n",
            "Speed: 3.3ms preprocess, 107.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2730: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 2733/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 1 bus, 104.8ms\n",
            "Speed: 3.6ms preprocess, 104.8ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2733: Found 22 objects - car, bus, lane\n",
            "    🔎 Processing frame 2736/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 1 bus, 126.4ms\n",
            "Speed: 3.6ms preprocess, 126.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2736: Found 22 objects - car, bus, lane\n",
            "    🔎 Processing frame 2739/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 107.9ms\n",
            "Speed: 3.5ms preprocess, 107.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2739: Found 22 objects - car, lane\n",
            "    🔎 Processing frame 2742/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 129.9ms\n",
            "Speed: 3.2ms preprocess, 129.9ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2742: Found 22 objects - car, lane\n",
            "    🔎 Processing frame 2745/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.9ms\n",
            "Speed: 3.2ms preprocess, 109.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2745: Found 22 objects - car, lane\n",
            "    🔎 Processing frame 2748/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 118.2ms\n",
            "Speed: 3.3ms preprocess, 118.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2748: Found 24 objects - car, lane\n",
            "    🔎 Processing frame 2751/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 105.8ms\n",
            "Speed: 6.8ms preprocess, 105.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2751: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 2754/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.9ms\n",
            "Speed: 3.2ms preprocess, 110.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2754: Found 22 objects - car, lane\n",
            "    🔎 Processing frame 2757/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.1ms\n",
            "Speed: 3.4ms preprocess, 109.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2757: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2760/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.8ms\n",
            "Speed: 3.3ms preprocess, 110.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2760: Found 25 objects - car, lane\n",
            "    🔎 Processing frame 2763/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.8ms\n",
            "Speed: 3.3ms preprocess, 113.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2763: Found 19 objects - car, lane\n",
            "    🔎 Processing frame 2766/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 172.8ms\n",
            "Speed: 3.4ms preprocess, 172.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2766: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 2769/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 180.0ms\n",
            "Speed: 6.8ms preprocess, 180.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2769: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 2772/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 175.3ms\n",
            "Speed: 3.4ms preprocess, 175.3ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2772: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 2775/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 202.2ms\n",
            "Speed: 4.3ms preprocess, 202.2ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2775: Found 20 objects - car, lane\n",
            "    🔎 Processing frame 2778/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 139.3ms\n",
            "Speed: 3.5ms preprocess, 139.3ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2778: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 2781/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 121.6ms\n",
            "Speed: 3.2ms preprocess, 121.6ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2781: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 2784/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.4ms\n",
            "Speed: 3.1ms preprocess, 114.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2784: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 2787/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 105.0ms\n",
            "Speed: 3.6ms preprocess, 105.0ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2787: Found 25 objects - car, lane\n",
            "    🔎 Processing frame 2790/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.2ms\n",
            "Speed: 3.3ms preprocess, 110.2ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2790: Found 21 objects - car, lane\n",
            "    🔎 Processing frame 2793/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.1ms\n",
            "Speed: 5.7ms preprocess, 109.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2793: Found 25 objects - car, lane\n",
            "    🔎 Processing frame 2796/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 134.7ms\n",
            "Speed: 4.3ms preprocess, 134.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2796: Found 24 objects - car, lane\n",
            "    🔎 Processing frame 2799/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.3ms\n",
            "Speed: 3.4ms preprocess, 114.3ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2799: Found 26 objects - car, lane\n",
            "    🔎 Processing frame 2802/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 125.7ms\n",
            "Speed: 3.3ms preprocess, 125.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2802: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 2805/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.6ms\n",
            "Speed: 3.2ms preprocess, 114.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2805: Found 30 objects - car, lane\n",
            "    🔎 Processing frame 2808/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.2ms\n",
            "Speed: 3.3ms preprocess, 111.2ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2808: Found 28 objects - car, lane\n",
            "    🔎 Processing frame 2811/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.0ms\n",
            "Speed: 3.5ms preprocess, 113.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2811: Found 30 objects - car, lane\n",
            "    🔎 Processing frame 2814/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.8ms\n",
            "Speed: 3.6ms preprocess, 111.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2814: Found 23 objects - car, lane\n",
            "    🔎 Processing frame 2817/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.8ms\n",
            "Speed: 5.4ms preprocess, 109.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2817: Found 27 objects - car, lane\n",
            "    🔎 Processing frame 2820/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 118.5ms\n",
            "Speed: 3.5ms preprocess, 118.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2820: Found 23 objects - car, lane\n",
            "\n",
            "📈 Progress: 75.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 83\n",
            "    car: 3976\n",
            "    truck: 72\n",
            "    bus: 35\n",
            "    traffic light: 34\n",
            "    stop sign: 3\n",
            "    lane: 9318\n",
            "\n",
            "    🔎 Processing frame 2823/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.0ms\n",
            "Speed: 4.8ms preprocess, 109.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2823: Found 19 objects - car, lane\n",
            "    🔎 Processing frame 2826/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.9ms\n",
            "Speed: 3.9ms preprocess, 111.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2826: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 2829/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 169.9ms\n",
            "Speed: 6.6ms preprocess, 169.9ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2829: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 2832/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 173.3ms\n",
            "Speed: 4.5ms preprocess, 173.3ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2832: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2835/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 174.0ms\n",
            "Speed: 3.8ms preprocess, 174.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2835: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2838/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 170.8ms\n",
            "Speed: 3.7ms preprocess, 170.8ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2838: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 2841/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 187.1ms\n",
            "Speed: 3.3ms preprocess, 187.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2841: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 2844/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 1 traffic light, 180.6ms\n",
            "Speed: 3.3ms preprocess, 180.6ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2844: Found 17 objects - car, traffic light, lane\n",
            "    🔎 Processing frame 2847/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.0ms\n",
            "Speed: 7.2ms preprocess, 111.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2847: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2850/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.0ms\n",
            "Speed: 4.0ms preprocess, 112.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2850: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2853/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.9ms\n",
            "Speed: 5.7ms preprocess, 111.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2853: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2856/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.6ms\n",
            "Speed: 6.8ms preprocess, 108.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2856: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2859/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.4ms\n",
            "Speed: 6.4ms preprocess, 112.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2859: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2862/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.5ms\n",
            "Speed: 3.2ms preprocess, 110.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2862: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2865/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.3ms\n",
            "Speed: 3.3ms preprocess, 114.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2865: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2868/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.3ms\n",
            "Speed: 3.2ms preprocess, 113.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2868: Found 19 objects - car, lane\n",
            "    🔎 Processing frame 2871/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 122.4ms\n",
            "Speed: 3.3ms preprocess, 122.4ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2871: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2874/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.5ms\n",
            "Speed: 3.2ms preprocess, 111.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2874: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2877/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 113.4ms\n",
            "Speed: 3.4ms preprocess, 113.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2877: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2880/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.9ms\n",
            "Speed: 3.3ms preprocess, 112.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2880: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2883/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.4ms\n",
            "Speed: 6.0ms preprocess, 110.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2883: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2886/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 105.9ms\n",
            "Speed: 3.7ms preprocess, 105.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2886: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2889/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 110.8ms\n",
            "Speed: 5.6ms preprocess, 110.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2889: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2892/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 163.9ms\n",
            "Speed: 3.8ms preprocess, 163.9ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2892: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2895/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 167.3ms\n",
            "Speed: 5.7ms preprocess, 167.3ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2895: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2898/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 183.8ms\n",
            "Speed: 4.0ms preprocess, 183.8ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2898: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2901/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 174.2ms\n",
            "Speed: 3.7ms preprocess, 174.2ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2901: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2904/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 135.6ms\n",
            "Speed: 8.4ms preprocess, 135.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2904: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2907/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 108.8ms\n",
            "Speed: 6.0ms preprocess, 108.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2907: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2910/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 127.5ms\n",
            "Speed: 5.0ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2910: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2913/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.7ms\n",
            "Speed: 3.0ms preprocess, 109.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2913: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 2916/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 127.3ms\n",
            "Speed: 6.6ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2916: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2919/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.0ms\n",
            "Speed: 3.4ms preprocess, 111.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2919: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2922/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 1 person, 3 cars, 138.6ms\n",
            "Speed: 3.5ms preprocess, 138.6ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2922: Found 14 objects - car, person, lane\n",
            "    🔎 Processing frame 2925/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 105.1ms\n",
            "Speed: 3.7ms preprocess, 105.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2925: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2928/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.6ms\n",
            "Speed: 3.4ms preprocess, 108.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2928: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2931/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 107.5ms\n",
            "Speed: 3.3ms preprocess, 107.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2931: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2934/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 111.4ms\n",
            "Speed: 3.2ms preprocess, 111.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2934: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2937/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 105.7ms\n",
            "Speed: 6.1ms preprocess, 105.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2937: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2940/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 108.0ms\n",
            "Speed: 3.3ms preprocess, 108.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2940: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2943/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 113.9ms\n",
            "Speed: 5.7ms preprocess, 113.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2943: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2946/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.9ms\n",
            "Speed: 5.8ms preprocess, 109.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2946: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2949/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 108.8ms\n",
            "Speed: 3.5ms preprocess, 108.8ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2949: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2952/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.1ms\n",
            "Speed: 3.5ms preprocess, 109.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2952: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2955/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 112.7ms\n",
            "Speed: 3.3ms preprocess, 112.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2955: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2958/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 107.8ms\n",
            "Speed: 3.4ms preprocess, 107.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2958: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2961/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 114.1ms\n",
            "Speed: 3.5ms preprocess, 114.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2961: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2964/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 177.0ms\n",
            "Speed: 3.4ms preprocess, 177.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2964: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2967/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 177.1ms\n",
            "Speed: 3.4ms preprocess, 177.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2967: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 2970/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 163.2ms\n",
            "Speed: 3.4ms preprocess, 163.2ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2970: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 2973/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 181.0ms\n",
            "Speed: 3.5ms preprocess, 181.0ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2973: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2976/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 185.3ms\n",
            "Speed: 3.5ms preprocess, 185.3ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2976: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 2979/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 111.5ms\n",
            "Speed: 3.6ms preprocess, 111.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2979: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2982/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 128.4ms\n",
            "Speed: 6.3ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2982: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 2985/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 116.6ms\n",
            "Speed: 3.4ms preprocess, 116.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2985: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 2988/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 135.1ms\n",
            "Speed: 4.4ms preprocess, 135.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2988: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2991/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.9ms\n",
            "Speed: 3.7ms preprocess, 109.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2991: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 2994/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 115.3ms\n",
            "Speed: 8.2ms preprocess, 115.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2994: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 2997/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.5ms\n",
            "Speed: 6.3ms preprocess, 111.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 2997: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3000/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 120.4ms\n",
            "Speed: 4.6ms preprocess, 120.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3000: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 3003/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.6ms\n",
            "Speed: 6.5ms preprocess, 114.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3003: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3006/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.8ms\n",
            "Speed: 3.4ms preprocess, 109.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3006: Found 11 objects - car, lane\n",
            "\n",
            "📈 Progress: 80.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 84\n",
            "    car: 4212\n",
            "    truck: 72\n",
            "    bus: 35\n",
            "    traffic light: 35\n",
            "    stop sign: 3\n",
            "    lane: 9963\n",
            "\n",
            "    🔎 Processing frame 3009/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.2ms\n",
            "Speed: 3.8ms preprocess, 110.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3009: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3012/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.1ms\n",
            "Speed: 3.5ms preprocess, 109.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3012: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3015/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.1ms\n",
            "Speed: 3.3ms preprocess, 108.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3015: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3018/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.8ms\n",
            "Speed: 3.4ms preprocess, 112.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3018: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 3021/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 115.5ms\n",
            "Speed: 3.8ms preprocess, 115.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3021: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3024/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 109.1ms\n",
            "Speed: 4.0ms preprocess, 109.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3024: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3027/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.3ms\n",
            "Speed: 3.4ms preprocess, 111.3ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3027: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3030/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 106.7ms\n",
            "Speed: 3.6ms preprocess, 106.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3030: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3033/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 111.9ms\n",
            "Speed: 3.4ms preprocess, 111.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3033: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3036/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 176.2ms\n",
            "Speed: 3.4ms preprocess, 176.2ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3036: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3039/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 172.8ms\n",
            "Speed: 3.5ms preprocess, 172.8ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3039: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3042/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 175.5ms\n",
            "Speed: 6.1ms preprocess, 175.5ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3042: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3045/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 163.1ms\n",
            "Speed: 10.8ms preprocess, 163.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3045: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3048/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 176.0ms\n",
            "Speed: 3.3ms preprocess, 176.0ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3048: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3051/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 175.3ms\n",
            "Speed: 3.8ms preprocess, 175.3ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3051: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3054/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 132.7ms\n",
            "Speed: 3.5ms preprocess, 132.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3054: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 3057/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.9ms\n",
            "Speed: 3.1ms preprocess, 114.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3057: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3060/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 106.4ms\n",
            "Speed: 3.5ms preprocess, 106.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3060: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3063/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 106.1ms\n",
            "Speed: 7.0ms preprocess, 106.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3063: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3066/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.1ms\n",
            "Speed: 3.4ms preprocess, 108.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3066: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3069/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.6ms\n",
            "Speed: 3.6ms preprocess, 112.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3069: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3072/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 115.3ms\n",
            "Speed: 3.5ms preprocess, 115.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3072: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3075/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.5ms\n",
            "Speed: 3.5ms preprocess, 113.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3075: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3078/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.6ms\n",
            "Speed: 7.0ms preprocess, 112.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3078: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3081/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.7ms\n",
            "Speed: 9.5ms preprocess, 109.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3081: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3084/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 121.1ms\n",
            "Speed: 4.1ms preprocess, 121.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3084: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3087/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 117.0ms\n",
            "Speed: 3.5ms preprocess, 117.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3087: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3090/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 112.2ms\n",
            "Speed: 3.6ms preprocess, 112.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3090: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3093/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.5ms\n",
            "Speed: 3.3ms preprocess, 112.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3093: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3096/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.4ms\n",
            "Speed: 4.9ms preprocess, 111.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3096: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3099/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.7ms\n",
            "Speed: 3.4ms preprocess, 108.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3099: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3102/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.0ms\n",
            "Speed: 3.4ms preprocess, 110.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3102: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3105/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 173.0ms\n",
            "Speed: 3.6ms preprocess, 173.0ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3105: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3108/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 177.0ms\n",
            "Speed: 3.5ms preprocess, 177.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3108: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3111/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 164.9ms\n",
            "Speed: 3.7ms preprocess, 164.9ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3111: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3114/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 116.4ms\n",
            "Speed: 3.0ms preprocess, 116.4ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3114: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3117/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.9ms\n",
            "Speed: 5.9ms preprocess, 112.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3117: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3120/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.6ms\n",
            "Speed: 5.3ms preprocess, 110.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3120: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3123/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.9ms\n",
            "Speed: 3.4ms preprocess, 110.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3123: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3126/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 107.5ms\n",
            "Speed: 3.4ms preprocess, 107.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3126: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3129/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.2ms\n",
            "Speed: 6.1ms preprocess, 110.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3129: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3132/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 115.3ms\n",
            "Speed: 3.4ms preprocess, 115.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3132: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3135/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 119.1ms\n",
            "Speed: 3.5ms preprocess, 119.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3135: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3138/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 125.5ms\n",
            "Speed: 5.1ms preprocess, 125.5ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3138: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3141/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.6ms\n",
            "Speed: 3.3ms preprocess, 109.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3141: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3144/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 126.8ms\n",
            "Speed: 4.5ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3144: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3147/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.4ms\n",
            "Speed: 4.6ms preprocess, 112.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3147: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3150/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.3ms\n",
            "Speed: 3.2ms preprocess, 110.3ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3150: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3153/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.4ms\n",
            "Speed: 5.3ms preprocess, 112.4ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3153: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3156/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 113.6ms\n",
            "Speed: 4.0ms preprocess, 113.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3156: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3159/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 110.3ms\n",
            "Speed: 6.2ms preprocess, 110.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3159: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3162/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 114.9ms\n",
            "Speed: 3.3ms preprocess, 114.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3162: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3165/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 112.7ms\n",
            "Speed: 3.1ms preprocess, 112.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3165: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3168/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 170.8ms\n",
            "Speed: 3.4ms preprocess, 170.8ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3168: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3171/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 172.5ms\n",
            "Speed: 3.4ms preprocess, 172.5ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3171: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3174/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 177.3ms\n",
            "Speed: 3.6ms preprocess, 177.3ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3174: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 3177/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 175.2ms\n",
            "Speed: 4.5ms preprocess, 175.2ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3177: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3180/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 189.8ms\n",
            "Speed: 3.2ms preprocess, 189.8ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3180: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3183/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 178.7ms\n",
            "Speed: 3.6ms preprocess, 178.7ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3183: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3186/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.5ms\n",
            "Speed: 4.0ms preprocess, 113.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3186: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3189/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.8ms\n",
            "Speed: 3.1ms preprocess, 110.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3189: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3192/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.7ms\n",
            "Speed: 3.7ms preprocess, 108.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3192: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3195/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.4ms\n",
            "Speed: 5.8ms preprocess, 110.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3195: Found 11 objects - car, lane\n",
            "\n",
            "📈 Progress: 85.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 84\n",
            "    car: 4495\n",
            "    truck: 72\n",
            "    bus: 35\n",
            "    traffic light: 35\n",
            "    stop sign: 3\n",
            "    lane: 10458\n",
            "\n",
            "    🔎 Processing frame 3198/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.4ms\n",
            "Speed: 6.7ms preprocess, 112.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3198: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3201/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 128.6ms\n",
            "Speed: 3.4ms preprocess, 128.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3201: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3204/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.6ms\n",
            "Speed: 3.4ms preprocess, 111.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3204: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3207/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.0ms\n",
            "Speed: 4.1ms preprocess, 111.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3207: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3210/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.6ms\n",
            "Speed: 3.4ms preprocess, 111.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3210: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3213/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 106.5ms\n",
            "Speed: 3.8ms preprocess, 106.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3213: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3216/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.2ms\n",
            "Speed: 3.3ms preprocess, 108.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3216: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3219/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.8ms\n",
            "Speed: 3.3ms preprocess, 113.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3219: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3222/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 108.9ms\n",
            "Speed: 3.5ms preprocess, 108.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3222: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 3225/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 113.7ms\n",
            "Speed: 3.4ms preprocess, 113.7ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3225: Found 8 objects - car, lane\n",
            "    🔎 Processing frame 3228/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 109.0ms\n",
            "Speed: 3.5ms preprocess, 109.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3228: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3231/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.0ms\n",
            "Speed: 3.2ms preprocess, 112.0ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3231: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3234/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 120.4ms\n",
            "Speed: 7.4ms preprocess, 120.4ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3234: Found 9 objects - car, lane\n",
            "    🔎 Processing frame 3237/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.8ms\n",
            "Speed: 3.4ms preprocess, 111.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3237: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3240/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 171.5ms\n",
            "Speed: 3.6ms preprocess, 171.5ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3240: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3243/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 169.4ms\n",
            "Speed: 3.5ms preprocess, 169.4ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3243: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3246/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 170.4ms\n",
            "Speed: 3.4ms preprocess, 170.4ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3246: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3249/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 182.7ms\n",
            "Speed: 3.2ms preprocess, 182.7ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3249: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3252/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 184.6ms\n",
            "Speed: 3.4ms preprocess, 184.6ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3252: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3255/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.9ms\n",
            "Speed: 3.4ms preprocess, 109.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3255: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3258/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 132.2ms\n",
            "Speed: 3.2ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3258: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3261/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 181.6ms\n",
            "Speed: 3.4ms preprocess, 181.6ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3261: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3264/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 174.9ms\n",
            "Speed: 10.8ms preprocess, 174.9ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3264: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3267/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.8ms\n",
            "Speed: 3.1ms preprocess, 114.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3267: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3270/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.1ms\n",
            "Speed: 5.6ms preprocess, 112.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3270: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3273/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.1ms\n",
            "Speed: 3.3ms preprocess, 111.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3273: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3276/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 117.7ms\n",
            "Speed: 3.3ms preprocess, 117.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3276: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3279/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.5ms\n",
            "Speed: 3.9ms preprocess, 109.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3279: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3282/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.3ms\n",
            "Speed: 3.4ms preprocess, 113.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3282: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3285/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 115.4ms\n",
            "Speed: 4.2ms preprocess, 115.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3285: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3288/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.7ms\n",
            "Speed: 4.3ms preprocess, 111.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3288: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3291/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 186.3ms\n",
            "Speed: 6.6ms preprocess, 186.3ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3291: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3294/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 197.0ms\n",
            "Speed: 3.4ms preprocess, 197.0ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3294: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3297/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 118.8ms\n",
            "Speed: 4.1ms preprocess, 118.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3297: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3300/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.3ms\n",
            "Speed: 3.3ms preprocess, 113.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3300: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3303/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.6ms\n",
            "Speed: 3.5ms preprocess, 108.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3303: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3306/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 106.0ms\n",
            "Speed: 4.6ms preprocess, 106.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3306: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3309/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 107.5ms\n",
            "Speed: 3.6ms preprocess, 107.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3309: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3312/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.0ms\n",
            "Speed: 4.2ms preprocess, 111.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3312: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3315/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.5ms\n",
            "Speed: 3.4ms preprocess, 111.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3315: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3318/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 124.9ms\n",
            "Speed: 4.0ms preprocess, 124.9ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3318: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3321/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.2ms\n",
            "Speed: 4.1ms preprocess, 111.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3321: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3324/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 107.6ms\n",
            "Speed: 3.4ms preprocess, 107.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3324: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3327/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.8ms\n",
            "Speed: 5.9ms preprocess, 111.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3327: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3330/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 177.7ms\n",
            "Speed: 3.5ms preprocess, 177.7ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3330: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3333/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 188.0ms\n",
            "Speed: 4.5ms preprocess, 188.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3333: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3336/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 182.7ms\n",
            "Speed: 3.8ms preprocess, 182.7ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3336: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3339/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 129.2ms\n",
            "Speed: 3.5ms preprocess, 129.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3339: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3342/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 110.2ms\n",
            "Speed: 3.6ms preprocess, 110.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3342: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3345/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 122.1ms\n",
            "Speed: 5.8ms preprocess, 122.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3345: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3348/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.6ms\n",
            "Speed: 5.5ms preprocess, 113.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3348: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3351/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 115.9ms\n",
            "Speed: 3.6ms preprocess, 115.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3351: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3354/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 112.0ms\n",
            "Speed: 3.4ms preprocess, 112.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3354: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3357/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.3ms\n",
            "Speed: 3.4ms preprocess, 112.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3357: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3360/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 110.1ms\n",
            "Speed: 4.8ms preprocess, 110.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3360: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3363/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 112.4ms\n",
            "Speed: 4.9ms preprocess, 112.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3363: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3366/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 111.0ms\n",
            "Speed: 4.1ms preprocess, 111.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3366: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3369/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 182.3ms\n",
            "Speed: 3.5ms preprocess, 182.3ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3369: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3372/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 179.3ms\n",
            "Speed: 8.5ms preprocess, 179.3ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3372: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3375/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 178.5ms\n",
            "Speed: 3.3ms preprocess, 178.5ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3375: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3378/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 116.9ms\n",
            "Speed: 3.2ms preprocess, 116.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3378: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3381/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.3ms\n",
            "Speed: 4.0ms preprocess, 109.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3381: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3384/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.0ms\n",
            "Speed: 3.3ms preprocess, 114.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3384: Found 12 objects - car, lane\n",
            "\n",
            "📈 Progress: 90.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 84\n",
            "    car: 4768\n",
            "    truck: 72\n",
            "    bus: 35\n",
            "    traffic light: 35\n",
            "    stop sign: 3\n",
            "    lane: 10915\n",
            "\n",
            "    🔎 Processing frame 3387/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.6ms\n",
            "Speed: 3.2ms preprocess, 111.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3387: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3390/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 127.7ms\n",
            "Speed: 6.9ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3390: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3393/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.1ms\n",
            "Speed: 7.6ms preprocess, 108.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3393: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3396/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.6ms\n",
            "Speed: 7.9ms preprocess, 114.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3396: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3399/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 117.6ms\n",
            "Speed: 3.7ms preprocess, 117.6ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3399: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3402/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.1ms\n",
            "Speed: 5.9ms preprocess, 112.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3402: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3405/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.2ms\n",
            "Speed: 3.3ms preprocess, 114.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3405: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3408/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.9ms\n",
            "Speed: 3.2ms preprocess, 112.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3408: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3411/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 112.5ms\n",
            "Speed: 3.5ms preprocess, 112.5ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3411: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3414/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 157.4ms\n",
            "Speed: 3.7ms preprocess, 157.4ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3414: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3417/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 175.6ms\n",
            "Speed: 3.8ms preprocess, 175.6ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3417: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3420/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 175.2ms\n",
            "Speed: 3.4ms preprocess, 175.2ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3420: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3423/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 172.0ms\n",
            "Speed: 3.5ms preprocess, 172.0ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3423: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3426/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 179.7ms\n",
            "Speed: 4.8ms preprocess, 179.7ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3426: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3429/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 178.5ms\n",
            "Speed: 6.1ms preprocess, 178.5ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3429: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3432/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.4ms\n",
            "Speed: 5.0ms preprocess, 114.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3432: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3435/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 116.5ms\n",
            "Speed: 3.5ms preprocess, 116.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3435: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3438/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 120.8ms\n",
            "Speed: 3.5ms preprocess, 120.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3438: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3441/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 120.3ms\n",
            "Speed: 3.8ms preprocess, 120.3ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3441: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3444/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 3 cars, 130.0ms\n",
            "Speed: 4.0ms preprocess, 130.0ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3444: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3447/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.4ms\n",
            "Speed: 3.4ms preprocess, 113.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3447: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3450/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 125.6ms\n",
            "Speed: 3.5ms preprocess, 125.6ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3450: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3453/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 125.0ms\n",
            "Speed: 3.7ms preprocess, 125.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3453: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3456/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 129.3ms\n",
            "Speed: 3.9ms preprocess, 129.3ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3456: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3459/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.9ms\n",
            "Speed: 3.5ms preprocess, 112.9ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3459: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3462/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.2ms\n",
            "Speed: 5.2ms preprocess, 112.2ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3462: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3465/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 114.3ms\n",
            "Speed: 3.5ms preprocess, 114.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3465: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3468/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.8ms\n",
            "Speed: 5.8ms preprocess, 108.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3468: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3471/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.7ms\n",
            "Speed: 4.4ms preprocess, 108.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3471: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3474/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 107.8ms\n",
            "Speed: 3.2ms preprocess, 107.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3474: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3477/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.6ms\n",
            "Speed: 5.6ms preprocess, 109.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3477: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3480/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.0ms\n",
            "Speed: 3.4ms preprocess, 110.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3480: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3483/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 168.9ms\n",
            "Speed: 3.4ms preprocess, 168.9ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3483: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3486/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 164.9ms\n",
            "Speed: 4.4ms preprocess, 164.9ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3486: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3489/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 206.8ms\n",
            "Speed: 4.0ms preprocess, 206.8ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3489: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3492/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 177.9ms\n",
            "Speed: 3.5ms preprocess, 177.9ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3492: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3495/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.7ms\n",
            "Speed: 7.0ms preprocess, 112.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3495: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3498/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.8ms\n",
            "Speed: 3.5ms preprocess, 111.8ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3498: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3501/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.7ms\n",
            "Speed: 3.7ms preprocess, 111.7ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3501: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3504/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 123.4ms\n",
            "Speed: 3.3ms preprocess, 123.4ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3504: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3507/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.2ms\n",
            "Speed: 6.6ms preprocess, 113.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3507: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3510/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.6ms\n",
            "Speed: 3.6ms preprocess, 109.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3510: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3513/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.7ms\n",
            "Speed: 4.0ms preprocess, 111.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3513: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3516/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.9ms\n",
            "Speed: 6.6ms preprocess, 109.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3516: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3519/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.9ms\n",
            "Speed: 3.4ms preprocess, 114.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3519: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3522/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 115.8ms\n",
            "Speed: 3.3ms preprocess, 115.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3522: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3525/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.1ms\n",
            "Speed: 3.3ms preprocess, 110.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3525: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3528/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 113.0ms\n",
            "Speed: 3.5ms preprocess, 113.0ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3528: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3531/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.7ms\n",
            "Speed: 3.4ms preprocess, 110.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3531: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3534/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 113.7ms\n",
            "Speed: 3.4ms preprocess, 113.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3534: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3537/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 174.0ms\n",
            "Speed: 3.2ms preprocess, 174.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3537: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3540/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 173.1ms\n",
            "Speed: 6.6ms preprocess, 173.1ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3540: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3543/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 166.5ms\n",
            "Speed: 9.2ms preprocess, 166.5ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3543: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3546/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 174.1ms\n",
            "Speed: 3.5ms preprocess, 174.1ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3546: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3549/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 178.8ms\n",
            "Speed: 3.8ms preprocess, 178.8ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3549: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3552/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 181.9ms\n",
            "Speed: 3.3ms preprocess, 181.9ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3552: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3555/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 115.4ms\n",
            "Speed: 3.1ms preprocess, 115.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3555: Found 11 objects - car, lane\n",
            "    🔎 Processing frame 3558/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 126.4ms\n",
            "Speed: 5.5ms preprocess, 126.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3558: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3561/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.2ms\n",
            "Speed: 3.6ms preprocess, 114.2ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3561: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3564/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.4ms\n",
            "Speed: 3.6ms preprocess, 112.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3564: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3567/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 116.3ms\n",
            "Speed: 3.3ms preprocess, 116.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3567: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3570/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 112.3ms\n",
            "Speed: 6.4ms preprocess, 112.3ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3570: Found 15 objects - car, lane\n",
            "\n",
            "📈 Progress: 95.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 84\n",
            "    car: 5037\n",
            "    truck: 72\n",
            "    bus: 35\n",
            "    traffic light: 35\n",
            "    stop sign: 3\n",
            "    lane: 11410\n",
            "\n",
            "    🔎 Processing frame 3573/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 107.9ms\n",
            "Speed: 5.5ms preprocess, 107.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3573: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3576/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 111.4ms\n",
            "Speed: 3.2ms preprocess, 111.4ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3576: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3579/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 113.4ms\n",
            "Speed: 4.7ms preprocess, 113.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3579: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3582/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 129.1ms\n",
            "Speed: 3.5ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3582: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 3585/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 110.0ms\n",
            "Speed: 3.7ms preprocess, 110.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3585: Found 18 objects - car, lane\n",
            "    🔎 Processing frame 3588/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 126.7ms\n",
            "Speed: 4.9ms preprocess, 126.7ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3588: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3591/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 118.6ms\n",
            "Speed: 6.7ms preprocess, 118.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3591: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3594/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 114.2ms\n",
            "Speed: 3.5ms preprocess, 114.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3594: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3597/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 106.6ms\n",
            "Speed: 4.2ms preprocess, 106.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3597: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 3600/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 112.9ms\n",
            "Speed: 7.6ms preprocess, 112.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3600: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 3603/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 175.8ms\n",
            "Speed: 3.5ms preprocess, 175.8ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3603: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3606/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 168.0ms\n",
            "Speed: 3.4ms preprocess, 168.0ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3606: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3609/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 169.0ms\n",
            "Speed: 9.2ms preprocess, 169.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3609: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3612/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 181.7ms\n",
            "Speed: 3.4ms preprocess, 181.7ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3612: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3615/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 186.3ms\n",
            "Speed: 3.3ms preprocess, 186.3ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3615: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3618/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 174.1ms\n",
            "Speed: 3.2ms preprocess, 174.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3618: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3621/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 115.7ms\n",
            "Speed: 5.4ms preprocess, 115.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3621: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3624/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 107.8ms\n",
            "Speed: 4.1ms preprocess, 107.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3624: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3627/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 119.5ms\n",
            "Speed: 3.2ms preprocess, 119.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3627: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3630/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 112.7ms\n",
            "Speed: 6.6ms preprocess, 112.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3630: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3633/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 126.9ms\n",
            "Speed: 3.4ms preprocess, 126.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3633: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3636/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 109.9ms\n",
            "Speed: 3.3ms preprocess, 109.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3636: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3639/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 111.3ms\n",
            "Speed: 5.4ms preprocess, 111.3ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3639: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3642/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 115.6ms\n",
            "Speed: 3.4ms preprocess, 115.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3642: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3645/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.3ms\n",
            "Speed: 6.6ms preprocess, 111.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3645: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3648/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.4ms\n",
            "Speed: 3.2ms preprocess, 111.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3648: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3651/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 112.4ms\n",
            "Speed: 3.5ms preprocess, 112.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3651: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3654/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 112.8ms\n",
            "Speed: 3.1ms preprocess, 112.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3654: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3657/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.8ms\n",
            "Speed: 4.5ms preprocess, 108.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3657: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3660/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 125.4ms\n",
            "Speed: 3.7ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3660: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3663/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 110.2ms\n",
            "Speed: 3.2ms preprocess, 110.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3663: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3666/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 174.7ms\n",
            "Speed: 3.8ms preprocess, 174.7ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3666: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3669/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 165.4ms\n",
            "Speed: 10.6ms preprocess, 165.4ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3669: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3672/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 167.1ms\n",
            "Speed: 3.4ms preprocess, 167.1ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3672: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3675/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 168.7ms\n",
            "Speed: 3.5ms preprocess, 168.7ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3675: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3678/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 180.7ms\n",
            "Speed: 6.2ms preprocess, 180.7ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3678: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3681/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 174.5ms\n",
            "Speed: 3.3ms preprocess, 174.5ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3681: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3684/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.0ms\n",
            "Speed: 7.8ms preprocess, 109.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3684: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3687/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.4ms\n",
            "Speed: 4.2ms preprocess, 109.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3687: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3690/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 108.5ms\n",
            "Speed: 5.8ms preprocess, 108.5ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3690: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3693/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 111.7ms\n",
            "Speed: 3.4ms preprocess, 111.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3693: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 3696/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.6ms\n",
            "Speed: 3.4ms preprocess, 110.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3696: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3699/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 7 cars, 114.9ms\n",
            "Speed: 3.8ms preprocess, 114.9ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3699: Found 17 objects - car, lane\n",
            "    🔎 Processing frame 3702/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 108.7ms\n",
            "Speed: 3.7ms preprocess, 108.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3702: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3705/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 109.7ms\n",
            "Speed: 4.1ms preprocess, 109.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3705: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3708/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 110.3ms\n",
            "Speed: 3.5ms preprocess, 110.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3708: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3711/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 111.4ms\n",
            "Speed: 5.7ms preprocess, 111.4ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3711: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3714/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 108.7ms\n",
            "Speed: 3.6ms preprocess, 108.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3714: Found 15 objects - car, lane\n",
            "    🔎 Processing frame 3717/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 114.6ms\n",
            "Speed: 3.4ms preprocess, 114.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3717: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3720/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 108.8ms\n",
            "Speed: 6.0ms preprocess, 108.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3720: Found 16 objects - car, lane\n",
            "    🔎 Processing frame 3723/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 122.0ms\n",
            "Speed: 6.5ms preprocess, 122.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3723: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3726/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 104.7ms\n",
            "Speed: 4.1ms preprocess, 104.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3726: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3729/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 181.6ms\n",
            "Speed: 5.4ms preprocess, 181.6ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3729: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3732/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 6 cars, 175.6ms\n",
            "Speed: 3.4ms preprocess, 175.6ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3732: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3735/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 178.1ms\n",
            "Speed: 3.4ms preprocess, 178.1ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3735: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3738/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 187.4ms\n",
            "Speed: 3.3ms preprocess, 187.4ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3738: Found 10 objects - car, lane\n",
            "    🔎 Processing frame 3741/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 178.5ms\n",
            "Speed: 3.3ms preprocess, 178.5ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3741: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3744/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.1ms\n",
            "Speed: 6.1ms preprocess, 113.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3744: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3747/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 109.6ms\n",
            "Speed: 3.4ms preprocess, 109.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3747: Found 12 objects - car, lane\n",
            "    🔎 Processing frame 3750/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 113.2ms\n",
            "Speed: 3.4ms preprocess, 113.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3750: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3753/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 107.6ms\n",
            "Speed: 3.2ms preprocess, 107.6ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3753: Found 14 objects - car, lane\n",
            "    🔎 Processing frame 3756/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 5 cars, 111.7ms\n",
            "Speed: 4.0ms preprocess, 111.7ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3756: Found 13 objects - car, lane\n",
            "    🔎 Processing frame 3759/3760...\n",
            "      🚗 Running traffic object detection...\n",
            "\n",
            "0: 288x640 4 cars, 125.4ms\n",
            "Speed: 3.3ms preprocess, 125.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "      🛣️  Running lane detection...\n",
            "      ✅ Frame 3759: Found 11 objects - car, lane\n",
            "\n",
            "📈 Progress: 100.0% complete\n",
            "🎯 Detection summary so far:\n",
            "    person: 84\n",
            "    car: 5375\n",
            "    truck: 72\n",
            "    bus: 35\n",
            "    traffic light: 35\n",
            "    stop sign: 3\n",
            "    lane: 11953\n",
            "\n",
            "🎉 Comprehensive detection completed!\n",
            "==================================================\n",
            "📊 FINAL DETECTION SUMMARY:\n",
            "==================================================\n",
            "🔸 Person: 84 detections\n",
            "🔸 Car: 5375 detections\n",
            "🔸 Truck: 72 detections\n",
            "🔸 Bus: 35 detections\n",
            "🔸 Traffic Light: 35 detections\n",
            "🔸 Stop Sign: 3 detections\n",
            "🔸 Lane: 11953 detections\n",
            "\n",
            "🎯 Total objects detected: 17557\n",
            "🎥 Output video: comprehensive_detection_result.mp4\n",
            "==================================================\n",
            "\n",
            "🎉 Comprehensive detection completed!\n",
            "📺 Result video: comprehensive_detection_result.mp4\n",
            "\n",
            "🎨 Color coding:\n",
            "  person: (0, 255, 0)\n",
            "  car: (255, 0, 0)\n",
            "  truck: (255, 0, 150)\n",
            "  bus: (255, 100, 0)\n",
            "  motorcycle: (0, 255, 255)\n",
            "  bicycle: (255, 255, 0)\n",
            "  traffic light: (0, 0, 255)\n",
            "  stop sign: (0, 150, 255)\n",
            "  lane: (255, 0, 255)\n",
            "  crosswalk: (255, 255, 255)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the contents of dataset.yaml"
      ],
      "metadata": {
        "id": "_NeRfugzfonO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. dataset.yaml 파일 내용 확인\n",
        "print(\"📋 dataset.yaml 파일 내용:\")\n",
        "with open('/content/dataset/dataset.yaml', 'r') as f:\n",
        "    yaml_content = f.read()\n",
        "    print(yaml_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqn9bfQjfm06",
        "outputId": "1950edec-2ebf-40d5-fdd1-25a5899a6ca5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📋 dataset.yaml 파일 내용:\n",
            "path: /content/dataset\n",
            "train: train/images\n",
            "val: valid/images\n",
            "names:\n",
            "  0: lane\n",
            "  1: traffic_sign\n",
            "nc: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trasfer Learning(perception) using YOLO11 and pre-traind YOLO"
      ],
      "metadata": {
        "id": "NgsEQKJGfoLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages for YOLO and video processing\n",
        "!pip install ultralytics yt-dlp\n",
        "\n",
        "# Import all necessary libraries\n",
        "from ultralytics import YOLO           # YOLO model for object detection\n",
        "import glob                            # File path pattern matching\n",
        "import cv2                             # OpenCV for video processing\n",
        "import numpy as np                     # Numerical operations\n",
        "from IPython.display import Video      # Display videos in Jupyter notebook\n",
        "import shutil                          # File operations (copy, move files)\n",
        "from google.colab import files         # File upload functionality for Google Colab\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: CREATE DATASET CONFIGURATION FILE\n",
        "# ============================================================================\n",
        "# This YAML configuration file defines the dataset structure for the custom model\n",
        "# It specifies where training/validation images are located and what classes exist\n",
        "yaml_fix = '''path: /content/dataset\n",
        "train: train/images\n",
        "val: valid/images\n",
        "names:\n",
        "  0: lane                # Class 0: Lane detection\n",
        "  1: traffic_sign        # Class 1: Traffic sign detection\n",
        "nc: 2'''                 # Number of classes (nc = number of classes)\n",
        "\n",
        "# Write the configuration to a file that YOLO can read\n",
        "with open('/content/dataset/dataset_fixed.yaml', 'w') as f:\n",
        "    f.write(yaml_fix)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: LOAD YOLO MODELS\n",
        "# ============================================================================\n",
        "print(\"🤖 모델 로드 중...\")\n",
        "print(\"   - 기본 YOLO 모델: 일반적인 80개 클래스 객체 탐지 (사람, 차량, 신호등 등)\")\n",
        "print(\"   - 커스텀 YOLO 모델: 특별히 학습된 2개 클래스 탐지 (차선, 교통표지판)\")\n",
        "\n",
        "# Load the base YOLO11n model (pre-trained on COCO dataset with 80 classes)\n",
        "base_model = YOLO('yolo11n.pt')        # Detects: person, car, truck, traffic light, etc.\n",
        "\n",
        "# Load your custom trained model (specialized for 2 classes)\n",
        "custom_model = YOLO('/content/dataset/best.pt')  # Detects: lane, traffic_sign\n",
        "\n",
        "print(f\"📋 기본 모델 클래스 수: {len(base_model.names)} (COCO 데이터셋 기반)\")\n",
        "print(f\"📋 커스텀 모델 클래스 수: {len(custom_model.names)} (차선, 교통표지판 전용)\")\n",
        "\n",
        "# Display what classes each model can detect\n",
        "print(f\"   🔍 기본 모델 클래스 예시: {list(base_model.names.values())[:10]}...\")  # Show first 10 classes\n",
        "print(f\"   🔍 커스텀 모델 클래스: {list(custom_model.names.values())}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: UPLOAD VIDEO FILES FROM PC\n",
        "# ============================================================================\n",
        "print(\"\\n📥 비디오 파일 업로드\")\n",
        "print(\"   PC에서 비디오 파일을 선택하여 업로드하세요\")\n",
        "print(\"   지원 형식: MP4, AVI, MOV, MKV 등 대부분의 비디오 형식\")\n",
        "\n",
        "# Open file upload dialog for users to select video files from their PC\n",
        "print(\"\\n🎬 업로드할 비디오 파일을 선택하세요:\")\n",
        "uploaded = files.upload()  # Returns a dictionary: {filename: file_content}\n",
        "\n",
        "# Check if any files were actually uploaded\n",
        "if not uploaded:\n",
        "    print(\"❌ 업로드된 파일이 없습니다!\")\n",
        "    raise Exception(\"No files uploaded - 업로드를 다시 시도해주세요\")\n",
        "\n",
        "print(f\"\\n✅ {len(uploaded)} 개의 파일이 업로드되었습니다\")\n",
        "\n",
        "# Get the first uploaded video file path\n",
        "# The uploaded files are automatically saved to the current directory\n",
        "uploaded_filenames = list(uploaded.keys())\n",
        "video_path = uploaded_filenames[0]  # Use the first uploaded file\n",
        "print(f\"📹 처리할 비디오: {video_path}\")\n",
        "print(f\"📁 파일 크기: {len(uploaded[video_path]) / (1024*1024):.1f} MB\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: COMBINED INFERENCE FUNCTION\n",
        "# ============================================================================\n",
        "def combined_inference(video_path, output_path='/content/combined_result.mp4'):\n",
        "    \"\"\"\n",
        "    Combine results from both base YOLO and custom YOLO models\n",
        "\n",
        "    Args:\n",
        "        video_path: Path to input video file\n",
        "        output_path: Path where the result video will be saved\n",
        "\n",
        "    Process:\n",
        "        1. Read video frame by frame\n",
        "        2. Run both models on each frame\n",
        "        3. Draw detection boxes with different colors\n",
        "        4. Save processed video\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n🎬 결합된 추론 시작: {video_path}\")\n",
        "    print(\"   두 개의 YOLO 모델을 동시에 실행하여 모든 객체를 탐지합니다\")\n",
        "\n",
        "    # ========== Video Properties Setup ==========\n",
        "    cap = cv2.VideoCapture(video_path)           # Open video file for reading\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))         # Get original video frame rate\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # Get video width in pixels\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Get video height in pixels\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # Total number of frames\n",
        "\n",
        "    print(f\"   📹 비디오 정보: {width}x{height} 해상도, {fps} FPS, {total_frames} 총 프레임\")\n",
        "\n",
        "    # Setup output video writer with same properties as input video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')     # Video codec for MP4 format\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # ========== Frame Processing Loop ==========\n",
        "    frame_count = 0\n",
        "    print(f\"🔄 영상 처리 중... (총 {total_frames} 프레임)\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()  # Read next frame from video\n",
        "        if not ret:              # If no more frames, break the loop\n",
        "            break\n",
        "\n",
        "        # ========== Run Both YOLO Models ==========\n",
        "        # Base YOLO inference: detects general objects (cars, people, traffic lights, etc.)\n",
        "        base_results = base_model(frame, verbose=False)    # verbose=False: suppress output messages\n",
        "\n",
        "        # Custom YOLO inference: detects specialized objects (lanes, traffic signs)\n",
        "        custom_results = custom_model(frame, verbose=False)\n",
        "\n",
        "        # ========== Prepare Frame for Annotation ==========\n",
        "        annotated_frame = frame.copy()  # Create a copy to draw on (preserve original)\n",
        "\n",
        "        # ========== Draw Base YOLO Results (BLUE boxes) ==========\n",
        "        if base_results[0].boxes is not None:  # Check if any objects were detected\n",
        "            for box in base_results[0].boxes:\n",
        "                # Extract bounding box coordinates (x1, y1) = top-left, (x2, y2) = bottom-right\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])        # Confidence score (0.0 to 1.0)\n",
        "                cls = int(box.cls[0])            # Class index number\n",
        "\n",
        "                # Only draw boxes with confidence > 30% to reduce false positives\n",
        "                if conf > 0.3:\n",
        "                    # Create label text with class name and confidence percentage\n",
        "                    label = f\"{base_model.names[cls]} {conf:.2f}\"\n",
        "\n",
        "                    # Draw blue rectangle around detected object\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Blue color (B, G, R)\n",
        "\n",
        "                    # Draw label text above the rectangle\n",
        "                    cv2.putText(annotated_frame, label, (x1, y1-10),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # ========== Draw Custom YOLO Results (RED boxes) ==========\n",
        "        if custom_results[0].boxes is not None:  # Check if any objects were detected\n",
        "            for box in custom_results[0].boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "                cls = int(box.cls[0])\n",
        "\n",
        "                # Only draw boxes with confidence > 30%\n",
        "                if conf > 0.3:\n",
        "                    # Create label text with class name and confidence\n",
        "                    label = f\"{custom_model.names[cls]} {conf:.2f}\"\n",
        "\n",
        "                    # Draw red rectangle around detected object\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red color (B, G, R)\n",
        "\n",
        "                    # Draw label text above the rectangle\n",
        "                    cv2.putText(annotated_frame, label, (x1, y1-10),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "        # ========== Save Processed Frame ==========\n",
        "        out.write(annotated_frame)  # Write the annotated frame to output video\n",
        "        frame_count += 1\n",
        "\n",
        "        # Progress reporting every 30 frames to avoid overwhelming the console\n",
        "        if frame_count % 30 == 0:\n",
        "            progress_percent = (frame_count / total_frames) * 100\n",
        "            print(f\"   🔄 진행상황: {frame_count}/{total_frames} ({progress_percent:.1f}%)\")\n",
        "\n",
        "    # ========== Cleanup and Finalize ==========\n",
        "    cap.release()   # Close input video file\n",
        "    out.release()   # Close output video file and finalize writing\n",
        "\n",
        "    print(f\"✅ 결합 결과 영상 저장 완료: {output_path}\")\n",
        "    print(f\"📊 처리된 총 프레임: {frame_count}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: INDIVIDUAL MODEL INFERENCE RESULTS\n",
        "# ============================================================================\n",
        "print(\"\\n🔍 개별 모델 추론 결과 생성:\")\n",
        "print(\"   각 모델의 개별 성능을 확인하기 위해 따로따로 실행합니다\")\n",
        "\n",
        "# ========== Custom Model Only Inference ==========\n",
        "print(\"\\n1️⃣ 커스텀 모델 단독 실행 (차선, 교통표지판만 탐지):\")\n",
        "print(\"   이 모델은 특별히 차선과 교통표지판 탐지를 위해 학습되었습니다\")\n",
        "custom_results = custom_model(\n",
        "    video_path,                    # Input video path\n",
        "    save=True,                     # Save results automatically\n",
        "    project='/content',            # Project directory for saving\n",
        "    name='custom_only',            # Folder name for this run\n",
        "    conf=0.3                       # Minimum confidence threshold\n",
        ")\n",
        "\n",
        "# ========== Base Model Only Inference ==========\n",
        "print(\"\\n2️⃣ 기본 모델 단독 실행 (일반 객체들 탐지):\")\n",
        "print(\"   COCO 데이터셋으로 학습된 모델로 80개 클래스의 일반적인 객체를 탐지합니다\")\n",
        "base_results = base_model(\n",
        "    video_path,                    # Input video path\n",
        "    save=True,                     # Save results automatically\n",
        "    project='/content',            # Project directory for saving\n",
        "    name='base_only',              # Folder name for this run\n",
        "    conf=0.3                       # Minimum confidence threshold\n",
        ")\n",
        "\n",
        "# ========== Combined Model Inference ==========\n",
        "print(\"\\n3️⃣ 결합 모델 실행 (모든 객체 동시 탐지):\")\n",
        "print(\"   두 모델을 동시에 실행하여 모든 종류의 객체를 탐지합니다\")\n",
        "print(\"   파란색 박스: 기본 모델 결과, 빨간색 박스: 커스텀 모델 결과\")\n",
        "combined_inference(video_path, '/content/combined_result.mp4')\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: ORGANIZE RESULT FILES\n",
        "# ============================================================================\n",
        "print(\"\\n📁 결과 파일 정리 중...\")\n",
        "print(\"   생성된 결과 파일들을 표준 이름으로 복사하여 쉽게 접근할 수 있도록 합니다\")\n",
        "\n",
        "# Define mapping of standard names to actual generated file paths\n",
        "result_files = {\n",
        "    'custom_result.mp4': glob.glob('/content/custom_only/*.avi') + glob.glob('/content/custom_only/*.mp4'),\n",
        "    'base_result.mp4': glob.glob('/content/base_only/*.avi') + glob.glob('/content/base_only/*.mp4'),\n",
        "    'final_combined_result.mp4': ['/content/combined_result.mp4']\n",
        "}\n",
        "\n",
        "print(\"\\n📋 결과 파일들:\")\n",
        "for standard_name, file_list in result_files.items():\n",
        "    if file_list and file_list[0]:  # Check if files exist\n",
        "        try:\n",
        "            # Copy the first found file to a standard name\n",
        "            shutil.copy(file_list[0], f'/content/{standard_name}')\n",
        "            print(f\"✅ {standard_name} 생성 완료 (원본: {file_list[0]})\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ {standard_name} 생성 실패: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠️ {standard_name} 해당 파일을 찾을 수 없습니다\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: MODEL PERFORMANCE EVALUATION\n",
        "# ============================================================================\n",
        "print(\"\\n📊 커스텀 모델 성능 평가:\")\n",
        "print(\"   Validation 데이터셋을 사용하여 모델의 정확도를 측정합니다\")\n",
        "print(\"   mAP50은 IoU 0.5에서의 평균 정밀도로, 높을수록 좋은 성능을 의미합니다\")\n",
        "\n",
        "try:\n",
        "    # Evaluate custom model performance on validation dataset\n",
        "    metrics = custom_model.val(data='/content/dataset/dataset_fixed.yaml')\n",
        "    print(f\"🎯 mAP50 (Mean Average Precision): {metrics.box.map50:.4f}\")\n",
        "    print(f\"   해석: {metrics.box.map50:.1%} 정확도로 객체를 탐지합니다\")\n",
        "\n",
        "    # Additional metrics if available\n",
        "    if hasattr(metrics.box, 'map'):\n",
        "        print(f\"🎯 mAP50-95 (전체 IoU 범위): {metrics.box.map:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 모델 평가 중 오류 발생: {e}\")\n",
        "    print(\"   데이터셋 파일이 없거나 경로가 잘못되었을 수 있습니다\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 8: DISPLAY FINAL RESULTS\n",
        "# ============================================================================\n",
        "print(\"\\n🎬 최종 결합 결과 영상:\")\n",
        "print(\"   모든 객체가 탐지된 최종 결과를 확인하세요\")\n",
        "\n",
        "try:\n",
        "    # Display the final combined result video\n",
        "    Video('/content/final_combined_result.mp4', width=800)\n",
        "except Exception as e:\n",
        "    print(f\"❌ 비디오 표시 오류: {e}\")\n",
        "    print(\"   파일이 생성되었지만 표시할 수 없습니다. 파일을 직접 다운로드하세요.\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 9: RESULTS SUMMARY AND INTERPRETATION GUIDE\n",
        "# ============================================================================\n",
        "print(\"\\n🎯 결과 요약 및 해석 가이드:\")\n",
        "print(\"=\"*60)\n",
        "print(\"📋 탐지 결과 색상 구분:\")\n",
        "print(\"🔵 파란색 박스: 기본 YOLO 모델 결과\")\n",
        "print(\"   └── 탐지 가능: 사람, 자동차, 트럭, 버스, 오토바이, 자전거, 신호등, 정지표지판 등\")\n",
        "print(\"   └── 총 80개 클래스의 일반적인 객체들\")\n",
        "print(\"🔴 빨간색 박스: 커스텀 YOLO 모델 결과\")\n",
        "print(\"   └── 탐지 가능: 차선(lane), 교통표지판(traffic_sign)\")\n",
        "print(\"   └── 도로 환경 특화 객체들\")\n",
        "\n",
        "print(\"\\n📊 성능 특징:\")\n",
        "print(\"• 기본 모델: 넓은 범위의 객체 탐지, 일반적인 상황에 강함\")\n",
        "print(\"• 커스텀 모델: 특정 도메인 특화, 차선/표지판 탐지에 높은 정확도\")\n",
        "print(\"• 결합 모델: 두 모델의 장점을 모두 활용, 포괄적인 객체 탐지\")\n",
        "\n",
        "print(\"\\n💾 다운로드 가능한 결과 파일들:\")\n",
        "print(\"📁 /content/ 폴더에 저장된 파일들:\")\n",
        "print(\"├── custom_result.mp4        : 커스텀 모델만의 탐지 결과\")\n",
        "print(\"├── base_result.mp4          : 기본 모델만의 탐지 결과\")\n",
        "print(\"├── final_combined_result.mp4: 두 모델 결합 최종 결과\")\n",
        "print(\"└── 원본 업로드 파일도 함께 보관됨\")\n",
        "\n",
        "print(\"\\n🚀 사용 권장사항:\")\n",
        "print(\"• 일반적인 객체 탐지: base_result.mp4 사용\")\n",
        "print(\"• 도로/교통 환경 분석: custom_result.mp4 사용\")\n",
        "print(\"• 종합적인 분석: final_combined_result.mp4 사용\")\n",
        "\n",
        "print(\"\\n✨ 처리 완료! 결과 파일들을 다운로드하여 확인하세요.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zO8V1XsmfpMW",
        "outputId": "85ca55e5-9b80-42a4-fbd1-b3244e838e61"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.170)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.7.21)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "🤖 모델 로드 중...\n",
            "   - 기본 YOLO 모델: 일반적인 80개 클래스 객체 탐지 (사람, 차량, 신호등 등)\n",
            "   - 커스텀 YOLO 모델: 특별히 학습된 2개 클래스 탐지 (차선, 교통표지판)\n",
            "📋 기본 모델 클래스 수: 80 (COCO 데이터셋 기반)\n",
            "📋 커스텀 모델 클래스 수: 2 (차선, 교통표지판 전용)\n",
            "   🔍 기본 모델 클래스 예시: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light']...\n",
            "   🔍 커스텀 모델 클래스: ['lane', 'traffic_sign']\n",
            "\n",
            "📥 비디오 파일 업로드\n",
            "   PC에서 비디오 파일을 선택하여 업로드하세요\n",
            "   지원 형식: MP4, AVI, MOV, MKV 등 대부분의 비디오 형식\n",
            "\n",
            "🎬 업로드할 비디오 파일을 선택하세요:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bac84c5b-891d-4b2d-bc5a-3852d13cd0ec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bac84c5b-891d-4b2d-bc5a-3852d13cd0ec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving KakaoTalk_20250717_091729282.mp4 to KakaoTalk_20250717_091729282 (4).mp4\n",
            "\n",
            "✅ 1 개의 파일이 업로드되었습니다\n",
            "📹 처리할 비디오: KakaoTalk_20250717_091729282 (4).mp4\n",
            "📁 파일 크기: 3.3 MB\n",
            "\n",
            "🔍 개별 모델 추론 결과 생성:\n",
            "   각 모델의 개별 성능을 확인하기 위해 따로따로 실행합니다\n",
            "\n",
            "1️⃣ 커스텀 모델 단독 실행 (차선, 교통표지판만 탐지):\n",
            "   이 모델은 특별히 차선과 교통표지판 탐지를 위해 학습되었습니다\n",
            "\n",
            "WARNING ⚠️ \n",
            "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (frame 1/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 traffic_sign, 104.1ms\n",
            "video 1/1 (frame 2/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 traffic_sign, 103.6ms\n",
            "video 1/1 (frame 3/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 traffic_sign, 105.4ms\n",
            "video 1/1 (frame 4/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 traffic_signs, 119.9ms\n",
            "video 1/1 (frame 5/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 traffic_sign, 102.7ms\n",
            "video 1/1 (frame 6/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 traffic_sign, 102.9ms\n",
            "video 1/1 (frame 7/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 105.6ms\n",
            "video 1/1 (frame 8/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 traffic_sign, 103.2ms\n",
            "video 1/1 (frame 9/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 104.4ms\n",
            "video 1/1 (frame 10/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 110.3ms\n",
            "video 1/1 (frame 11/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 106.2ms\n",
            "video 1/1 (frame 12/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 115.4ms\n",
            "video 1/1 (frame 13/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 101.0ms\n",
            "video 1/1 (frame 14/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 114.7ms\n",
            "video 1/1 (frame 15/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 105.1ms\n",
            "video 1/1 (frame 16/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 104.0ms\n",
            "video 1/1 (frame 17/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 101.9ms\n",
            "video 1/1 (frame 18/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 105.3ms\n",
            "video 1/1 (frame 19/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 117.8ms\n",
            "video 1/1 (frame 20/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 2 traffic_signs, 102.1ms\n",
            "video 1/1 (frame 21/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 2 traffic_signs, 102.4ms\n",
            "video 1/1 (frame 22/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 2 traffic_signs, 102.6ms\n",
            "video 1/1 (frame 23/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 2 traffic_signs, 104.6ms\n",
            "video 1/1 (frame 24/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 2 traffic_signs, 99.4ms\n",
            "video 1/1 (frame 25/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 2 traffic_signs, 101.2ms\n",
            "video 1/1 (frame 26/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 2 traffic_signs, 104.3ms\n",
            "video 1/1 (frame 27/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 118.2ms\n",
            "video 1/1 (frame 28/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 traffic_sign, 101.3ms\n",
            "video 1/1 (frame 29/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 104.9ms\n",
            "video 1/1 (frame 30/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 100.9ms\n",
            "video 1/1 (frame 31/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 107.4ms\n",
            "video 1/1 (frame 32/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 2 traffic_signs, 102.5ms\n",
            "video 1/1 (frame 33/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 107.9ms\n",
            "video 1/1 (frame 34/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 2 traffic_signs, 101.9ms\n",
            "video 1/1 (frame 35/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 117.8ms\n",
            "video 1/1 (frame 36/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 105.9ms\n",
            "video 1/1 (frame 37/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 116.9ms\n",
            "video 1/1 (frame 38/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 158.1ms\n",
            "video 1/1 (frame 39/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 163.5ms\n",
            "video 1/1 (frame 40/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 157.1ms\n",
            "video 1/1 (frame 41/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 168.3ms\n",
            "video 1/1 (frame 42/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 162.3ms\n",
            "video 1/1 (frame 43/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 153.8ms\n",
            "video 1/1 (frame 44/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 154.1ms\n",
            "video 1/1 (frame 45/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 163.2ms\n",
            "video 1/1 (frame 46/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 169.9ms\n",
            "video 1/1 (frame 47/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 160.9ms\n",
            "video 1/1 (frame 48/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 156.5ms\n",
            "video 1/1 (frame 49/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 156.8ms\n",
            "video 1/1 (frame 50/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 165.4ms\n",
            "video 1/1 (frame 51/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 182.2ms\n",
            "video 1/1 (frame 52/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 181.7ms\n",
            "video 1/1 (frame 53/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 159.2ms\n",
            "video 1/1 (frame 54/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 166.1ms\n",
            "video 1/1 (frame 55/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 158.0ms\n",
            "video 1/1 (frame 56/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 175.2ms\n",
            "video 1/1 (frame 57/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 174.0ms\n",
            "video 1/1 (frame 58/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 161.1ms\n",
            "video 1/1 (frame 59/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 164.7ms\n",
            "video 1/1 (frame 60/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 147.8ms\n",
            "video 1/1 (frame 61/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 103.9ms\n",
            "video 1/1 (frame 62/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 108.2ms\n",
            "video 1/1 (frame 63/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 99.5ms\n",
            "video 1/1 (frame 64/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 121.1ms\n",
            "video 1/1 (frame 65/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 102.6ms\n",
            "video 1/1 (frame 66/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 104.7ms\n",
            "video 1/1 (frame 67/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 103.5ms\n",
            "video 1/1 (frame 68/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 103.0ms\n",
            "video 1/1 (frame 69/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 105.6ms\n",
            "video 1/1 (frame 70/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 110.2ms\n",
            "video 1/1 (frame 71/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 101.3ms\n",
            "video 1/1 (frame 72/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 109.7ms\n",
            "video 1/1 (frame 73/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 103.9ms\n",
            "video 1/1 (frame 74/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 104.1ms\n",
            "video 1/1 (frame 75/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 100.2ms\n",
            "video 1/1 (frame 76/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 (no detections), 104.9ms\n",
            "video 1/1 (frame 77/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 102.8ms\n",
            "video 1/1 (frame 78/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 108.2ms\n",
            "video 1/1 (frame 79/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 102.4ms\n",
            "video 1/1 (frame 80/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 101.6ms\n",
            "video 1/1 (frame 81/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 103.7ms\n",
            "video 1/1 (frame 82/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 103.2ms\n",
            "video 1/1 (frame 83/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 101.9ms\n",
            "video 1/1 (frame 84/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 lanes, 1 traffic_sign, 105.5ms\n",
            "video 1/1 (frame 85/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 1 traffic_sign, 105.2ms\n",
            "video 1/1 (frame 86/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 104.6ms\n",
            "video 1/1 (frame 87/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 115.3ms\n",
            "video 1/1 (frame 88/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 107.2ms\n",
            "video 1/1 (frame 89/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 107.1ms\n",
            "video 1/1 (frame 90/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 (no detections), 105.4ms\n",
            "video 1/1 (frame 91/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 102.1ms\n",
            "video 1/1 (frame 92/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 106.1ms\n",
            "video 1/1 (frame 93/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 103.1ms\n",
            "video 1/1 (frame 94/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 105.6ms\n",
            "video 1/1 (frame 95/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 117.8ms\n",
            "video 1/1 (frame 96/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 104.7ms\n",
            "video 1/1 (frame 97/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 101.3ms\n",
            "video 1/1 (frame 98/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 106.2ms\n",
            "video 1/1 (frame 99/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 1 traffic_sign, 105.4ms\n",
            "video 1/1 (frame 100/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 108.8ms\n",
            "video 1/1 (frame 101/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 101.9ms\n",
            "video 1/1 (frame 102/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 2 traffic_signs, 104.1ms\n",
            "video 1/1 (frame 103/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 2 traffic_signs, 117.5ms\n",
            "video 1/1 (frame 104/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 105.9ms\n",
            "video 1/1 (frame 105/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 101.4ms\n",
            "video 1/1 (frame 106/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 104.1ms\n",
            "video 1/1 (frame 107/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 105.8ms\n",
            "video 1/1 (frame 108/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 108.0ms\n",
            "video 1/1 (frame 109/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 101.6ms\n",
            "video 1/1 (frame 110/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 106.8ms\n",
            "video 1/1 (frame 111/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 107.0ms\n",
            "video 1/1 (frame 112/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 106.0ms\n",
            "video 1/1 (frame 113/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 101.3ms\n",
            "video 1/1 (frame 114/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 105.5ms\n",
            "video 1/1 (frame 115/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 103.7ms\n",
            "video 1/1 (frame 116/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 104.0ms\n",
            "video 1/1 (frame 117/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 101.4ms\n",
            "video 1/1 (frame 118/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 111.9ms\n",
            "video 1/1 (frame 119/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 105.5ms\n",
            "video 1/1 (frame 120/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 108.7ms\n",
            "video 1/1 (frame 121/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 101.0ms\n",
            "video 1/1 (frame 122/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 112.4ms\n",
            "video 1/1 (frame 123/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 103.6ms\n",
            "video 1/1 (frame 124/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 107.8ms\n",
            "video 1/1 (frame 125/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 105.6ms\n",
            "video 1/1 (frame 126/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 2 traffic_signs, 126.5ms\n",
            "video 1/1 (frame 127/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 109.5ms\n",
            "video 1/1 (frame 128/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 104.3ms\n",
            "video 1/1 (frame 129/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 106.8ms\n",
            "video 1/1 (frame 130/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 109.1ms\n",
            "video 1/1 (frame 131/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 99.4ms\n",
            "video 1/1 (frame 132/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 (no detections), 102.1ms\n",
            "video 1/1 (frame 133/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 112.7ms\n",
            "video 1/1 (frame 134/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 118.7ms\n",
            "video 1/1 (frame 135/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 163.5ms\n",
            "video 1/1 (frame 136/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 2 traffic_signs, 170.8ms\n",
            "video 1/1 (frame 137/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 156.6ms\n",
            "video 1/1 (frame 138/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 162.1ms\n",
            "video 1/1 (frame 139/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 179.0ms\n",
            "video 1/1 (frame 140/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 2 traffic_signs, 158.6ms\n",
            "video 1/1 (frame 141/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 2 traffic_signs, 164.5ms\n",
            "video 1/1 (frame 142/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 172.7ms\n",
            "video 1/1 (frame 143/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 168.2ms\n",
            "video 1/1 (frame 144/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 1 traffic_sign, 181.8ms\n",
            "video 1/1 (frame 145/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 1 traffic_sign, 160.6ms\n",
            "video 1/1 (frame 146/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 161.1ms\n",
            "video 1/1 (frame 147/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 158.1ms\n",
            "video 1/1 (frame 148/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 160.6ms\n",
            "video 1/1 (frame 149/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 174.6ms\n",
            "video 1/1 (frame 150/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 155.8ms\n",
            "video 1/1 (frame 151/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 171.6ms\n",
            "video 1/1 (frame 152/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 162.1ms\n",
            "video 1/1 (frame 153/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 163.3ms\n",
            "video 1/1 (frame 154/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 167.5ms\n",
            "video 1/1 (frame 155/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 171.7ms\n",
            "video 1/1 (frame 156/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 164.6ms\n",
            "video 1/1 (frame 157/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 107.5ms\n",
            "video 1/1 (frame 158/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 107.5ms\n",
            "video 1/1 (frame 159/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 106.1ms\n",
            "video 1/1 (frame 160/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 101.9ms\n",
            "video 1/1 (frame 161/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 119.6ms\n",
            "video 1/1 (frame 162/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 104.0ms\n",
            "video 1/1 (frame 163/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 104.9ms\n",
            "video 1/1 (frame 164/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 106.8ms\n",
            "video 1/1 (frame 165/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 2 traffic_signs, 106.0ms\n",
            "video 1/1 (frame 166/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 110.1ms\n",
            "video 1/1 (frame 167/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 105.9ms\n",
            "video 1/1 (frame 168/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 107.6ms\n",
            "video 1/1 (frame 169/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 123.6ms\n",
            "video 1/1 (frame 170/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 (no detections), 108.8ms\n",
            "video 1/1 (frame 171/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 100.2ms\n",
            "video 1/1 (frame 172/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 111.5ms\n",
            "video 1/1 (frame 173/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 101.8ms\n",
            "video 1/1 (frame 174/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 105.2ms\n",
            "video 1/1 (frame 175/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 (no detections), 105.0ms\n",
            "video 1/1 (frame 176/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 109.1ms\n",
            "video 1/1 (frame 177/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 114.6ms\n",
            "video 1/1 (frame 178/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 172.9ms\n",
            "video 1/1 (frame 179/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 198.0ms\n",
            "video 1/1 (frame 180/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 282.9ms\n",
            "video 1/1 (frame 181/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 227.1ms\n",
            "video 1/1 (frame 182/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 178.1ms\n",
            "video 1/1 (frame 183/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 196.5ms\n",
            "video 1/1 (frame 184/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 398.8ms\n",
            "video 1/1 (frame 185/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 255.3ms\n",
            "video 1/1 (frame 186/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 300.4ms\n",
            "video 1/1 (frame 187/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 193.2ms\n",
            "video 1/1 (frame 188/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 314.6ms\n",
            "video 1/1 (frame 189/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 135.7ms\n",
            "video 1/1 (frame 190/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 102.6ms\n",
            "video 1/1 (frame 191/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 103.8ms\n",
            "video 1/1 (frame 192/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 106.0ms\n",
            "video 1/1 (frame 193/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 120.8ms\n",
            "video 1/1 (frame 194/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 107.1ms\n",
            "video 1/1 (frame 195/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 111.6ms\n",
            "video 1/1 (frame 196/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 106.9ms\n",
            "video 1/1 (frame 197/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 101.3ms\n",
            "video 1/1 (frame 198/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 108.0ms\n",
            "video 1/1 (frame 199/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 102.2ms\n",
            "video 1/1 (frame 200/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 106.6ms\n",
            "video 1/1 (frame 201/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 117.2ms\n",
            "video 1/1 (frame 202/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 107.8ms\n",
            "video 1/1 (frame 203/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 102.1ms\n",
            "video 1/1 (frame 204/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 lanes, 107.0ms\n",
            "video 1/1 (frame 205/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 104.1ms\n",
            "video 1/1 (frame 206/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 108.8ms\n",
            "video 1/1 (frame 207/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 103.2ms\n",
            "video 1/1 (frame 208/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 115.7ms\n",
            "video 1/1 (frame 209/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 102.7ms\n",
            "video 1/1 (frame 210/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 108.3ms\n",
            "video 1/1 (frame 211/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 101.8ms\n",
            "video 1/1 (frame 212/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 109.0ms\n",
            "video 1/1 (frame 213/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 104.4ms\n",
            "video 1/1 (frame 214/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 107.4ms\n",
            "video 1/1 (frame 215/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 105.3ms\n",
            "video 1/1 (frame 216/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 190.7ms\n",
            "video 1/1 (frame 217/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 162.5ms\n",
            "video 1/1 (frame 218/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 lanes, 173.9ms\n",
            "video 1/1 (frame 219/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 1 traffic_sign, 156.6ms\n",
            "video 1/1 (frame 220/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 160.3ms\n",
            "video 1/1 (frame 221/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 165.2ms\n",
            "video 1/1 (frame 222/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 153.1ms\n",
            "video 1/1 (frame 223/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 lanes, 171.6ms\n",
            "video 1/1 (frame 224/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 1 traffic_sign, 172.5ms\n",
            "video 1/1 (frame 225/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 176.9ms\n",
            "video 1/1 (frame 226/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 168.6ms\n",
            "video 1/1 (frame 227/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 lanes, 1 traffic_sign, 152.8ms\n",
            "video 1/1 (frame 228/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 1 traffic_sign, 158.7ms\n",
            "video 1/1 (frame 229/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 1 traffic_sign, 156.7ms\n",
            "video 1/1 (frame 230/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 lanes, 1 traffic_sign, 157.2ms\n",
            "video 1/1 (frame 231/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 lanes, 1 traffic_sign, 157.8ms\n",
            "video 1/1 (frame 232/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 lanes, 1 traffic_sign, 172.7ms\n",
            "video 1/1 (frame 233/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 154.6ms\n",
            "video 1/1 (frame 234/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 168.6ms\n",
            "video 1/1 (frame 235/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 168.4ms\n",
            "video 1/1 (frame 236/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 179.6ms\n",
            "video 1/1 (frame 237/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 172.9ms\n",
            "video 1/1 (frame 238/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 111.5ms\n",
            "video 1/1 (frame 239/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 100.4ms\n",
            "video 1/1 (frame 240/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 106.9ms\n",
            "video 1/1 (frame 241/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 101.5ms\n",
            "video 1/1 (frame 242/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 104.6ms\n",
            "video 1/1 (frame 243/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 102.1ms\n",
            "video 1/1 (frame 244/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 123.0ms\n",
            "video 1/1 (frame 245/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 102.3ms\n",
            "video 1/1 (frame 246/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 109.8ms\n",
            "video 1/1 (frame 247/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 100.7ms\n",
            "video 1/1 (frame 248/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 111.0ms\n",
            "video 1/1 (frame 249/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 104.3ms\n",
            "video 1/1 (frame 250/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 106.0ms\n",
            "video 1/1 (frame 251/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 104.9ms\n",
            "video 1/1 (frame 252/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 106.5ms\n",
            "video 1/1 (frame 253/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 100.7ms\n",
            "video 1/1 (frame 254/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 110.0ms\n",
            "video 1/1 (frame 255/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 103.7ms\n",
            "video 1/1 (frame 256/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 109.1ms\n",
            "video 1/1 (frame 257/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 105.7ms\n",
            "video 1/1 (frame 258/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 108.8ms\n",
            "video 1/1 (frame 259/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 120.1ms\n",
            "video 1/1 (frame 260/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 110.8ms\n",
            "video 1/1 (frame 261/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 100.8ms\n",
            "video 1/1 (frame 262/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 105.1ms\n",
            "video 1/1 (frame 263/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 103.8ms\n",
            "video 1/1 (frame 264/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 107.4ms\n",
            "video 1/1 (frame 265/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 101.5ms\n",
            "video 1/1 (frame 266/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 108.4ms\n",
            "video 1/1 (frame 267/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 125.0ms\n",
            "video 1/1 (frame 268/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 107.7ms\n",
            "video 1/1 (frame 269/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 100.5ms\n",
            "video 1/1 (frame 270/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 104.2ms\n",
            "video 1/1 (frame 271/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 106.4ms\n",
            "video 1/1 (frame 272/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 103.0ms\n",
            "video 1/1 (frame 273/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 105.7ms\n",
            "video 1/1 (frame 274/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 118.3ms\n",
            "video 1/1 (frame 275/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 103.4ms\n",
            "video 1/1 (frame 276/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 106.4ms\n",
            "video 1/1 (frame 277/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 104.6ms\n",
            "video 1/1 (frame 278/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 105.7ms\n",
            "video 1/1 (frame 279/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 lanes, 103.1ms\n",
            "video 1/1 (frame 280/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 traffic_sign, 109.1ms\n",
            "video 1/1 (frame 281/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 99.5ms\n",
            "video 1/1 (frame 282/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 124.7ms\n",
            "video 1/1 (frame 283/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 104.5ms\n",
            "video 1/1 (frame 284/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 121.1ms\n",
            "video 1/1 (frame 285/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 101.3ms\n",
            "video 1/1 (frame 286/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 108.3ms\n",
            "video 1/1 (frame 287/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 99.7ms\n",
            "video 1/1 (frame 288/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 109.7ms\n",
            "video 1/1 (frame 289/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 103.3ms\n",
            "video 1/1 (frame 290/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 126.0ms\n",
            "video 1/1 (frame 291/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 103.8ms\n",
            "video 1/1 (frame 292/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 105.4ms\n",
            "video 1/1 (frame 293/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 111.1ms\n",
            "video 1/1 (frame 294/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 104.3ms\n",
            "video 1/1 (frame 295/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 101.6ms\n",
            "video 1/1 (frame 296/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 109.7ms\n",
            "video 1/1 (frame 297/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 114.5ms\n",
            "video 1/1 (frame 298/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 1 traffic_sign, 109.0ms\n",
            "video 1/1 (frame 299/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 1 traffic_sign, 102.4ms\n",
            "video 1/1 (frame 300/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 105.2ms\n",
            "video 1/1 (frame 301/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 1 traffic_sign, 100.7ms\n",
            "video 1/1 (frame 302/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 105.2ms\n",
            "video 1/1 (frame 303/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 1 traffic_sign, 110.8ms\n",
            "video 1/1 (frame 304/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 111.3ms\n",
            "video 1/1 (frame 305/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 121.1ms\n",
            "video 1/1 (frame 306/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 lanes, 110.1ms\n",
            "video 1/1 (frame 307/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 1 traffic_sign, 107.2ms\n",
            "video 1/1 (frame 308/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 114.1ms\n",
            "video 1/1 (frame 309/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 104.0ms\n",
            "video 1/1 (frame 310/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 lanes, 110.4ms\n",
            "video 1/1 (frame 311/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 lanes, 178.4ms\n",
            "video 1/1 (frame 312/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 lanes, 175.6ms\n",
            "video 1/1 (frame 313/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 lane, 166.8ms\n",
            "Speed: 3.3ms preprocess, 125.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
            "Results saved to \u001b[1m/content/custom_only\u001b[0m\n",
            "\n",
            "2️⃣ 기본 모델 단독 실행 (일반 객체들 탐지):\n",
            "   COCO 데이터셋으로 학습된 모델로 80개 클래스의 일반적인 객체를 탐지합니다\n",
            "\n",
            "WARNING ⚠️ \n",
            "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (frame 1/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 157.4ms\n",
            "video 1/1 (frame 2/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 154.8ms\n",
            "video 1/1 (frame 3/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 156.5ms\n",
            "video 1/1 (frame 4/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 150.7ms\n",
            "video 1/1 (frame 5/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 159.3ms\n",
            "video 1/1 (frame 6/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 person, 4 cars, 168.3ms\n",
            "video 1/1 (frame 7/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 149.1ms\n",
            "video 1/1 (frame 8/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 147.9ms\n",
            "video 1/1 (frame 9/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 179.3ms\n",
            "video 1/1 (frame 10/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 152.5ms\n",
            "video 1/1 (frame 11/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 149.3ms\n",
            "video 1/1 (frame 12/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 148.3ms\n",
            "video 1/1 (frame 13/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 153.9ms\n",
            "video 1/1 (frame 14/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 172.9ms\n",
            "video 1/1 (frame 15/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 153.7ms\n",
            "video 1/1 (frame 16/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 178.2ms\n",
            "video 1/1 (frame 17/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 161.6ms\n",
            "video 1/1 (frame 18/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 161.4ms\n",
            "video 1/1 (frame 19/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 172.1ms\n",
            "video 1/1 (frame 20/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 137.4ms\n",
            "video 1/1 (frame 21/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 99.0ms\n",
            "video 1/1 (frame 22/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.1ms\n",
            "video 1/1 (frame 23/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 97.2ms\n",
            "video 1/1 (frame 24/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.3ms\n",
            "video 1/1 (frame 25/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 person, 4 cars, 101.1ms\n",
            "video 1/1 (frame 26/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.6ms\n",
            "video 1/1 (frame 27/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 truck, 1 traffic light, 114.9ms\n",
            "video 1/1 (frame 28/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 99.3ms\n",
            "video 1/1 (frame 29/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.0ms\n",
            "video 1/1 (frame 30/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 100.7ms\n",
            "video 1/1 (frame 31/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 99.7ms\n",
            "video 1/1 (frame 32/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 103.7ms\n",
            "video 1/1 (frame 33/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 108.9ms\n",
            "video 1/1 (frame 34/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 100.4ms\n",
            "video 1/1 (frame 35/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 99.6ms\n",
            "video 1/1 (frame 36/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 100.6ms\n",
            "video 1/1 (frame 37/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 100.4ms\n",
            "video 1/1 (frame 38/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 107.8ms\n",
            "video 1/1 (frame 39/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 98.3ms\n",
            "video 1/1 (frame 40/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 102.9ms\n",
            "video 1/1 (frame 41/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 102.4ms\n",
            "video 1/1 (frame 42/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 118.8ms\n",
            "video 1/1 (frame 43/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 98.6ms\n",
            "video 1/1 (frame 44/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 102.6ms\n",
            "video 1/1 (frame 45/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 98.2ms\n",
            "video 1/1 (frame 46/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.7ms\n",
            "video 1/1 (frame 47/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 98.4ms\n",
            "video 1/1 (frame 48/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 100.5ms\n",
            "video 1/1 (frame 49/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 100.6ms\n",
            "video 1/1 (frame 50/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 119.2ms\n",
            "video 1/1 (frame 51/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 101.3ms\n",
            "video 1/1 (frame 52/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 100.9ms\n",
            "video 1/1 (frame 53/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 99.4ms\n",
            "video 1/1 (frame 54/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 96.8ms\n",
            "video 1/1 (frame 55/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 108.3ms\n",
            "video 1/1 (frame 56/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 105.0ms\n",
            "video 1/1 (frame 57/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 100.0ms\n",
            "video 1/1 (frame 58/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 115.4ms\n",
            "video 1/1 (frame 59/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 99.7ms\n",
            "video 1/1 (frame 60/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 110.5ms\n",
            "video 1/1 (frame 61/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 102.1ms\n",
            "video 1/1 (frame 62/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.2ms\n",
            "video 1/1 (frame 63/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 103.4ms\n",
            "video 1/1 (frame 64/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.2ms\n",
            "video 1/1 (frame 65/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 114.6ms\n",
            "video 1/1 (frame 66/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.5ms\n",
            "video 1/1 (frame 67/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 98.6ms\n",
            "video 1/1 (frame 68/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 cars, 102.7ms\n",
            "video 1/1 (frame 69/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 98.7ms\n",
            "video 1/1 (frame 70/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 stop sign, 105.5ms\n",
            "video 1/1 (frame 71/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 99.0ms\n",
            "video 1/1 (frame 72/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 97.5ms\n",
            "video 1/1 (frame 73/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 traffic light, 119.7ms\n",
            "video 1/1 (frame 74/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 cars, 99.7ms\n",
            "video 1/1 (frame 75/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 100.7ms\n",
            "video 1/1 (frame 76/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 traffic light, 99.0ms\n",
            "video 1/1 (frame 77/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 100.1ms\n",
            "video 1/1 (frame 78/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 106.4ms\n",
            "video 1/1 (frame 79/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 traffic light, 104.8ms\n",
            "video 1/1 (frame 80/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 traffic light, 98.8ms\n",
            "video 1/1 (frame 81/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 118.0ms\n",
            "video 1/1 (frame 82/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 98.5ms\n",
            "video 1/1 (frame 83/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 101.1ms\n",
            "video 1/1 (frame 84/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 97.1ms\n",
            "video 1/1 (frame 85/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 103.4ms\n",
            "video 1/1 (frame 86/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 101.7ms\n",
            "video 1/1 (frame 87/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 97.9ms\n",
            "video 1/1 (frame 88/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 100.1ms\n",
            "video 1/1 (frame 89/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 121.2ms\n",
            "video 1/1 (frame 90/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 98.2ms\n",
            "video 1/1 (frame 91/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 99.6ms\n",
            "video 1/1 (frame 92/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 133.2ms\n",
            "video 1/1 (frame 93/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 279.1ms\n",
            "video 1/1 (frame 94/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 258.0ms\n",
            "video 1/1 (frame 95/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 163.5ms\n",
            "video 1/1 (frame 96/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 154.2ms\n",
            "video 1/1 (frame 97/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 151.8ms\n",
            "video 1/1 (frame 98/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 stop sign, 158.0ms\n",
            "video 1/1 (frame 99/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 stop sign, 164.9ms\n",
            "video 1/1 (frame 100/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 154.6ms\n",
            "video 1/1 (frame 101/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 184.8ms\n",
            "video 1/1 (frame 102/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 163.5ms\n",
            "video 1/1 (frame 103/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 traffic light, 153.2ms\n",
            "video 1/1 (frame 104/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 158.8ms\n",
            "video 1/1 (frame 105/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 159.9ms\n",
            "video 1/1 (frame 106/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 152.6ms\n",
            "video 1/1 (frame 107/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 161.8ms\n",
            "video 1/1 (frame 108/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 162.9ms\n",
            "video 1/1 (frame 109/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 146.9ms\n",
            "video 1/1 (frame 110/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 169.9ms\n",
            "video 1/1 (frame 111/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 152.2ms\n",
            "video 1/1 (frame 112/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 166.5ms\n",
            "video 1/1 (frame 113/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 156.8ms\n",
            "video 1/1 (frame 114/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 159.5ms\n",
            "video 1/1 (frame 115/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 171.0ms\n",
            "video 1/1 (frame 116/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 131.1ms\n",
            "video 1/1 (frame 117/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 motorcycle, 1 traffic light, 102.3ms\n",
            "video 1/1 (frame 118/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 traffic light, 102.8ms\n",
            "video 1/1 (frame 119/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 car, 105.4ms\n",
            "video 1/1 (frame 120/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 105.5ms\n",
            "video 1/1 (frame 121/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 truck, 101.2ms\n",
            "video 1/1 (frame 122/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 136.1ms\n",
            "video 1/1 (frame 123/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 traffic light, 108.8ms\n",
            "video 1/1 (frame 124/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 traffic light, 111.3ms\n",
            "video 1/1 (frame 125/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 traffic light, 105.4ms\n",
            "video 1/1 (frame 126/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 truck, 1 traffic light, 97.6ms\n",
            "video 1/1 (frame 127/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 traffic light, 105.0ms\n",
            "video 1/1 (frame 128/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 traffic light, 101.5ms\n",
            "video 1/1 (frame 129/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 126.0ms\n",
            "video 1/1 (frame 130/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 99.5ms\n",
            "video 1/1 (frame 131/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.3ms\n",
            "video 1/1 (frame 132/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 104.5ms\n",
            "video 1/1 (frame 133/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 traffic light, 107.4ms\n",
            "video 1/1 (frame 134/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 104.5ms\n",
            "video 1/1 (frame 135/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 truck, 100.8ms\n",
            "video 1/1 (frame 136/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 truck, 109.7ms\n",
            "video 1/1 (frame 137/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 120.4ms\n",
            "video 1/1 (frame 138/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 truck, 98.8ms\n",
            "video 1/1 (frame 139/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 motorcycle, 1 truck, 111.0ms\n",
            "video 1/1 (frame 140/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 98.5ms\n",
            "video 1/1 (frame 141/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 2 trucks, 1 traffic light, 99.9ms\n",
            "video 1/1 (frame 142/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 2 trucks, 97.0ms\n",
            "video 1/1 (frame 143/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 2 trucks, 103.4ms\n",
            "video 1/1 (frame 144/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 117.8ms\n",
            "video 1/1 (frame 145/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 100.9ms\n",
            "video 1/1 (frame 146/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 101.2ms\n",
            "video 1/1 (frame 147/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 103.1ms\n",
            "video 1/1 (frame 148/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 97.3ms\n",
            "video 1/1 (frame 149/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 99.5ms\n",
            "video 1/1 (frame 150/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 100.6ms\n",
            "video 1/1 (frame 151/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 99.3ms\n",
            "video 1/1 (frame 152/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 traffic light, 116.2ms\n",
            "video 1/1 (frame 153/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 100.9ms\n",
            "video 1/1 (frame 154/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 motorcycle, 98.1ms\n",
            "video 1/1 (frame 155/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 motorcycle, 101.1ms\n",
            "video 1/1 (frame 156/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 motorcycle, 97.6ms\n",
            "video 1/1 (frame 157/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 car, 1 motorcycle, 2 trucks, 106.7ms\n",
            "video 1/1 (frame 158/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 motorcycle, 103.6ms\n",
            "video 1/1 (frame 159/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 motorcycle, 121.9ms\n",
            "video 1/1 (frame 160/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 3 trucks, 108.4ms\n",
            "video 1/1 (frame 161/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 cars, 103.3ms\n",
            "video 1/1 (frame 162/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 100.0ms\n",
            "video 1/1 (frame 163/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 98.2ms\n",
            "video 1/1 (frame 164/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 101.0ms\n",
            "video 1/1 (frame 165/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 truck, 111.5ms\n",
            "video 1/1 (frame 166/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 truck, 99.7ms\n",
            "video 1/1 (frame 167/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 traffic light, 109.2ms\n",
            "video 1/1 (frame 168/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 1 truck, 99.5ms\n",
            "video 1/1 (frame 169/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 bus, 99.8ms\n",
            "video 1/1 (frame 170/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 98.7ms\n",
            "video 1/1 (frame 171/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 103.7ms\n",
            "video 1/1 (frame 172/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 1 truck, 106.4ms\n",
            "video 1/1 (frame 173/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 104.3ms\n",
            "video 1/1 (frame 174/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 119.2ms\n",
            "video 1/1 (frame 175/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 101.9ms\n",
            "video 1/1 (frame 176/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 99.2ms\n",
            "video 1/1 (frame 177/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 98.2ms\n",
            "video 1/1 (frame 178/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 98.2ms\n",
            "video 1/1 (frame 179/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 103.5ms\n",
            "video 1/1 (frame 180/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 2 trucks, 98.5ms\n",
            "video 1/1 (frame 181/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 bus, 3 trucks, 100.0ms\n",
            "video 1/1 (frame 182/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 bus, 1 truck, 120.3ms\n",
            "video 1/1 (frame 183/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 101.2ms\n",
            "video 1/1 (frame 184/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 1 truck, 96.4ms\n",
            "video 1/1 (frame 185/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 1 truck, 98.0ms\n",
            "video 1/1 (frame 186/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 107.5ms\n",
            "video 1/1 (frame 187/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 101.2ms\n",
            "video 1/1 (frame 188/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 bus, 1 truck, 154.0ms\n",
            "video 1/1 (frame 189/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 184.6ms\n",
            "video 1/1 (frame 190/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 154.1ms\n",
            "video 1/1 (frame 191/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 161.4ms\n",
            "video 1/1 (frame 192/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 bus, 1 traffic light, 159.3ms\n",
            "video 1/1 (frame 193/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 149.3ms\n",
            "video 1/1 (frame 194/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 2 trucks, 156.7ms\n",
            "video 1/1 (frame 195/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 150.7ms\n",
            "video 1/1 (frame 196/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 160.9ms\n",
            "video 1/1 (frame 197/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 2 trucks, 162.4ms\n",
            "video 1/1 (frame 198/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 153.1ms\n",
            "video 1/1 (frame 199/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 151.7ms\n",
            "video 1/1 (frame 200/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 154.2ms\n",
            "video 1/1 (frame 201/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 160.9ms\n",
            "video 1/1 (frame 202/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 2 trucks, 157.3ms\n",
            "video 1/1 (frame 203/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 bus, 144.9ms\n",
            "video 1/1 (frame 204/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 160.3ms\n",
            "video 1/1 (frame 205/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 169.4ms\n",
            "video 1/1 (frame 206/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 150.8ms\n",
            "video 1/1 (frame 207/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 1 truck, 164.5ms\n",
            "video 1/1 (frame 208/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 155.4ms\n",
            "video 1/1 (frame 209/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 168.4ms\n",
            "video 1/1 (frame 210/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 cars, 157.0ms\n",
            "video 1/1 (frame 211/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 132.0ms\n",
            "video 1/1 (frame 212/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 motorcycle, 107.5ms\n",
            "video 1/1 (frame 213/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 motorcycle, 98.2ms\n",
            "video 1/1 (frame 214/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 99.4ms\n",
            "video 1/1 (frame 215/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 104.6ms\n",
            "video 1/1 (frame 216/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 cars, 98.2ms\n",
            "video 1/1 (frame 217/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 car, 99.7ms\n",
            "video 1/1 (frame 218/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 114.4ms\n",
            "video 1/1 (frame 219/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 100.5ms\n",
            "video 1/1 (frame 220/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 bus, 4 trucks, 105.6ms\n",
            "video 1/1 (frame 221/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 103.4ms\n",
            "video 1/1 (frame 222/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 2 buss, 1 truck, 103.1ms\n",
            "video 1/1 (frame 223/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 106.3ms\n",
            "video 1/1 (frame 224/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 1 car, 1 bus, 4 trucks, 100.7ms\n",
            "video 1/1 (frame 225/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 3 trucks, 97.8ms\n",
            "video 1/1 (frame 226/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 3 trucks, 1 stop sign, 117.6ms\n",
            "video 1/1 (frame 227/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 bus, 2 trucks, 103.9ms\n",
            "video 1/1 (frame 228/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 4 trucks, 99.5ms\n",
            "video 1/1 (frame 229/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 4 trucks, 99.4ms\n",
            "video 1/1 (frame 230/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 bus, 2 trucks, 106.8ms\n",
            "video 1/1 (frame 231/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 2 trucks, 107.0ms\n",
            "video 1/1 (frame 232/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 1 truck, 1 traffic light, 104.7ms\n",
            "video 1/1 (frame 233/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 bus, 1 truck, 98.4ms\n",
            "video 1/1 (frame 234/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 1 truck, 103.8ms\n",
            "video 1/1 (frame 235/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 99.8ms\n",
            "video 1/1 (frame 236/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 98.7ms\n",
            "video 1/1 (frame 237/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 truck, 105.4ms\n",
            "video 1/1 (frame 238/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 108.8ms\n",
            "video 1/1 (frame 239/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 9 cars, 1 bus, 1 truck, 215.7ms\n",
            "video 1/1 (frame 240/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 bus, 1 truck, 120.0ms\n",
            "video 1/1 (frame 241/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 bus, 1 truck, 101.7ms\n",
            "video 1/1 (frame 242/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 98.8ms\n",
            "video 1/1 (frame 243/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 truck, 104.5ms\n",
            "video 1/1 (frame 244/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 truck, 214.5ms\n",
            "video 1/1 (frame 245/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 truck, 98.2ms\n",
            "video 1/1 (frame 246/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 104.5ms\n",
            "video 1/1 (frame 247/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 4 trucks, 124.8ms\n",
            "video 1/1 (frame 248/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 103.7ms\n",
            "video 1/1 (frame 249/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 104.1ms\n",
            "video 1/1 (frame 250/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 99.3ms\n",
            "video 1/1 (frame 251/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 102.2ms\n",
            "video 1/1 (frame 252/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 99.5ms\n",
            "video 1/1 (frame 253/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 2 trucks, 101.7ms\n",
            "video 1/1 (frame 254/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 truck, 107.2ms\n",
            "video 1/1 (frame 255/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 cars, 3 trucks, 107.1ms\n",
            "video 1/1 (frame 256/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 98.1ms\n",
            "video 1/1 (frame 257/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 1 truck, 106.2ms\n",
            "video 1/1 (frame 258/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 108.0ms\n",
            "video 1/1 (frame 259/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 104.3ms\n",
            "video 1/1 (frame 260/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 2 trucks, 107.6ms\n",
            "video 1/1 (frame 261/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 cars, 2 trucks, 109.5ms\n",
            "video 1/1 (frame 262/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 2 trucks, 121.8ms\n",
            "video 1/1 (frame 263/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 2 cars, 1 truck, 100.8ms\n",
            "video 1/1 (frame 264/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 truck, 104.8ms\n",
            "video 1/1 (frame 265/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 2 trucks, 102.9ms\n",
            "video 1/1 (frame 266/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 8 cars, 3 trucks, 101.0ms\n",
            "video 1/1 (frame 267/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 2 trucks, 99.5ms\n",
            "video 1/1 (frame 268/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 8 cars, 1 truck, 101.3ms\n",
            "video 1/1 (frame 269/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 truck, 99.3ms\n",
            "video 1/1 (frame 270/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 truck, 119.7ms\n",
            "video 1/1 (frame 271/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 truck, 106.2ms\n",
            "video 1/1 (frame 272/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 bus, 1 truck, 100.8ms\n",
            "video 1/1 (frame 273/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 bus, 104.0ms\n",
            "video 1/1 (frame 274/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 truck, 97.4ms\n",
            "video 1/1 (frame 275/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 2 trucks, 97.2ms\n",
            "video 1/1 (frame 276/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 104.5ms\n",
            "video 1/1 (frame 277/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 truck, 98.2ms\n",
            "video 1/1 (frame 278/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 2 trucks, 102.9ms\n",
            "video 1/1 (frame 279/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 2 trucks, 101.4ms\n",
            "video 1/1 (frame 280/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 3 cars, 1 truck, 100.5ms\n",
            "video 1/1 (frame 281/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 8 cars, 103.3ms\n",
            "video 1/1 (frame 282/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 8 cars, 98.3ms\n",
            "video 1/1 (frame 283/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 153.6ms\n",
            "video 1/1 (frame 284/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 truck, 162.1ms\n",
            "video 1/1 (frame 285/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 160.1ms\n",
            "video 1/1 (frame 286/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 truck, 149.9ms\n",
            "video 1/1 (frame 287/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 8 cars, 146.8ms\n",
            "video 1/1 (frame 288/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 truck, 153.2ms\n",
            "video 1/1 (frame 289/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 150.6ms\n",
            "video 1/1 (frame 290/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 truck, 171.4ms\n",
            "video 1/1 (frame 291/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 truck, 164.9ms\n",
            "video 1/1 (frame 292/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 158.4ms\n",
            "video 1/1 (frame 293/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 151.7ms\n",
            "video 1/1 (frame 294/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 traffic light, 151.6ms\n",
            "video 1/1 (frame 295/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 traffic light, 168.7ms\n",
            "video 1/1 (frame 296/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 160.9ms\n",
            "video 1/1 (frame 297/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 146.9ms\n",
            "video 1/1 (frame 298/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 9 cars, 149.5ms\n",
            "video 1/1 (frame 299/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 10 cars, 149.3ms\n",
            "video 1/1 (frame 300/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 8 cars, 162.0ms\n",
            "video 1/1 (frame 301/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 171.4ms\n",
            "video 1/1 (frame 302/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 4 cars, 1 truck, 158.0ms\n",
            "video 1/1 (frame 303/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 8 cars, 164.5ms\n",
            "video 1/1 (frame 304/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 9 cars, 1 truck, 154.1ms\n",
            "video 1/1 (frame 305/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 4 trucks, 153.4ms\n",
            "video 1/1 (frame 306/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 5 cars, 2 trucks, 113.4ms\n",
            "video 1/1 (frame 307/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 bus, 101.9ms\n",
            "video 1/1 (frame 308/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 99.8ms\n",
            "video 1/1 (frame 309/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 6 cars, 1 bus, 99.6ms\n",
            "video 1/1 (frame 310/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 1 bus, 97.5ms\n",
            "video 1/1 (frame 311/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 102.4ms\n",
            "video 1/1 (frame 312/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 102.6ms\n",
            "video 1/1 (frame 313/313) /content/KakaoTalk_20250717_091729282 (4).mp4: 288x640 7 cars, 102.3ms\n",
            "Speed: 3.5ms preprocess, 121.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "Results saved to \u001b[1m/content/base_only\u001b[0m\n",
            "\n",
            "3️⃣ 결합 모델 실행 (모든 객체 동시 탐지):\n",
            "   두 모델을 동시에 실행하여 모든 종류의 객체를 탐지합니다\n",
            "   파란색 박스: 기본 모델 결과, 빨간색 박스: 커스텀 모델 결과\n",
            "\n",
            "🎬 결합된 추론 시작: KakaoTalk_20250717_091729282 (4).mp4\n",
            "   두 개의 YOLO 모델을 동시에 실행하여 모든 객체를 탐지합니다\n",
            "   📹 비디오 정보: 1600x720 해상도, 24 FPS, 313 총 프레임\n",
            "🔄 영상 처리 중... (총 313 프레임)\n",
            "   🔄 진행상황: 30/313 (9.6%)\n",
            "   🔄 진행상황: 60/313 (19.2%)\n",
            "   🔄 진행상황: 90/313 (28.8%)\n",
            "   🔄 진행상황: 120/313 (38.3%)\n",
            "   🔄 진행상황: 150/313 (47.9%)\n",
            "   🔄 진행상황: 180/313 (57.5%)\n",
            "   🔄 진행상황: 210/313 (67.1%)\n",
            "   🔄 진행상황: 240/313 (76.7%)\n",
            "   🔄 진행상황: 270/313 (86.3%)\n",
            "   🔄 진행상황: 300/313 (95.8%)\n",
            "✅ 결합 결과 영상 저장 완료: /content/combined_result.mp4\n",
            "📊 처리된 총 프레임: 313\n",
            "\n",
            "📁 결과 파일 정리 중...\n",
            "   생성된 결과 파일들을 표준 이름으로 복사하여 쉽게 접근할 수 있도록 합니다\n",
            "\n",
            "📋 결과 파일들:\n",
            "✅ custom_result.mp4 생성 완료 (원본: /content/custom_only/KakaoTalk_20250717_091729282 (4).avi)\n",
            "✅ base_result.mp4 생성 완료 (원본: /content/base_only/KakaoTalk_20250717_091729282 (4).avi)\n",
            "✅ final_combined_result.mp4 생성 완료 (원본: /content/combined_result.mp4)\n",
            "\n",
            "📊 커스텀 모델 성능 평가:\n",
            "   Validation 데이터셋을 사용하여 모델의 정확도를 측정합니다\n",
            "   mAP50은 IoU 0.5에서의 평균 정밀도로, 높을수록 좋은 성능을 의미합니다\n",
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 947.8±210.4 MB/s, size: 324.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid/labels.cache... 72 images, 0 backgrounds, 0 corrupt: 100%|██████████| 72/72 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:15<00:00,  3.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         72        569      0.614      0.486      0.478      0.192\n",
            "                  lane         72        497      0.529      0.416      0.433      0.142\n",
            "          traffic_sign         34         72      0.699      0.556      0.523      0.243\n",
            "Speed: 3.6ms preprocess, 179.0ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n",
            "🎯 mAP50 (Mean Average Precision): 0.4781\n",
            "   해석: 47.8% 정확도로 객체를 탐지합니다\n",
            "🎯 mAP50-95 (전체 IoU 범위): 0.1924\n",
            "\n",
            "🎬 최종 결합 결과 영상:\n",
            "   모든 객체가 탐지된 최종 결과를 확인하세요\n",
            "\n",
            "🎯 결과 요약 및 해석 가이드:\n",
            "============================================================\n",
            "📋 탐지 결과 색상 구분:\n",
            "🔵 파란색 박스: 기본 YOLO 모델 결과\n",
            "   └── 탐지 가능: 사람, 자동차, 트럭, 버스, 오토바이, 자전거, 신호등, 정지표지판 등\n",
            "   └── 총 80개 클래스의 일반적인 객체들\n",
            "🔴 빨간색 박스: 커스텀 YOLO 모델 결과\n",
            "   └── 탐지 가능: 차선(lane), 교통표지판(traffic_sign)\n",
            "   └── 도로 환경 특화 객체들\n",
            "\n",
            "📊 성능 특징:\n",
            "• 기본 모델: 넓은 범위의 객체 탐지, 일반적인 상황에 강함\n",
            "• 커스텀 모델: 특정 도메인 특화, 차선/표지판 탐지에 높은 정확도\n",
            "• 결합 모델: 두 모델의 장점을 모두 활용, 포괄적인 객체 탐지\n",
            "\n",
            "💾 다운로드 가능한 결과 파일들:\n",
            "📁 /content/ 폴더에 저장된 파일들:\n",
            "├── custom_result.mp4        : 커스텀 모델만의 탐지 결과\n",
            "├── base_result.mp4          : 기본 모델만의 탐지 결과\n",
            "├── final_combined_result.mp4: 두 모델 결합 최종 결과\n",
            "└── 원본 업로드 파일도 함께 보관됨\n",
            "\n",
            "🚀 사용 권장사항:\n",
            "• 일반적인 객체 탐지: base_result.mp4 사용\n",
            "• 도로/교통 환경 분석: custom_result.mp4 사용\n",
            "• 종합적인 분석: final_combined_result.mp4 사용\n",
            "\n",
            "✨ 처리 완료! 결과 파일들을 다운로드하여 확인하세요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Compare inference speed between PyTorch and TensorRT models(with CPU)"
      ],
      "metadata": {
        "id": "l1QEksYFSalJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics yt-dlp\n",
        "\n",
        "# Import all necessary libraries\n",
        "from ultralytics import YOLO           # YOLO model for object detection\n",
        "import glob                            # File path pattern matching\n",
        "import cv2                             # OpenCV for video processing\n",
        "import numpy as np                     # Numerical operations\n",
        "from IPython.display import Video      # Display videos in Jupyter\n",
        "import shutil                          # File operations\n",
        "import time                            # Time measurement for performance testing\n",
        "from google.colab import files         # File upload functionality for Google Colab\n",
        "\n",
        "# Create and save the dataset configuration file\n",
        "# This YAML file defines the dataset structure for custom model training/validation\n",
        "yaml_fix = '''path: /content/dataset\n",
        "train: train/images\n",
        "val: valid/images\n",
        "names:\n",
        "  0: lane\n",
        "  1: traffic_sign\n",
        "nc: 2'''\n",
        "\n",
        "# Write the configuration to a file\n",
        "with open('/content/dataset/dataset.yaml', 'w') as f:   # Originally, /dataset_fixed.yaml\n",
        "    f.write(yaml_fix)\n",
        "\n",
        "print(\"🚀 TensorRT 최적화 YOLO 추론 시작!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: LOAD BASE MODELS\n",
        "# ============================================================================\n",
        "print(\"🤖 기본 모델 로드 중...\")\n",
        "print(\"   - 기본 YOLO11n 모델: 일반적인 객체 탐지용\")\n",
        "print(\"   - 커스텀 모델: 차선 및 교통표지판 전용 학습 모델\")\n",
        "\n",
        "# Load the base YOLO11n model (pre-trained on COCO dataset)\n",
        "base_model = YOLO('yolo11n.pt')\n",
        "\n",
        "# Load your custom trained model for lane and traffic sign detection\n",
        "custom_model = YOLO('/content/dataset/best.pt')\n",
        "\n",
        "print(f\"📋 기본 모델 클래스 수: {len(base_model.names)} (COCO 데이터셋 기반)\")\n",
        "print(f\"📋 커스텀 모델 클래스 수: {len(custom_model.names)} (lane, traffic_sign)\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: CHECK GPU AVAILABILITY AND MODEL OPTIMIZATION\n",
        "# ============================================================================\n",
        "import torch\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "cuda_available = torch.cuda.is_available()\n",
        "device_count = torch.cuda.device_count()\n",
        "\n",
        "print(f\"\\n🔍 시스템 환경 확인:\")\n",
        "print(f\"   CUDA 사용 가능: {cuda_available}\")\n",
        "print(f\"   GPU 개수: {device_count}\")\n",
        "\n",
        "if cuda_available:\n",
        "    print(f\"   GPU 장치: {torch.cuda.get_device_name(0)}\")\n",
        "    use_tensorrt = True\n",
        "    device = 0\n",
        "else:\n",
        "    print(\"   ⚠️ GPU를 사용할 수 없습니다. CPU 모드로 실행됩니다.\")\n",
        "    use_tensorrt = False\n",
        "    device = 'cpu'\n",
        "\n",
        "if use_tensorrt:\n",
        "    # ============================================================================\n",
        "    # STEP 2A: CONVERT MODELS TO TENSORRT FORMAT (GPU ONLY)\n",
        "    # ============================================================================\n",
        "    print(\"\\n⚡ TensorRT 변환 중...\")\n",
        "    print(\"   TensorRT는 NVIDIA GPU에서 추론 속도를 크게 향상시키는 최적화 엔진입니다\")\n",
        "\n",
        "    try:\n",
        "        # Convert base model to TensorRT format with FP16 precision for speed optimization\n",
        "        print(\"🔄 기본 모델 → TensorRT 변환 중... (FP16 정밀도로 최적화)\")\n",
        "        base_model.export(format='engine', half=True, device=device)\n",
        "        base_trt_path = 'yolo11n.engine'\n",
        "\n",
        "        # Convert custom model to TensorRT format\n",
        "        print(\"🔄 커스텀 모델 → TensorRT 변환 중... (FP16 정밀도로 최적화)\")\n",
        "        custom_model.export(format='engine', half=True, device=device)\n",
        "        custom_trt_path = '/content/dataset/best.engine'\n",
        "\n",
        "        # Load TensorRT optimized models\n",
        "        print(\"\\n🔥 TensorRT 최적화된 모델 로드 중...\")\n",
        "        print(\"   최적화된 모델은 일반 PyTorch 모델보다 2-5배 빠른 추론 속도를 제공합니다\")\n",
        "\n",
        "        base_trt_model = YOLO(base_trt_path)      # TensorRT optimized base model\n",
        "        custom_trt_model = YOLO(custom_trt_path)  # TensorRT optimized custom model\n",
        "\n",
        "        print(\"✅ TensorRT 모델 로드 완료!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ TensorRT 변환 실패: {e}\")\n",
        "        print(\"🔄 CPU 모드로 전환합니다...\")\n",
        "        use_tensorrt = False\n",
        "\n",
        "if not use_tensorrt:\n",
        "    # ============================================================================\n",
        "    # STEP 2B: USE PYTORCH MODELS ON CPU\n",
        "    # ============================================================================\n",
        "    print(\"\\n🐍 PyTorch CPU 모드로 실행\")\n",
        "    print(\"   GPU가 없거나 TensorRT 변환에 실패하여 CPU에서 PyTorch 모델을 사용합니다\")\n",
        "\n",
        "    # Use original PyTorch models\n",
        "    base_trt_model = base_model      # Use original base model\n",
        "    custom_trt_model = custom_model  # Use original custom model\n",
        "\n",
        "    print(\"✅ PyTorch CPU 모델 준비 완료!\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: UPLOAD VIDEO FILES FROM PC\n",
        "# ============================================================================\n",
        "print(\"\\n📥 비디오 파일 업로드\")\n",
        "print(\"   브라우저 다이얼로그를 통해 PC에서 비디오 파일을 선택하세요\")\n",
        "\n",
        "# Open file upload dialog for users to select video files from their PC\n",
        "print(\"\\n🎬 업로드할 비디오 파일을 선택하세요:\")\n",
        "uploaded = files.upload()  # Returns a dictionary: {filename: file_content}\n",
        "\n",
        "# Check if any files were actually uploaded\n",
        "if not uploaded:\n",
        "    print(\"❌ 업로드된 파일이 없습니다!\")\n",
        "    raise Exception(\"No files uploaded\")  # Stop execution if no files uploaded\n",
        "\n",
        "print(f\"\\n✅ {len(uploaded)} 개의 파일이 업로드되었습니다\")\n",
        "\n",
        "# Get the first uploaded video file path\n",
        "# The uploaded files are automatically saved to the current directory\n",
        "uploaded_filenames = list(uploaded.keys())\n",
        "video_path = uploaded_filenames[0]  # Use the first uploaded file\n",
        "print(f\"📹 처리할 비디오: {video_path}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: PERFORMANCE COMPARISON FUNCTION\n",
        "# ============================================================================\n",
        "def performance_comparison(video_path, frames_to_test=100):\n",
        "    \"\"\"\n",
        "    Compare inference speed between standard and optimized models\n",
        "\n",
        "    Args:\n",
        "        video_path: Path to the video file for testing\n",
        "        frames_to_test: Number of frames to use for speed comparison\n",
        "\n",
        "    Returns:\n",
        "        speedup_ratio: How many times faster optimized models are\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n⏱️ 성능 비교 테스트 (첫 {frames_to_test}프레임으로 측정)\")\n",
        "    if use_tensorrt:\n",
        "        print(\"   PyTorch vs TensorRT 추론 속도를 정확히 비교합니다\")\n",
        "    else:\n",
        "        print(\"   표준 PyTorch vs 최적화된 PyTorch 추론 속도를 비교합니다\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Open video capture object for reading frames\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # ========== Standard Models Performance Test ==========\n",
        "    print(\"🐍 표준 모델 성능 측정 중...\")\n",
        "    standard_times = []  # Store processing time for each frame\n",
        "\n",
        "    for i in range(frames_to_test):\n",
        "        ret, frame = cap.read()  # Read next frame\n",
        "        if not ret:  # End of video\n",
        "            break\n",
        "\n",
        "        # Measure inference time for both models\n",
        "        start_time = time.time()\n",
        "        _ = base_model(frame, verbose=False)      # Base model inference\n",
        "        _ = custom_model(frame, verbose=False)    # Custom model inference\n",
        "        end_time = time.time()\n",
        "\n",
        "        standard_times.append(end_time - start_time)\n",
        "\n",
        "    # ========== Optimized Models Performance Test ==========\n",
        "    if use_tensorrt:\n",
        "        print(\"⚡ TensorRT 모델 성능 측정 중...\")\n",
        "    else:\n",
        "        print(\"🔧 최적화된 모델 성능 측정 중...\")\n",
        "\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset video to beginning\n",
        "    optimized_times = []  # Store processing time for each frame\n",
        "\n",
        "    for i in range(frames_to_test):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Measure inference time for both optimized models\n",
        "        start_time = time.time()\n",
        "        _ = base_trt_model(frame, verbose=False)     # Optimized base model\n",
        "        _ = custom_trt_model(frame, verbose=False)   # Optimized custom model\n",
        "        end_time = time.time()\n",
        "\n",
        "        optimized_times.append(end_time - start_time)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # ========== Calculate and Display Results ==========\n",
        "    standard_avg = np.mean(standard_times) * 1000    # Convert to milliseconds\n",
        "    optimized_avg = np.mean(optimized_times) * 1000\n",
        "    speedup = standard_avg / optimized_avg           # Calculate speedup ratio\n",
        "\n",
        "    model_type = \"TensorRT\" if use_tensorrt else \"최적화된 PyTorch\"\n",
        "\n",
        "    print(f\"🐍 표준 PyTorch 평균: {standard_avg:.2f}ms/frame ({1000/standard_avg:.1f} FPS)\")\n",
        "    print(f\"⚡ {model_type} 평균: {optimized_avg:.2f}ms/frame ({1000/optimized_avg:.1f} FPS)\")\n",
        "    print(f\"🚀 속도 향상: {speedup:.2f}x 빨라짐\")\n",
        "\n",
        "    return speedup\n",
        "\n",
        "# Execute performance comparison\n",
        "try:\n",
        "    speedup_ratio = performance_comparison(video_path)\n",
        "except Exception as e:\n",
        "    print(f\"❌ 성능 비교 중 오류 발생: {e}\")\n",
        "    speedup_ratio = 1.0  # Default to no speedup if comparison fails\n",
        "\n",
        "# Set model type for display purposes\n",
        "model_type = \"TensorRT\" if use_tensorrt else \"최적화된\"\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: OPTIMIZED COMBINED INFERENCE\n",
        "# ============================================================================\n",
        "def optimized_combined_inference(video_path, output_path='/content/optimized_result.mp4'):\n",
        "    \"\"\"\n",
        "    Process entire video using optimized models with visual output\n",
        "\n",
        "    Args:\n",
        "        video_path: Input video file path\n",
        "        output_path: Output processed video file path\n",
        "\n",
        "    Returns:\n",
        "        avg_fps: Average processing speed in frames per second\n",
        "    \"\"\"\n",
        "\n",
        "    # ========== Video Properties Setup ==========\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))           # Original video FPS\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Video width\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Video height\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # Total frame count\n",
        "\n",
        "    # Setup output video writer with same properties as input\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Video codec\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    model_type = \"TensorRT\" if use_tensorrt else \"최적화된\"\n",
        "    print(f\"\\n🎬 {model_type} 영상 처리 시작...\")\n",
        "    print(f\"   📹 해상도: {width}x{height}\")\n",
        "    print(f\"   🎞️ FPS: {fps}\")\n",
        "    print(f\"   📊 총 프레임: {total_frames}\")\n",
        "    print(f\"   🖥️ 처리 장치: {'GPU (TensorRT)' if use_tensorrt else 'CPU (PyTorch)'}\")\n",
        "\n",
        "    # ========== Frame-by-Frame Processing ==========\n",
        "    frame_count = 0\n",
        "    total_inference_time = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:  # End of video\n",
        "            break\n",
        "\n",
        "        # ========== Optimized Inference (with timing) ==========\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Run inference on both optimized models\n",
        "        base_results = base_trt_model(frame, verbose=False)     # General objects\n",
        "        custom_results = custom_trt_model(frame, verbose=False) # Lanes & traffic signs\n",
        "\n",
        "        inference_time = time.time() - start_time\n",
        "        total_inference_time += inference_time\n",
        "\n",
        "        # ========== Visualization of Detection Results ==========\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        # Draw base YOLO detection results (BLUE boxes)\n",
        "        if base_results[0].boxes is not None:\n",
        "            for box in base_results[0].boxes:\n",
        "                # Extract bounding box coordinates\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])    # Confidence score\n",
        "                cls = int(box.cls[0])        # Class index\n",
        "\n",
        "                # Only draw boxes with confidence > 0.3\n",
        "                if conf > 0.3:\n",
        "                    label = f\"{base_trt_model.names[cls]} {conf:.2f}\"\n",
        "                    # Draw blue rectangle and text\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "                    cv2.putText(annotated_frame, label, (x1, y1-10),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # Draw custom YOLO detection results (RED boxes)\n",
        "        if custom_results[0].boxes is not None:\n",
        "            for box in custom_results[0].boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "                cls = int(box.cls[0])\n",
        "\n",
        "                if conf > 0.3:\n",
        "                    label = f\"{custom_trt_model.names[cls]} {conf:.2f}\"\n",
        "                    # Draw red rectangle and text\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "                    cv2.putText(annotated_frame, label, (x1, y1-10),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "        # Add real-time FPS information (GREEN text)\n",
        "        fps_text = f\"{model_type}: {1/inference_time:.1f} FPS\"\n",
        "        cv2.putText(annotated_frame, fps_text, (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # Write processed frame to output video\n",
        "        out.write(annotated_frame)\n",
        "        frame_count += 1\n",
        "\n",
        "        # Progress reporting every 50 frames\n",
        "        if frame_count % 50 == 0:\n",
        "            avg_fps = frame_count / total_inference_time\n",
        "            progress = frame_count / total_frames * 100\n",
        "            print(f\"   🔄 처리 중... {frame_count}/{total_frames} ({progress:.1f}%) - 평균 {avg_fps:.1f} FPS\")\n",
        "\n",
        "    # ========== Cleanup and Results ==========\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    avg_fps = frame_count / total_inference_time\n",
        "    print(f\"✅ {model_type} 결과 영상 저장 완료: {output_path}\")\n",
        "    print(f\"📊 최종 평균 처리 속도: {avg_fps:.1f} FPS\")\n",
        "\n",
        "    return avg_fps\n",
        "    \"\"\"\n",
        "    Process entire video using TensorRT optimized models with visual output\n",
        "\n",
        "    Args:\n",
        "        video_path: Input video file path\n",
        "        output_path: Output processed video file path\n",
        "\n",
        "    Returns:\n",
        "        avg_fps: Average processing speed in frames per second\n",
        "    \"\"\"\n",
        "\n",
        "    # ========== Video Properties Setup ==========\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))           # Original video FPS\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Video width\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Video height\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # Total frame count\n",
        "\n",
        "    # Setup output video writer with same properties as input\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Video codec\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    print(f\"\\n🎬 TensorRT 최적화 영상 처리 시작...\")\n",
        "    print(f\"   📹 해상도: {width}x{height}\")\n",
        "    print(f\"   🎞️ FPS: {fps}\")\n",
        "    print(f\"   📊 총 프레임: {total_frames}\")\n",
        "\n",
        "    # ========== Frame-by-Frame Processing ==========\n",
        "    frame_count = 0\n",
        "    total_inference_time = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:  # End of video\n",
        "            break\n",
        "\n",
        "        # ========== TensorRT Inference (with timing) ==========\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Run inference on both TensorRT optimized models\n",
        "        base_results = base_trt_model(frame, verbose=False)     # General objects\n",
        "        custom_results = custom_trt_model(frame, verbose=False) # Lanes & traffic signs\n",
        "\n",
        "        inference_time = time.time() - start_time\n",
        "        total_inference_time += inference_time\n",
        "\n",
        "        # ========== Visualization of Detection Results ==========\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        # Draw base YOLO detection results (BLUE boxes)\n",
        "        if base_results[0].boxes is not None:\n",
        "            for box in base_results[0].boxes:\n",
        "                # Extract bounding box coordinates\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])    # Confidence score\n",
        "                cls = int(box.cls[0])        # Class index\n",
        "\n",
        "                # Only draw boxes with confidence > 0.3\n",
        "                if conf > 0.3:\n",
        "                    label = f\"{base_trt_model.names[cls]} {conf:.2f}\"\n",
        "                    # Draw blue rectangle and text\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "                    cv2.putText(annotated_frame, label, (x1, y1-10),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # Draw custom YOLO detection results (RED boxes)\n",
        "        if custom_results[0].boxes is not None:\n",
        "            for box in custom_results[0].boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "                cls = int(box.cls[0])\n",
        "\n",
        "                if conf > 0.3:\n",
        "                    label = f\"{custom_trt_model.names[cls]} {conf:.2f}\"\n",
        "                    # Draw red rectangle and text\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "                    cv2.putText(annotated_frame, label, (x1, y1-10),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "        # Add real-time FPS information (GREEN text)\n",
        "        fps_text = f\"TensorRT: {1/inference_time:.1f} FPS\"\n",
        "        cv2.putText(annotated_frame, fps_text, (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # Write processed frame to output video\n",
        "        out.write(annotated_frame)\n",
        "        frame_count += 1\n",
        "\n",
        "        # Progress reporting every 50 frames\n",
        "        if frame_count % 50 == 0:\n",
        "            avg_fps = frame_count / total_inference_time\n",
        "            progress = frame_count / total_frames * 100\n",
        "            print(f\"   🔄 처리 중... {frame_count}/{total_frames} ({progress:.1f}%) - 평균 {avg_fps:.1f} FPS\")\n",
        "\n",
        "    # ========== Cleanup and Results ==========\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    avg_fps = frame_count / total_inference_time\n",
        "    print(f\"✅ TensorRT 결과 영상 저장 완료: {output_path}\")\n",
        "    print(f\"📊 최종 평균 처리 속도: {avg_fps:.1f} FPS\")\n",
        "\n",
        "    return avg_fps\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: EXECUTE OPTIMIZED INFERENCE\n",
        "# ============================================================================\n",
        "print(f\"\\n🔥 {model_type} 최적화된 결합 추론 실행...\")\n",
        "if use_tensorrt:\n",
        "    print(\"   전체 비디오를 TensorRT로 최적화된 두 모델로 처리합니다\")\n",
        "    output_filename = '/content/tensorrt_final_result.mp4'\n",
        "else:\n",
        "    print(\"   전체 비디오를 CPU에서 최적화된 두 모델로 처리합니다\")\n",
        "    output_filename = '/content/cpu_final_result.mp4'\n",
        "\n",
        "try:\n",
        "    optimized_fps = optimized_combined_inference(video_path, output_filename)\n",
        "except Exception as e:\n",
        "    print(f\"❌ 최적화된 추론 중 오류 발생: {e}\")\n",
        "    optimized_fps = 0\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: STANDARD PYTORCH INFERENCE FOR COMPARISON\n",
        "# ============================================================================\n",
        "print(\"\\n🐍 표준 PyTorch 추론 (비교 기준용)...\")\n",
        "print(\"   성능 비교를 위해 동일한 영상을 표준 PyTorch 모델로 처리합니다\")\n",
        "\n",
        "def standard_pytorch_inference(video_path, output_path='/content/standard_pytorch_result.mp4'):\n",
        "    \"\"\"\n",
        "    Process video using standard PyTorch models for performance comparison\n",
        "\n",
        "    Args:\n",
        "        video_path: Input video file path\n",
        "        output_path: Output video file path\n",
        "\n",
        "    Returns:\n",
        "        standard_fps: Average processing speed in FPS\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Setup video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Run inference with standard PyTorch models\n",
        "        base_results = base_model(frame, verbose=False)\n",
        "        custom_results = custom_model(frame, verbose=False)\n",
        "\n",
        "        # Simple annotation for comparison (without detailed boxes)\n",
        "        annotated_frame = frame.copy()\n",
        "        cv2.putText(annotated_frame, \"Standard PyTorch\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
        "\n",
        "        out.write(annotated_frame)\n",
        "        frame_count += 1\n",
        "\n",
        "        # Process only first 100 frames for quick comparison\n",
        "        if frame_count >= 100:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    standard_fps = frame_count / total_time\n",
        "    return standard_fps\n",
        "\n",
        "# Execute standard PyTorch inference for comparison\n",
        "try:\n",
        "    standard_fps = standard_pytorch_inference(video_path)\n",
        "except Exception as e:\n",
        "    print(f\"❌ 표준 PyTorch 추론 중 오류 발생: {e}\")\n",
        "    standard_fps = 0\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 9: MODEL PERFORMANCE EVALUATION\n",
        "# ============================================================================\n",
        "print(\"\\n📊 커스텀 모델 정확도 평가:\")\n",
        "print(\"   Validation 데이터셋을 사용하여 모델의 정확도를 측정합니다\")\n",
        "\n",
        "# Evaluate custom model performance on validation dataset\n",
        "metrics = custom_model.val(data='/content/dataset/dataset_fixed.yaml')\n",
        "print(f\"🎯 mAP50 (Mean Average Precision): {metrics.box.map50:.4f}\")\n",
        "print(\"   mAP50은 IoU 0.5에서의 평균 정밀도로, 높을수록 좋습니다 (최대값: 1.0)\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 10: FINAL RESULTS AND COMPARISON\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎯 최종 성능 비교 결과:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"🐍 PyTorch 처리 속도:  {pytorch_fps:.1f} FPS\")\n",
        "print(f\"⚡ TensorRT 처리 속도:  {tensorrt_fps:.1f} FPS\")\n",
        "print(f\"🚀 전체 속도 향상 비율: {tensorrt_fps/pytorch_fps:.2f}x 빨라짐\")\n",
        "print(f\"📊 모델 정확도 (mAP50): {metrics.box.map50:.4f}\")\n",
        "\n",
        "print(\"\\n🎬 최종 TensorRT 최적화 결과 영상:\")\n",
        "Video('/content/tensorrt_final_result.mp4', width=800)\n",
        "\n",
        "print(\"\\n🎉 TensorRT 최적화 완료!\")\n",
        "print(\"=\"*60)\n",
        "print(\"📋 결과 해석 가이드:\")\n",
        "print(\"🔵 파란색 박스: 기본 YOLO가 탐지한 일반 객체들 (TensorRT 최적화)\")\n",
        "print(\"🔴 빨간색 박스: 커스텀 모델이 탐지한 차선/교통표지판 (TensorRT 최적화)\")\n",
        "print(\"💚 초록색 텍스트: 실시간 FPS 표시 (처리 속도 모니터링)\")\n",
        "\n",
        "print(\"\\n💾 생성된 파일들:\")\n",
        "print(\"- tensorrt_final_result.mp4: TensorRT 최적화된 최종 결과 영상\")\n",
        "print(\"- pytorch_result.mp4: PyTorch 기본 모델 비교용 영상\")\n",
        "print(\"- yolo11n.engine: 기본 YOLO 모델의 TensorRT 엔진 파일\")\n",
        "print(\"- best.engine: 커스텀 모델의 TensorRT 엔진 파일\")\n",
        "\n",
        "print(\"\\n🚀 성능 최적화 완료!\")\n",
        "print(f\"   최종 속도 향상: {speedup_ratio:.1f}x (개별 프레임 기준)\")\n",
        "print(f\"   전체 영상 처리: {tensorrt_fps/pytorch_fps:.1f}x (전체 영상 기준)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JF5702JNN-Hv",
        "outputId": "4a47f068-c48e-4b94-86bb-b59fb5e86026"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.170)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.7.21)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "🚀 TensorRT 최적화 YOLO 추론 시작!\n",
            "============================================================\n",
            "🤖 기본 모델 로드 중...\n",
            "   - 기본 YOLO11n 모델: 일반적인 객체 탐지용\n",
            "   - 커스텀 모델: 차선 및 교통표지판 전용 학습 모델\n",
            "📋 기본 모델 클래스 수: 80 (COCO 데이터셋 기반)\n",
            "📋 커스텀 모델 클래스 수: 2 (lane, traffic_sign)\n",
            "\n",
            "🔍 시스템 환경 확인:\n",
            "   CUDA 사용 가능: False\n",
            "   GPU 개수: 0\n",
            "   ⚠️ GPU를 사용할 수 없습니다. CPU 모드로 실행됩니다.\n",
            "\n",
            "🐍 PyTorch CPU 모드로 실행\n",
            "   GPU가 없거나 TensorRT 변환에 실패하여 CPU에서 PyTorch 모델을 사용합니다\n",
            "✅ PyTorch CPU 모델 준비 완료!\n",
            "\n",
            "📥 비디오 파일 업로드\n",
            "   브라우저 다이얼로그를 통해 PC에서 비디오 파일을 선택하세요\n",
            "\n",
            "🎬 업로드할 비디오 파일을 선택하세요:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-db30a266-8b6d-420b-8141-5d9fdc4f0153\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-db30a266-8b6d-420b-8141-5d9fdc4f0153\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving KakaoTalk_20250717_091729282.mp4 to KakaoTalk_20250717_091729282 (3).mp4\n",
            "\n",
            "✅ 1 개의 파일이 업로드되었습니다\n",
            "📹 처리할 비디오: KakaoTalk_20250717_091729282 (3).mp4\n",
            "\n",
            "⏱️ 성능 비교 테스트 (첫 100프레임으로 측정)\n",
            "   표준 PyTorch vs 최적화된 PyTorch 추론 속도를 비교합니다\n",
            "--------------------------------------------------\n",
            "🐍 표준 모델 성능 측정 중...\n",
            "🔧 최적화된 모델 성능 측정 중...\n",
            "🐍 표준 PyTorch 평균: 233.14ms/frame (4.3 FPS)\n",
            "⚡ 최적화된 PyTorch 평균: 242.36ms/frame (4.1 FPS)\n",
            "🚀 속도 향상: 0.96x 빨라짐\n",
            "\n",
            "🔥 최적화된 최적화된 결합 추론 실행...\n",
            "   전체 비디오를 CPU에서 최적화된 두 모델로 처리합니다\n",
            "\n",
            "🎬 최적화된 영상 처리 시작...\n",
            "   📹 해상도: 1600x720\n",
            "   🎞️ FPS: 24\n",
            "   📊 총 프레임: 313\n",
            "   🖥️ 처리 장치: CPU (PyTorch)\n",
            "   🔄 처리 중... 50/313 (16.0%) - 평균 3.8 FPS\n",
            "   🔄 처리 중... 100/313 (31.9%) - 평균 3.9 FPS\n",
            "   🔄 처리 중... 150/313 (47.9%) - 평균 4.0 FPS\n",
            "   🔄 처리 중... 200/313 (63.9%) - 평균 4.0 FPS\n",
            "   🔄 처리 중... 250/313 (79.9%) - 평균 4.0 FPS\n",
            "   🔄 처리 중... 300/313 (95.8%) - 평균 4.0 FPS\n",
            "✅ 최적화된 결과 영상 저장 완료: /content/cpu_final_result.mp4\n",
            "📊 최종 평균 처리 속도: 4.0 FPS\n",
            "\n",
            "🐍 표준 PyTorch 추론 (비교 기준용)...\n",
            "   성능 비교를 위해 동일한 영상을 표준 PyTorch 모델로 처리합니다\n",
            "\n",
            "📊 커스텀 모델 정확도 평가:\n",
            "   Validation 데이터셋을 사용하여 모델의 정확도를 측정합니다\n",
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1092.0±798.7 MB/s, size: 283.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid/labels.cache... 72 images, 0 backgrounds, 0 corrupt: 100%|██████████| 72/72 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:15<00:00,  3.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         72        569      0.614      0.486      0.478      0.192\n",
            "                  lane         72        497      0.529      0.416      0.433      0.142\n",
            "          traffic_sign         34         72      0.699      0.556      0.523      0.243\n",
            "Speed: 4.2ms preprocess, 174.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n",
            "🎯 mAP50 (Mean Average Precision): 0.4781\n",
            "   mAP50은 IoU 0.5에서의 평균 정밀도로, 높을수록 좋습니다 (최대값: 1.0)\n",
            "\n",
            "============================================================\n",
            "🎯 최종 성능 비교 결과:\n",
            "------------------------------\n",
            "🐍 PyTorch 처리 속도:  3.9 FPS\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tensorrt_fps' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-46-2841521606.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"🐍 PyTorch 처리 속도:  {pytorch_fps:.1f} FPS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"⚡ TensorRT 처리 속도:  {tensorrt_fps:.1f} FPS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"🚀 전체 속도 향상 비율: {tensorrt_fps/pytorch_fps:.2f}x 빨라짐\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"📊 모델 정확도 (mAP50): {metrics.box.map50:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensorrt_fps' is not defined"
          ]
        }
      ]
    }
  ]
}